[{"path":"https://nepem-ufsc.github.io/pliman/articles/analyze_objects.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting started","title":"Analyzing objects in an image","text":"function analyze_objects() can used count objects image. Let us start simple example image object_300dpi.png available GitHub page. facilitate image importation folder, helper function image_pliman() used.  image produced Microsoft PowerPoint. known resolution 300 dpi (dots per inch) shows four objects Larger square: 10 x 10 cm (100 cm2) Smaller square: 5 x 5 cm (25 cm2) Rectangle: 4 x 2 cm (8 cm2) Circle: 3 cm diameter (~7.08 cm2) count objects image use analyze_objects() inform image object (mandatory argument). First, use image_binary() see suitable index segment objects background. default, R, G, B (first row) normalized values (second row) used.","code":"library(pliman) #> ╭ Welcome to pliman version \"3.1.0\"! ──────────────────────────────╮ #> │                                                                  │ #> │   Developed collaboratively by NEPEM <https://nepemufsc.com>     │ #> │   Group lead: Prof. Tiago Olivoto                                │ #> │   For citation, type `citation('pliman')`                        │ #> │   We welcome your feedback and suggestions!                      │ #> │                                                                  │ #> ╰────────────── Simplifying high-throughput plant phenotyping in R ╯ img <- image_pliman(\"objects_300dpi.jpg\", plot = TRUE) image_binary(img)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/analyze_objects.html","id":"analyzing-objects","dir":"Articles","previous_headings":"","what":"Analyzing objects","title":"Analyzing objects in an image","text":"","code":"img_res <-    analyze_objects(img,                   marker = \"id\",                   index = \"B\") # use blue index to segment #> ℹ Processing a single image. Please, wait. #> ✔ Image Successfully analyzed! [2.8s]"},{"path":"https://nepem-ufsc.github.io/pliman/articles/analyze_objects.html","id":"adjusting-object-measures","dir":"Articles","previous_headings":"","what":"Adjusting object measures","title":"Analyzing objects in an image","text":"results stored img_res. Since scale declared example, idea actual area objects cm2, pixels. case, use get_measures() adjust measures pixels metric units. two main ways adjusting object measures (pixels cm, example). first one declare known area, perimeter, radius given object. measure objects computed simple rule three. second one declaring known image resolution dpi (dots per inch). case, perimeter, area, radius adjusted informed dpi.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/articles/analyze_objects.html","id":"declaring-a-known-value","dir":"Articles","previous_headings":"Adjusting object measures","what":"Declaring a known value","title":"Analyzing objects in an image","text":"Since known area larger square (object 1), let us adjust area objects image using . can used adjust measures based perimeter radius. Let us adjust perimeter objects perimeter object 2 (20 cm).","code":"get_measures(img_res,              id = 1,              area ~ 100) |>    str() #> ----------------------------------------- #> measures corrected with: #> object id: 1 #> area     : 100 #> ----------------------------------------- #> Total    : 40.001  #> Average  : 13.334  #> ----------------------------------------- #> Classes 'measures' and 'data.frame': 3 obs. of  34 variables: #>  $ id                  : num  2 3 4 #>  $ x                   : num  1737 1737 1736 #>  $ y                   : num  452 1295 938 #>  $ area                : num  25 7.05 7.95 #>  $ area_ch             : num  24.92 7.05 7.9 #>  $ perimeter           : num  19.9 10.1 11.9 #>  $ radius_mean         : num  2.86 1.49 1.67 #>  $ radius_min          : num  2.492 1.482 0.988 #>  $ radius_max          : num  3.53 1.51 2.23 #>  $ radius_sd           : num  0.31434 0.00396 0.42388 #>  $ diam_mean           : num  5.73 2.99 3.34 #>  $ diam_min            : num  4.98 2.96 1.98 #>  $ diam_max            : num  7.06 3.02 4.45 #>  $ major_axis          : num  2.04 1.06 1.48 #>  $ minor_axis          : num  2.036 1.053 0.874 #>  $ caliper             : num  7.01 3 4.43 #>  $ length              : num  5 3 3.99 #>  $ width               : num  4.99 3 1.98 #>  $ radius_ratio        : num  1.42 1.02 2.25 #>  $ theta               : num  -1.57 0.459 0 #>  $ eccentricity        : num  0.0505 0.1114 0.808 #>  $ form_factor         : num  0.79 0.873 0.704 #>  $ narrow_factor       : num  1.4 1 1.11 #>  $ asp_ratio           : num  1 1 2.01 #>  $ rectangularity      : num  0.998 1.278 0.994 #>  $ pd_ratio            : num  2.85 3.36 2.69 #>  $ plw_ratio           : num  2 1.68 2 #>  $ solidity            : num  1 1 1.01 #>  $ convexity           : num  0.75 0.909 0.836 #>  $ elongation          : num  0.00169 0.00113 0.50318 #>  $ circularity         : num  15.9 14.4 17.8 #>  $ circularity_haralick: num  9.11 377.4 3.94 #>  $ circularity_norm    : num  0.787 0.868 0.7 #>  $ coverage            : num  0.1068 0.0301 0.034 get_measures(img_res,              id = 2,              perimeter ~ 20) |>    str() #> ----------------------------------------- #> measures corrected with: #> object id: 2 #> perimeter     : 20 #> ----------------------------------------- #> Total    : 62.081  #> Average  : 20.694  #> ----------------------------------------- #> Classes 'measures' and 'data.frame': 3 obs. of  34 variables: #>  $ id                  : num  1 3 4 #>  $ x                   : num  668 1737 1736 #>  $ y                   : num  797 1295 938 #>  $ area                : num  100.52 7.09 7.99 #>  $ area_ch             : num  100.35 7.09 7.94 #>  $ perimeter           : num  40 10.1 11.9 #>  $ radius_mean         : num  5.75 1.5 1.67 #>  $ radius_min          : num  5.01 1.49 0.99 #>  $ radius_max          : num  7.08 1.51 2.23 #>  $ radius_sd           : num  0.63056 0.00397 0.42499 #>  $ diam_mean           : num  11.5 3 3.35 #>  $ diam_min            : num  10.02 2.97 1.98 #>  $ diam_max            : num  14.16 3.03 4.46 #>  $ major_axis          : num  4.09 1.06 1.49 #>  $ minor_axis          : num  4.088 1.056 0.876 #>  $ caliper             : num  14.08 3.01 4.45 #>  $ length              : num  14.16 3.01 4 #>  $ width               : num  14.15 3.01 1.99 #>  $ radius_ratio        : num  1.41 1.02 2.25 #>  $ theta               : num  0.783 0.459 0 #>  $ eccentricity        : num  0.0253 0.1114 0.808 #>  $ form_factor         : num  0.788 0.873 0.704 #>  $ narrow_factor       : num  0.995 1 1.112 #>  $ asp_ratio           : num  1 1 2.01 #>  $ rectangularity      : num  1.992 1.278 0.994 #>  $ pd_ratio            : num  2.84 3.36 2.69 #>  $ plw_ratio           : num  1.41 1.68 2 #>  $ solidity            : num  1 1 1.01 #>  $ convexity           : num  0.75 0.909 0.836 #>  $ elongation          : num  0.00043 0.00113 0.50318 #>  $ circularity         : num  15.9 14.4 17.8 #>  $ circularity_haralick: num  9.12 377.4 3.94 #>  $ circularity_norm    : num  0.787 0.868 0.7 #>  $ coverage            : num  0.4274 0.0301 0.034"},{"path":"https://nepem-ufsc.github.io/pliman/articles/analyze_objects.html","id":"declaring-the-image-resolution","dir":"Articles","previous_headings":"Adjusting object measures","what":"Declaring the image resolution","title":"Analyzing objects in an image","text":"image resolution known, measures adjusted according resolution. Let us see numerical example pixels_to_cm(). function converts number pixels (pxpx) cm, considering image resolution dpidpi, follows: cm=px×(2.54/dpi)cm = px \\times (2.54/dpi). Since know number pixels larger square, perimeter cm given perimeter object 1 adjusted image resolution close true (40 cm). Bellow, values measures adjusted declaring dpi argument get_measures().","code":"# number of pixels for the highest square perimeter ls_px <- img_res$results$perimeter[1] pixels_to_cm(px = ls_px, dpi = 300) #> [1] 39.9294 get_measures(img_res, dpi = 300) |> str() #> Classes 'measures' and 'data.frame': 4 obs. of  34 variables: #>  $ id                  : num  1 2 3 4 #>  $ x                   : num  668 1737 1737 1736 #>  $ y                   : num  797 452 1295 938 #>  $ area                : num  99.98 25 7.05 7.95 #>  $ area_ch             : num  99.81 24.91 7.05 7.9 #>  $ perimeter           : num  39.9 19.9 10.1 11.9 #>  $ radius_mean         : num  5.73 2.86 1.49 1.67 #>  $ radius_min          : num  4.994 2.491 1.482 0.988 #>  $ radius_max          : num  7.06 3.53 1.51 2.23 #>  $ radius_sd           : num  0.62885 0.31432 0.00396 0.42384 #>  $ diam_mean           : num  11.46 5.73 2.99 3.34 #>  $ diam_min            : num  9.99 4.98 2.96 1.98 #>  $ diam_max            : num  14.12 7.06 3.02 4.45 #>  $ major_axis          : num  4.08 2.04 1.06 1.48 #>  $ minor_axis          : num  4.077 2.036 1.053 0.874 #>  $ caliper             : num  14.05 7.01 3 4.43 #>  $ length              : num  14.12 5 3 3.99 #>  $ width               : num  14.11 4.99 3 1.98 #>  $ radius_ratio        : num  1.41 1.42 1.02 2.25 #>  $ theta               : num  0.783 -1.57 0.459 0 #>  $ eccentricity        : num  0.0253 0.0505 0.1114 0.808 #>  $ form_factor         : num  0.788 0.79 0.873 0.704 #>  $ narrow_factor       : num  0.995 1.402 1 1.112 #>  $ asp_ratio           : num  1 1 1 2.01 #>  $ rectangularity      : num  1.992 0.998 1.278 0.994 #>  $ pd_ratio            : num  2.84 2.85 3.36 2.69 #>  $ plw_ratio           : num  1.41 2 1.68 2 #>  $ solidity            : num  1 1 1 1.01 #>  $ convexity           : num  0.75 0.75 0.909 0.836 #>  $ elongation          : num  0.00043 0.00169 0.00113 0.50318 #>  $ circularity         : num  15.9 15.9 14.4 17.8 #>  $ circularity_haralick: num  9.12 9.11 377.4 3.94 #>  $ circularity_norm    : num  0.787 0.787 0.868 0.7 #>  $ coverage            : num  0.4274 0.1068 0.0301 0.034"},{"path":"https://nepem-ufsc.github.io/pliman/articles/analyze_objects.html","id":"counting-crop-grains","dir":"Articles","previous_headings":"","what":"Counting crop grains","title":"Analyzing objects in an image","text":", count grains image soybean_touch.jpg. image cyan background contains 30 soybean grains touch . Two segmentation strategies used. first one using image segmentation based color indexes.  function analyze_objects() segment image using default normalized blue index, follows NB=(B/(R+G+B))NB = (B/(R+G+B)), RR, GG, BB red, green, blue bands. Objects count segmented objects colored random permutations.  Users can set show_contour = FALSE remove contour line identify objects (example grains) using arguments marker = \"id\". color background can also changed col_background.  following example, select objects area average objects using lower_size = 2057.36. Additionally, use argument show_original = FALSE show results colors (non-original image).  Users can also use topn_* arguments select top n objects based either smaller largest areas. Let’s see point 5 grains smallest area, showing original grains blue background. also use argument index choose personalized index segment image. Just comparison, set explicitly normalized blue index calling index = \"B/(R+G+B)\".","code":"soy <-        image_pliman(\"soybean_touch.jpg\") grain <-      image_pliman(\"soybean_grain.jpg\") background <- image_pliman(\"la_back.jpg\") image_combine(soy, grain, background, ncol = 3) count2 <-    analyze_objects(soy,                   index = \"NB\") # default #> ℹ Processing a single image. Please, wait. #> ✔ Image Successfully analyzed! [245ms] count <-    analyze_objects(soy,                   show_contour = FALSE,                   marker = \"id\",                   show_segmentation = FALSE,                   col_background = \"white\",                   index = \"NB\") # default #> ℹ Processing a single image. Please, wait. #> ✔ Image Successfully analyzed! [588ms] # Get the object measures measures <- get_measures(count) str(measures) #> Classes 'measures' and 'data.frame': 30 obs. of  34 variables: #>  $ id                  : num  1 2 3 4 5 6 7 8 9 10 ... #>  $ x                   : num  245 537 237 344 277 ... #>  $ y                   : num  509 401 339 105 260 ... #>  $ area                : num  2279 2289 2310 2436 2159 ... #>  $ area_ch             : num  2304 2262 2288 2408 2122 ... #>  $ perimeter           : num  184 178 181 186 172 ... #>  $ radius_mean         : num  26.5 26.6 26.7 27.5 25.8 ... #>  $ radius_min          : num  23 24.8 24 24.3 24.2 ... #>  $ radius_max          : num  29.4 28.7 29.4 30.5 28 ... #>  $ radius_sd           : num  1.375 0.966 1.238 1.74 0.801 ... #>  $ diam_mean           : num  53 53.1 53.4 54.9 51.5 ... #>  $ diam_min            : num  45.9 49.7 48 48.6 48.5 ... #>  $ diam_max            : num  58.8 57.4 58.9 61.1 56.1 ... #>  $ major_axis          : num  19.3 19.5 19.8 20.8 18.7 ... #>  $ minor_axis          : num  18.2 18 17.9 18 17.7 ... #>  $ caliper             : num  57.3 56.9 57.7 61 54.4 ... #>  $ length              : num  56.6 56.5 57.2 61 54 ... #>  $ width               : num  51.5 52.4 52 51 50.5 ... #>  $ radius_ratio        : num  1.28 1.16 1.23 1.26 1.16 ... #>  $ theta               : num  -0.828 -0.804 -0.637 -0.979 -0.217 ... #>  $ eccentricity        : num  0.328 0.387 0.428 0.495 0.325 ... #>  $ form_factor         : num  0.85 0.906 0.886 0.889 0.92 ... #>  $ narrow_factor       : num  1.01 1.01 1.01 1 1.01 ... #>  $ asp_ratio           : num  1.1 1.08 1.1 1.2 1.07 ... #>  $ rectangularity      : num  1.28 1.29 1.29 1.28 1.26 ... #>  $ pd_ratio            : num  3.2 3.13 3.14 3.04 3.16 ... #>  $ plw_ratio           : num  1.7 1.64 1.66 1.66 1.64 ... #>  $ solidity            : num  0.989 1.012 1.009 1.012 1.017 ... #>  $ convexity           : num  0.887 0.879 0.911 0.919 0.898 ... #>  $ elongation          : num  0.089 0.0737 0.0911 0.1639 0.0643 ... #>  $ circularity         : num  14.8 13.9 14.2 14.1 13.7 ... #>  $ circularity_haralick: num  19.3 27.5 21.6 15.8 32.2 ... #>  $ circularity_norm    : num  0.821 0.875 0.855 0.858 0.887 ... #>  $ coverage            : num  0.00426 0.00428 0.00432 0.00456 0.00404 0.0043 0.00414 0.00406 0.00432 0.00405 ... analyze_objects(soy,                 marker = \"id\",                 show_original = FALSE,                 lower_size = 2057.36,                 index = \"NB\") # default #> ℹ Processing a single image. Please, wait. #> ✔ Image Successfully analyzed! [496ms] analyze_objects(soy,                 marker = \"id\",                 topn_lower = 5,                 col_background = \"blue\",                 index = \"B/(R+G+B)\") # default #> ℹ Processing a single image. Please, wait. #> ✔ Image Successfully analyzed! [336ms]"},{"path":"https://nepem-ufsc.github.io/pliman/articles/analyze_objects.html","id":"using-sample-palettes","dir":"Articles","previous_headings":"","what":"Using sample palettes","title":"Analyzing objects in an image","text":"Sometimes difficult choose image index segments image efficiently (even using index ). pliman users alternative image segmentation strategy using sample color palettes. case, users can say analyze_objects color palettes used background foreground. generalized linear model (binomial family) used predict value pixel (background foreground). Let’s see grains image can counted strategy.  Provided images stored current working directory (subdirectory), users can count objects need first import image R environment. case, image names need declared characters. Assuming soy, background, grain images saved current working directory, result obtained ","code":"analyze_objects(img = soy,                 background = background,                 foreground = grain) #> ℹ Processing a single image. Please, wait. #> ✔ Image Successfully analyzed! [575ms] analyze_objects(img = \"soy\",                 background = \"background\",                 foreground = \"grain\")"},{"path":"https://nepem-ufsc.github.io/pliman/articles/analyze_objects.html","id":"leaf-shape","dir":"Articles","previous_headings":"","what":"Leaf shape","title":"Analyzing objects in an image","text":"function analyze_objects() computes range object features can used study leaf shape. motivating example, use image potato_leaves.png, gathered Gupta et al. (2020)1  Three key measures (pixel units) : area area object. area_ch area convex hull. perimeter perimeter object. Using measures, circularity solidity computed shown (Gupta et al, 2020). circularity=4π(area/perimeter2) circularity = 4\\pi(area / perimeter^2) solidity=area/area_chsolidity = area / area\\_ch Circularity influenced serrations lobing. Solidity sensitive leaves deep lobes, distinct petiole, can used distinguish leaves lacking structures. Unlike circularity, sensitive serrations minor lobings, since convex hull remains largely unaffected.","code":"potato <- image_pliman(\"potato_leaves.jpg\", plot = TRUE) pot_meas <-   analyze_objects(potato,                   watershed = FALSE,                   marker = \"id\",                   show_chull = TRUE) # shows the convex hull #> ℹ Processing a single image. Please, wait. #> ✔ Image Successfully analyzed! [327ms]     str(pot_meas) #> List of 16 #>  $ results         :'data.frame':    3 obs. of  34 variables: #>   ..$ id                  : num [1:3] 1 2 3 #>   ..$ x                   : num [1:3] 639 147 401 #>   ..$ y                   : num [1:3] 167 162 180 #>   ..$ area                : num [1:3] 28715 32982 19565 #>   ..$ area_ch             : num [1:3] 30490 42835 34718 #>   ..$ perimeter           : num [1:3] 754 935 1132 #>   ..$ radius_mean         : num [1:3] 98.1 105 81.8 #>   ..$ radius_min          : num [1:3] 68.5 52.7 27.9 #>   ..$ radius_max          : num [1:3] 147 143 140 #>   ..$ radius_sd           : num [1:3] 19.6 21.3 26.3 #>   ..$ diam_mean           : num [1:3] 196 210 164 #>   ..$ diam_min            : num [1:3] 137.1 105.5 55.9 #>   ..$ diam_max            : num [1:3] 295 287 279 #>   ..$ major_axis          : num [1:3] 78.5 80 62.2 #>   ..$ minor_axis          : num [1:3] 62 71.3 59.2 #>   ..$ caliper             : num [1:3] 258 257 233 #>   ..$ length              : num [1:3] 258 244 219 #>   ..$ width               : num [1:3] 191 246 228 #>   ..$ radius_ratio        : num [1:3] 2.15 2.72 5 #>   ..$ theta               : num [1:3] 1.428 -0.136 0.536 #>   ..$ eccentricity        : num [1:3] 0.614 0.453 0.307 #>   ..$ form_factor         : num [1:3] 0.635 0.474 0.192 #>   ..$ narrow_factor       : num [1:3] 1 1.06 1.06 #>   ..$ asp_ratio           : num [1:3] 1.352 0.991 0.961 #>   ..$ rectangularity      : num [1:3] 1.71 1.82 2.55 #>   ..$ pd_ratio            : num [1:3] 2.92 3.63 4.86 #>   ..$ plw_ratio           : num [1:3] 1.68 1.91 2.53 #>   ..$ solidity            : num [1:3] 0.942 0.77 0.564 #>   ..$ convexity           : num [1:3] 0.915 0.736 0.563 #>   ..$ elongation          : num [1:3] 0.26027 -0.00948 -0.04045 #>   ..$ circularity         : num [1:3] 19.8 26.5 65.5 #>   ..$ circularity_haralick: num [1:3] 5.02 4.93 3.1 #>   ..$ circularity_norm    : num [1:3] 0.628 0.468 0.187 #>   ..$ coverage            : num [1:3] 0.1332 0.153 0.0908 #>  $ statistics      :'data.frame':    7 obs. of  2 variables: #>   ..$ stat : chr [1:7] \"n\" \"min_area\" \"mean_area\" \"max_area\" ... #>   ..$ value: num [1:7] 3 19565 27087 32982 6855 ... #>  $ object_rgb      : NULL #>  $ object_index    : NULL #>  $ efourier        : NULL #>  $ efourier_norm   : NULL #>  $ efourier_error  : NULL #>  $ efourier_power  : NULL #>  $ efourier_minharm: NULL #>  $ veins           : NULL #>  $ angles          : NULL #>  $ width_at        : NULL #>  $ mask            : NULL #>  $ pcv             : NULL #>  $ contours        :List of 3 #>   ..$ 1: int [1:641, 1:2] 634 634 633 633 632 631 631 630 630 629 ... #>   ..$ 2: int [1:806, 1:2] 144 144 144 143 143 142 142 142 141 141 ... #>   ..$ 3: int [1:982, 1:2] 395 395 395 394 394 394 394 394 394 394 ... #>  $ parms           :List of 2 #>   ..$ index       : chr \"NB\" #>   ..$ object_index: NULL #>  - attr(*, \"class\")= chr \"anal_obj\""},{"path":"https://nepem-ufsc.github.io/pliman/articles/analyze_objects.html","id":"object-contour","dir":"Articles","previous_headings":"Leaf shape","what":"Object contour","title":"Analyzing objects in an image","text":"Users can also obtain object contour convex hull follows:","code":"cont <-   object_contour(potato,                  watershed = FALSE,                  plot = FALSE) plot(potato) plot_contour(cont, col = \"red\", lwd = 3)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/analyze_objects.html","id":"convex-hull","dir":"Articles","previous_headings":"Leaf shape","what":"Convex hull","title":"Analyzing objects in an image","text":"function object_contour() returns list coordinate points object contour can used obtain convex hull conv_hull().","code":"conv <- conv_hull(cont) plot(potato) plot_contour(conv, col = \"red\", lwd = 3)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/analyze_objects.html","id":"area-of-the-convex-hull","dir":"Articles","previous_headings":"Leaf shape","what":"Area of the convex hull","title":"Analyzing objects in an image","text":", area convex hull can obtained poly_area().","code":"(area <- poly_area(conv)) #> [1] 30490 42835 34718"},{"path":"https://nepem-ufsc.github.io/pliman/articles/analyze_objects.html","id":"leaves-as-base-plot","dir":"Articles","previous_headings":"Leaf shape","what":"Leaves as base plot","title":"Analyzing objects in an image","text":"ggplot2","code":"# create a data frame for contour and convex hull df_cont <-   do.call(rbind,           lapply(seq_along(cont), function(i){             transform(as.data.frame(cont[[i]]), object = names(cont[i]))           }))  df_conv <-     do.call(rbind,           lapply(seq_along(conv), function(i){             transform(as.data.frame(conv[[i]]), object = names(conv[i]))           }))   # plot the objects palette(c(\"red\",\"blue\",\"green\")) with(df_cont,      plot(V1, V2,            cex = 0.5,           col = object,           xlab = NA,           ylab = NA,           axes = F)) with(subset(df_conv, object == 1),      polygon(V1, V2,               col = rgb(1, 0, 0, 0.2),              border = NA)) with(subset(df_conv, object == 2),      polygon(V1, V2,               col = rgb(0, 0, 1, 0.2),              border = NA)) with(subset(df_conv, object == 3),      polygon(V1, V2,               col = rgb(0, 1, 0, 0.2),              border = NA)) library(ggplot2) ggplot(df_cont, aes(V1, V2, group = object)) +   geom_polygon(aes(fill = object)) +   geom_polygon(data = df_conv,                aes(V1, V2, fill = object),                alpha = 0.3) +   theme_void() +   theme(legend.position = \"bottom\")"},{"path":"https://nepem-ufsc.github.io/pliman/articles/analyze_objects.html","id":"batch-processing","dir":"Articles","previous_headings":"","what":"Batch processing","title":"Analyzing objects in an image","text":"plant image analysis, frequently necessary process one image. example, plant breeding, number grains per plant (e.g., wheat) frequently used indirect selection high-yielding plants. pliman, batch processing can done user declares argument pattern. following example used count objects images pattern name \"trat\" (e.g., \"trat1\", \"trat2\", \"tratn\") saved subfolder “originals\" current working directory. processed images saved subfolder \"processed\". object list_res list two objects (results statistics) image. speed processing time, especially large number images, argument parallel = TRUE can used. case, images processed asynchronously (parallel) separate R sessions running background machine. number sections set 50% available cores. number can controlled explicitly argument workers.","code":"list_res <-    analyze_objects(pattern = \"trat\", # matches the name pattern in 'originals' subfolder                   dir_original = \"originals\",                   dir_processed = \"processed\",                   parallel = TRUE, # parallel processing                   workers = 8, # 8 multiple sections                   save_image = TRUE)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/analyze_objects.html","id":"a-little-bit-more","dir":"Articles","previous_headings":"","what":"A little bit more!","title":"Analyzing objects in an image","text":"link find examples use {pliman} analyze plant images. Source code images can downloaded . can also find talk (Portuguese language) {pliman} . Lights, camera, {pliman}!","code":""},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"High Throughput Phenotyping","text":"two main function families pliman —shapefile_*() mosaic_*()— serve foundation high-throughput phenotyping (HTP) analysis. shapefile_build() function central constructing shapefiles, offering customizable layouts export options allow users tailor shapefiles diverse experimental designs field layouts, enhancing relevance reproducibility data collected. Following shapefile creation, mosaic_*() family pivotal performing mosaic analysis —process includes calculating vegetation indices, segmenting plant canopies, visualizing plant-level data. mosaic_analyze() function, particular, automates extraction detailed phenotypic information, making easy capture metrics plant health, spatial distribution, structure across fields. practical examples, users learn leverage function automating plant-level data extraction, thus boosting efficiency depth HTP workflows. shapefiles orthomosaics used vignette publicly available , ensuring reproducibility allowing users follow along example. Since data accessed remotely, active internet connection required run examples. Alternatively, can download entire repository modify code import files local source, making convenient offline use adaptable different working environments.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"r-packages","dir":"Articles","previous_headings":"","what":"R packages","title":"High Throughput Phenotyping","text":"","code":"library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) library(pliman) #> ╭ Welcome to pliman version \"3.1.0\"! ──────────────────────────────╮ #> │                                                                  │ #> │   Developed collaboratively by NEPEM <https://nepemufsc.com>     │ #> │   Group lead: Prof. Tiago Olivoto                                │ #> │   For citation, type `citation('pliman')`                        │ #> │   We welcome your feedback and suggestions!                      │ #> │                                                                  │ #> ╰────────────── Simplifying high-throughput plant phenotyping in R ╯ #>  #> Attaching package: 'pliman' #> The following object is masked from 'package:dplyr': #>  #>     %>%"},{"path":[]},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"building","dir":"Articles","previous_headings":"Shapefiles","what":"Building","title":"High Throughput Phenotyping","text":"Shapefiles widely used format geographic information systems (GIS) representing vector data points, lines, polygons. essential spatial analysis can store information geographical features attributes. three main geometry types. Points: Represent specific locations (e.g., control points, cities). Lines: Represent linear features (e.g., roads, rivers). Polygons: Represent areas (e.g., boundaries regions land parcels). , explore theshapefile_build() function works constructing shapefiles. default, calling shapefile_build(mosaic, ...) allows creation either rectangular grids (defined rows columns) custom, free-form shapes, providing flexibility different experimental designs. create rectangular grid, define corners region interest (ROI) sequence: top left → top right → bottom right → bottom left → back top left close polygon. four points provided, function interpret vertices free-form shape, constructing customized polygon precisely fits specified boundaries. flexibility makes shapefile_build() versatile tool, allowing users adapt shapefile structures match complex field layouts specific plot arrangements. purpose example, use predefined shapefile containing control points demonstrate process, ensuring reproducibility allowing follow along output.  function shapefile_build() returns Simple Feature sf object , data structure used store spatial objects (points, lines, polygons) along associated attributes, follows: shapefile_build() returns grid layout default goes left right top bottom (layout = \"lrtb\") combining layout serpentine arguments, can generate total 16 distinct layouts. layout argument controls primary arrangement items, serpentine argument introduces optional serpentine pattern, alters direction item placement alternating rows columns. layout argument specifies orientation layout character string. can choose following options: ‘tblr’: Top Bottom, Left Right ‘tbrl’: Top Bottom, Right Left ‘btlr’: Bottom Top, Left Right ‘btrl’: Bottom Top, Right Left ‘lrtb’: Left Right, Top Bottom ‘lrbt’: Left Right, Bottom Top ‘rltb’: Right Left, Top Bottom ‘rlbt’: Right Left, Bottom Top serpentine argument determines whether serpentine layout applied. set TRUE, items alternating rows columns placed reverse order, creating “zig-zag” pattern. default, serpentine set FALSE, means layout follows specified direction without altering order alternating rows columns. Copy run following code build Shiny app demonstrate two arguments interact affect layout:","code":"url <- \"https://github.com/TiagoOlivoto/images/raw/refs/heads/master/pliman/ortho/\" mosaic <-    mosaic_input(paste0(url, \"orthosmall.tif\"), info = FALSE) cpoint <- shapefile_input(paste0(url, \"controlpoints.rds\"), info = FALSE)  mosaic_plot_rgb(mosaic) shapefile_plot(cpoint, add = TRUE, lwd = 5) # Create a basemap for further plots bm <- mosaic_view(mosaic, r = 1, g = 2, b = 3) #> Warning in CPL_crs_from_input(x): GDAL Message 1: +init=epsg:XXXX syntax is #> deprecated. It might return a CRS with a non-EPSG compliant axis order. Further #> messages of this type will be suppressed.  shp <- shapefile_build(   mosaic = mosaic,        # the raster file   controlpoints = cpoint, # control points (optional)   basemap = bm,           # basemap (optional)   nrow = 5,               # number of rows   ncol = 3,               # number of columns   layout = \"tbrl\",        # layout definition   serpentine = FALSE      # serpentine layout?    ) #> ℹ Building the mosaic✔ Mosaic built [13ms] #> ℹ Cropping the mosaic✔ Mosaic cropped [425ms] #> ℹ Creating the shapes✔ Shapes created [143ms] #> ℹ Finishing the shapefile✔ Shapefile built [49ms]   # see key aspects of the created shapefiles shapefile_measures(shp) #> Simple feature collection with 15 features and 11 fields #> Geometry type: POLYGON #> Dimension:     XY #> Bounding box:  xmin: 734315.6 ymin: 4488975 xmax: 734327 ymax: 4488979 #> Projected CRS: WGS 72BE / UTM zone 14N #> First 10 features: #>    unique_id block plot_id row column   xcoord  ycoord     area perimeter width #> 1          1   B01   P0011   1      1 734317.5 4488978 2.943949  9.127652 3.786 #> 2          2   B01   P0012   2      1 734317.5 4488978 2.943949  9.127652 3.786 #> 3          3   B01   P0013   3      1 734317.5 4488977 2.943949  9.127652 3.786 #> 4          4   B01   P0014   4      1 734317.5 4488976 2.943949  9.127652 3.786 #> 5          5   B01   P0015   5      1 734317.6 4488975 2.943949  9.127652 3.786 #> 6          6   B01   P0006   1      2 734321.2 4488978 2.943949  9.127652 3.786 #> 7          7   B01   P0007   2      2 734321.3 4488978 2.943949  9.127652 3.786 #> 8          8   B01   P0008   3      2 734321.3 4488977 2.943949  9.127652 3.786 #> 9          9   B01   P0009   4      2 734321.3 4488976 2.943949  9.127652 3.786 #> 10        10   B01   P0010   5      2 734321.3 4488975 2.943949  9.127652 3.786 #>    height                       geometry #> 1   0.778 POLYGON ((734315.6 4488979,... #> 2   0.778 POLYGON ((734315.6 4488978,... #> 3   0.778 POLYGON ((734315.6 4488977,... #> 4   0.778 POLYGON ((734315.6 4488976,... #> 5   0.778 POLYGON ((734315.7 4488976,... #> 6   0.778 POLYGON ((734319.3 4488979,... #> 7   0.778 POLYGON ((734319.4 4488978,... #> 8   0.778 POLYGON ((734319.4 4488977,... #> 9   0.778 POLYGON ((734319.4 4488976,... #> 10  0.778 POLYGON ((734319.4 4488976,... bm + shapefile_view(shp, attribute = \"plot_id\") library(shiny) library(bs4Dash) library(pliman) library(leaflet)  # Define the UI ui <- bs4DashPage(   sidebar = bs4DashSidebar(disable = TRUE),    body = bs4DashBody(     fluidRow(       column(         width = 4, # Controls will be in a 3-column layout         title = \"Controls\",         selectInput(           inputId = \"layout\",           label = \"Select Layout Orientation:\",           choices = c('tblr', 'tbrl', 'btlr', 'btrl', 'lrtb', 'lrbt', 'rltb', 'rlbt'),           selected = 'tblr'         ),         checkboxInput(           inputId = \"serpentine\",           label = \"Apply Serpentine Layout?\",           value = FALSE         ),         numericInput(           inputId = \"nrow\",           label = \"Number of Rows:\",           value = 5,           min = 1,           max = 10         ),         numericInput(           inputId = \"ncol\",           label = \"Number of Columns:\",           value = 3,           min = 1,           max = 10         ),         numericInput(           inputId = \"pwidth\",           label = \"Plot width (optional):\",           value = NULL,           min = 0,           max = Inf         ),         numericInput(           inputId = \"pheight\",           label = \"Plot height (optional):\",           value = NULL,           min = 0,           max = Inf         )       ),       column(         width = 8, # Map plot will take 9 columns         title = \"Map\",         leafletOutput(\"map\", height = \"640px\")       )     )   ),   header = bs4DashNavbar(     title = dashboardBrand(       title = \"Live demonstration\",       color = \"white\",       opacity = 0.8     ),     status = \"white\",     fixed = TRUE   ) )   # Define the server logic server <- function(input, output, session) {   url <- \"https://github.com/TiagoOlivoto/images/raw/refs/heads/master/pliman/ortho/\"   mosaic <-    mosaic_input(paste0(url, \"orthosmall.tif\"), info = FALSE)   cpoint <- shapefile_input(paste0(url, \"controlpoints.rds\"), info = FALSE)   bm <- mosaic_view(mosaic, r = 1, g = 2, b = 3)   # Build the shapefile   map <- reactive({     if(!is.na(input$pwidth) && !is.na(input$pheight)){       pwidth <- input$pwidth       pheight <- input$pheight     } else{       pwidth <- NULL       pheight <- NULL     }     shp <- shapefile_build(mosaic = mosaic,                            controlpoints = cpoint,                            basemap = bm,                            nrow = input$nrow,                            ncol = input$ncol,                            layout = input$layout,                            serpentine = input$serpentine,                            plot_width = pwidth,                            plot_height = pheight,                            verbose = FALSE)     req(shp)     (bm + shapefile_view(shp, attribute = \"plot_id\"))@map   })      output$map <- renderLeaflet({     map()   }) }  # Run the application  shinyApp(ui = ui, server = server)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"exporting","dir":"Articles","previous_headings":"Shapefiles","what":"Exporting","title":"High Throughput Phenotyping","text":"working spatial data R, two common file formats .shp (shapefiles) .rds (R serialized files). shapefile standard format Geographic Information Systems (GIS) storing spatial vector data (points, lines, polygons) can imported GIS software, like QGIS. Despite name, shapefile single file collection related files: .shp: Contains geometry (shapes) features (points, lines, polygons). .cpg: Contains character encoding used interpret text data .dbf file (defaults UTF-8). .shx: index file speeds data access. .dbf: Stores attributes properties feature (like ID, name, etc.). .prj: Defines Coordinate Reference System (CRS), ensuring correct placement Earth’s surface. .rds file (suggested work pliman) format specific R, used saving single R objects (including spatial data) serialized form. ’s ideal saving R objects native format later loading back R exactly saved. function shapefile_export() can used export shapefile created shapefile_build() SpatVector sf object.","code":"# export to a .rds file shapefile_export(shp, \"shape_rds.rds\") # export to a .shp file shapefile_export(shp, \"shape_shp.shp\")"},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"importing-shapefiles","dir":"Articles","previous_headings":"Shapefiles","what":"Importing shapefiles","title":"High Throughput Phenotyping","text":"can import previously saved shapefiles using shapefile_input() function. function supports .rds files .shp files, whether exported using shapefile_export() created software. However, since functions pliman package designed work shapefiles generated within pliman, ’s crucial ensure specific fields—unique_id, block, plot_id, row, column—present shapefile. required fields missing, unexpected errors may occur processing.","code":"shp <- shapefile_input(\"shape_rds.rds\")"},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"exploring-the-mosaic_analyze-function","dir":"Articles","previous_headings":"","what":"Exploring the mosaic_analyze() function","title":"High Throughput Phenotyping","text":"mosaic_analyze() cornerstone function pliman high-throughput phenotyping. enables users efficiently process orthomosaics extract wealth data satellite drone imagery just lines code. cases, need orthomosaic (even .jpg image cellphone) right function parameters unlock full potential.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"case-study","dir":"Articles","previous_headings":"Exploring the mosaic_analyze() function","what":"Case study","title":"High Throughput Phenotyping","text":"example , mosaic_analyze() used count, measure, extract image indices block, plot, individual levels lettuce trial. process based orthomosaic image, described paper. big thank authors providing full-resolution .tif file, enabled advance several functionalities pliman, including high-throughput image analysis data extraction multiple levels. kind data sharing invaluable driving innovation tool development. trial conducted using randomized complete block design four blocks. researchers tested effects Aspergillus niger application (six different levels, combining concentration formulation) three levels phosphorus (0%, 50%, 100%) lettuce growth. plimans shapefile, plot within four blocks represented unique plot_id, “P0001,” “P0002,” etc. correspond following treatments:","code":""},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"importing-the-needed-files","dir":"Articles","previous_headings":"Exploring the mosaic_analyze() function","what":"Importing the needed files","title":"High Throughput Phenotyping","text":"mosaic_input() function used load mosaic lettuce field, shapefile_input() function used load corresponding shapefile delineates plots. can also create shapefile shapefile_build() (previous section) simply define nrow ncol arguments mosaic_analyze(). example, basemap created using mosaic image serve foundation visualizations. creating basemap mandatory, can significantly speed process, functions like mosaic_analyze(), shapefile_build(), shapefile_edit() automatically render leaflet map one provided. pre-creating basemap, avoid overhead rendering multiple maps, making workflow efficient. Additionally, shapefile layer overlaid top basemap display levels inoculante factor.","code":"url <- \"https://github.com/TiagoOlivoto/images/raw/refs/heads/master/pliman/lettuce/\" mos <-    mosaic_input(paste0(url, \"lettuce.tif\"), info = FALSE) shp <- shapefile_input(paste0(url, \"lettuce.rds\"), info = FALSE)  # create a basemap bm <- mosaic_view(mos, r = 1, g = 2, b = 3) # defaults is 1e6.. so here, a bit higher resolution is used #> ℹ Using `downsample = 2` to match the max_pixels #> constraint. bm + shapefile_view(shp, attribute = \"p\", color_regions = ggplot_color(3))"},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"analyzing-the-mosaic","dir":"Articles","previous_headings":"Exploring the mosaic_analyze() function","what":"Analyzing the mosaic","title":"High Throughput Phenotyping","text":"function mosaic_analyze() need now. vegetation indexes computed plant defined object indexes. , Normalized Green Red Difference Index (NGRDI), Green Leaf Index (GLI), Blue Green Index (BGI) used. can find list build-vegetation indexes pliman . setting segment_individuals = TRUE, mosaic_analyze() shifts focus individual plant level. Using threshold-based segmentation method, isolates plant within plot, enabling precise counting measurement, provided higher contrast plant soi. function can also handle complex backgrounds additional arguments, ’s focus . Instead, power approach lies ability break plot individual components, providing detailed analysis plant morphology, size, distribution. transforms high-throughput phenotyping moving broad plot-level perspective -depth examination plant, unlocking new level precision insight. context, original study, researchers manually measured diameter four central plants plot. mosaic_analyze(), process automated also expanded include every plant plot, providing comprehensive data fraction time. Using segment_index = \"GLI\", configure analysis segment soil identify individual plants based GLI index. analysis return summary statistics plot map showing segmented individual plants. , can see results individual plant level. plant within plot identified, segmented, color-coded based measured characteristics (e.g., mean vegetation indices). can use attribute argument mosaic_analyze() control visualizations, ’s need worry—new plots can easily generated results computed, giving full flexibility data displayed. plot, detailed summary statistics also returned, allowing -depth analysis plant performance across entire experiment. can gain deeper insights utilizing results generated mosaic_analyze(). , data grouped different levels inoculante factor explore influences analysis.","code":"indexes <- c(\"NGRDI\", \"GLI\") an <- mosaic_analyze(   mosaic = mos,   basemap = bm,   r = 1,   g = 2,   b = 3,   shapefile = shp,   plot_index = indexes,   segment_individuals = TRUE,   segment_index = \"GLI\" ) #> ── Analyzing the mosaic ──────────────────── Started on 2025-08-23 | 16:08:24 ── #> ℹ Cropping the mosaic to the shapefile extent... #> Warning: ! ``segment_plot`` must have length 1 or 4 (the #> number of drawn polygons). #> Warning: ! ``segment_individuals`` must have length 1 or 4 (the number of drawn #>   polygons). #> Warning: ! ``threshold`` must have length 1 or 4 (the #> number of drawn polygons). #> Warning: ! ``watershed`` must have length 1 or 4 (the #> number of drawn polygons). #> Warning: ! ``segment_index`` must have length 1 or 4 #> (the number of drawn polygons). #> Warning: ! ``invert`` must have length 1 or 4 (the #> number of drawn polygons). #> Warning: ! ``includeopt`` must have length 1 or 4 (the #> number of drawn polygons). #> Warning: ! ``opening`` must have length 1 or 4 (the #> number of drawn polygons). #> Warning: ! ``closing`` must have length 1 or 4 (the #> number of drawn polygons). #> Warning: ! ``filter`` must have length 1 or 4 (the #> number of drawn polygons). #> Warning: ! ``erode`` must have length 1 or 4 (the number #> of drawn polygons). #> Warning: ! ``dilate`` must have length 1 or 4 (the #> number of drawn polygons). #> Warning: ! ``grid`` must have length 1 or 4 (the number #> of drawn polygons). #> Warning: ! ``lower_noise`` must have length 1 or 4 (the #> number of drawn polygons). #> ✔ Cropping the mosaic to the shapefile extent [1.2s] #> ℹ Computing vegetation indexes...✔ Computing vegetation indexes [903ms] #>  #> ── Analyzing block 1 ── #>  #> ℹ Segmenting individuals within plots...✔ Segmenting individuals within plots [1.6s] #> ℹ Extracting features from segmented individuals...✔ Extracting features from segmented individuals [171ms] #> ℹ Extracting plot-level features...✔ Extracting plot-level features [220ms] #> ℹ Binding the extracted features...                                    ── Analyzing block 2 ── #> ℹ Binding the extracted features...                                     #> ℹ Binding the extracted features...✔ Binding the extracted features [74ms] #> ℹ Segmenting individuals within plots...✔ Segmenting individuals within plots [1.4s] #> ℹ Extracting features from segmented individuals...✔ Extracting features from segmented individuals [139ms] #> ℹ Extracting plot-level features...✔ Extracting plot-level features [72ms] #> ℹ Binding the extracted features...                                    ── Analyzing block 3 ── #> ℹ Binding the extracted features...                                     #> ℹ Binding the extracted features...✔ Binding the extracted features [68ms] #> ℹ Segmenting individuals within plots...✔ Segmenting individuals within plots [1.4s] #> ℹ Extracting features from segmented individuals...✔ Extracting features from segmented individuals [117ms] #> ℹ Extracting plot-level features...✔ Extracting plot-level features [67ms] #> ℹ Binding the extracted features...                                    ── Analyzing block 4 ── #> ℹ Binding the extracted features...                                     #> ℹ Binding the extracted features...✔ Binding the extracted features [67ms] #> ℹ Segmenting individuals within plots...✔ Segmenting individuals within plots [1.1s] #> ℹ Extracting features from segmented individuals...✔ Extracting features from segmented individuals [132ms] #> ℹ Extracting plot-level features...✔ Extracting plot-level features [85ms] #> ℹ Binding the extracted features...✔ Binding the extracted features [18ms] #> ℹ Summarizing the results...                             ── Mosaic successfully analyzed ─────────── Finished on 2025-08-23 | 16:08:34 ── #> ℹ Summarizing the results...✔ Summarizing the results [737ms] an$map_indiv # see the results averaged by the combination of inoculante and p factors library(dplyr) dfino <-    an$result_plot_summ |>    group_by(plot_id, inoculante, p) |>    summarise(across(where(is.numeric), mean)) #> `summarise()` has grouped output by 'plot_id', 'inoculante'. You can override #> using the `.groups` argument.  # inoculante levels bm + shapefile_view(dfino, attribute = \"inoculante\", color_regions = ggplot_color(6)) # phospurus level bm + shapefile_view(dfino, attribute = \"p\", color_regions = ggplot_color(3))"},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"vegetation-indexes-and-canopy-coverage","dir":"Articles","previous_headings":"","what":"Vegetation indexes and canopy coverage","title":"High Throughput Phenotyping","text":"example demonstrates use orthomosaic soybean trial calculate vegetation indexes, specifically Green Leaf Index (GLI) Normalized Green-Red Difference Index (NGRDI). analysis computes indexes also segments plots based GLI index, allowing remotion soil effects. soil removed, canopy coverage within plot can computed ration area covered plants plot area. , visualized interactive map. following steps guide loading orthomosaic corresponding shapefile, calculating vegetation indexes, visualizing segmented canopy coverage.","code":"# Define the base URL for the example dataset url <- \"https://github.com/TiagoOlivoto/images/raw/refs/heads/master/pliman/ortho/\"  # Load the orthomosaic and shapefile mosaic <- mosaic_input(paste0(url, \"orthomosaic.tif\"), info = FALSE) shp <- shapefile_input(paste0(url, \"orthomosaic.rds\"), info = FALSE)  # Visualize the mosaic and overlay the shapefile for plot boundaries bm <- mosaic_view(mosaic, r = 1, g = 2, b = 3) # RGB visualization of the mosaic #> ℹ Using `downsample = 4` to match the max_pixels #> constraint. bm + shapefile_view(shp)                       # Overlay the shapefile on the mosaic # Compute the Green Leaf Index (GLI) for the mosaic to highlight vegetation ind <- mosaic_index(mosaic, index = \"GLI\", r = 1, g = 2, b = 3) # Segment the mosaic based on the GLI index to distinguish soil and plants seg <- mosaic_segment(   mosaic = mosaic,   index = \"GLI\",  # Use GLI for segmentation   r = 1,          # Red channel   g = 2,          # Green channel   b = 3           # Blue channel )  # Plot the segmented mosaic, showing the separation of plants and soil mosaic_plot(seg) # Perform further analysis using mosaic_analyze # - This calculates both GLI and NGRDI for each plot # - Segments the plots based on the GLI index # - Calculates canopy coverage within each plot res <- mosaic_analyze(   mosaic = mosaic,                 # The orthomosaic image   shapefile = shp,                 # The shapefile with plot boundaries   basemap = bm,                    # Basemap (not mandatory)   plot_index = c(\"GLI\", \"NGRDI\"),  # Vegetation indexes to calculate   segment_plot = TRUE,             # Segment plots using the index   segment_index = \"GLI\",           # GLI is used for segmentation   attribute = \"coverage\"           # Calculate canopy coverage ) #> ── Analyzing the mosaic ──────────────────── Started on 2025-08-23 | 16:09:04 ── #> ℹ Cropping the mosaic to the shapefile extent...✔ Cropping the mosaic to the shapefile extent [1.9s] #> ℹ Computing vegetation indexes...✔ Computing vegetation indexes [2.7s] #>  #> ── Analyzing block 1 ── #>  #> ℹ Masking vegetation from ground...✔ Vegetation masking completed [4.5s] #> ℹ Extracting plot-level features...✔ Extracting plot-level features [1.3s] #> ℹ Binding the extracted features...✔ Binding the extracted features [26ms] #> ℹ Summarizing the results...                             ── Mosaic successfully analyzed ─────────── Finished on 2025-08-23 | 16:09:17 ── #> ℹ Summarizing the results...✔ Summarizing the results [2.3s]  # Display the interactive map showing the plot segmentation # Color shows the canopy coverage res$map_plot # create a plot to shows the NGRDI index # bm + shapefile_view(res$result_plot, attribute = \"mean.NGRDI\")"},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"multispectral-indexes","dir":"Articles","previous_headings":"","what":"Multispectral Indexes","title":"High Throughput Phenotyping","text":"example, use multispectral orthomosaic compute important vegetation indexes Normalized Difference Vegetation Index (NDVI), Enhanced Vegetation Index (EVI), Normalized Difference Red Edge Index (NDRE). can see complete list multispectral indexes available pliman details. indexes valuable assessing plant health, canopy coverage, agronomic insights. can download orthomosaic shapefile reproduce analysis following steps . process involves loading multispectral mosaic shapefile, calculating vegetation indexes, segmenting plots based NDVI index. Additionally, interactive map display segmented plots canopy coverage metrics.","code":"# Define the base URL for the example dataset url <- \"https://github.com/TiagoOlivoto/images/raw/refs/heads/master/pliman/wheat/\"  # Load the orthomosaic and shapefile mosaic <- mosaic_input(paste0(url, \"wheat.tif\"), info = FALSE) shp <- shapefile_input(paste0(url, \"wheat.rds\"), info = FALSE) # Generate a basemap bm <- mosaic_view(mosaic, r = 3, g = 2, b = 1) #> ℹ Using `downsample = 2` to match the max_pixels #> constraint.  # - Computes three vegetation indexes: NDVI, EVI, and NDRE ind <- mosaic_index(   mosaic = mosaic,   index = c(\"NDVI\", \"TVI\", \"NDRE\"),   b = 1,   g = 2,   r = 3,   re = 4,   nir = 5,   plot = FALSE ) #> ── Computing rasters for 3 indices ──────────────────── Started at \"16:09:29\" ── #> ■■■■■■■■■■■                      1/3 | ETA:  3s■■■■■■■■■■■■■■■■■■■■■            2/3 | ETA:  1s■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  3/3 | ETA:  0s #> ── 3 vegetation indices computed ─────────── Ended at \"2025-08-23 | 16:09:33\" ── # NDVI mosaic_plot(ind[[1]]) shapefile_plot(shp, lwd = 3, add = TRUE) # EVI and NDRE mosaic_plot(c(ind[[2]], ind[[3]])) # - Here, I declared the orthomosaic and the bult indexes # - The basemap will be needed if `plot = TRUE` (default). If not provided, it will be rendered # - Declare summary statistics res <- mosaic_analyze(   mosaic = mosaic,                          # The orthomosaic image   indexes = ind,                            # we can also declare a raster with computed indexes   basemap = bm,                             # Use the visualized mosaic as the base map   shapefile = shp,                          # The shapefile with plot boundaries   summarize_fun = c(\"min\", \"median\", \"max\"), # Calculate min, mean, max for the indexes   attribute = \"median.NDVI\" ) #> ── Analyzing the mosaic ──────────────────── Started on 2025-08-23 | 16:09:35 ── #> ℹ Cropping the mosaic to the shapefile extent... #> Warning: ! ``segment_plot`` must have length 1 or 2 (the #> number of drawn polygons). #> Warning: ! ``segment_individuals`` must have length 1 or 2 (the number of drawn #>   polygons). #> Warning: ! ``threshold`` must have length 1 or 2 (the #> number of drawn polygons). #> Warning: ! ``watershed`` must have length 1 or 2 (the #> number of drawn polygons). #> Warning: ! ``segment_index`` must have length 1 or 2 #> (the number of drawn polygons). #> Warning: ! ``invert`` must have length 1 or 2 (the #> number of drawn polygons). #> Warning: ! ``includeopt`` must have length 1 or 2 (the #> number of drawn polygons). #> Warning: ! ``opening`` must have length 1 or 2 (the #> number of drawn polygons). #> Warning: ! ``closing`` must have length 1 or 2 (the #> number of drawn polygons). #> Warning: ! ``filter`` must have length 1 or 2 (the #> number of drawn polygons). #> Warning: ! ``erode`` must have length 1 or 2 (the number #> of drawn polygons). #> Warning: ! ``dilate`` must have length 1 or 2 (the #> number of drawn polygons). #> Warning: ! ``grid`` must have length 1 or 2 (the number #> of drawn polygons). #> Warning: ! ``lower_noise`` must have length 1 or 2 (the #> number of drawn polygons). #> ✔ Cropping the mosaic to the shapefile extent [1.2s] #>  #> ── Analyzing block 1 ── #>  #> ℹ Extracting plot-level features...✔ Extracting plot-level features [242ms] #> ℹ Binding the extracted features...                                    ── Analyzing block 2 ── #> ℹ Binding the extracted features...                                     #> ℹ Binding the extracted features...✔ Binding the extracted features [161ms] #> ℹ Extracting plot-level features...✔ Extracting plot-level features [114ms] #> ℹ Binding the extracted features...✔ Binding the extracted features [35ms] #> ℹ Summarizing the results...                             ── Mosaic successfully analyzed ─────────── Finished on 2025-08-23 | 16:09:37 ── #> ℹ Summarizing the results...✔ Summarizing the results [202ms]  # Display the interactive map showing the segmented plots res$map_plot"},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"canopy-height-models","dir":"Articles","previous_headings":"","what":"Canopy Height Models","title":"High Throughput Phenotyping","text":"Canopy Height Model (CHM) represents height vegetation structures ground surface, making crucial tool analyzing vegetation structure biomass. derived subtracting Digital Terrain Model (DTM), shows bare earth surface, Digital Surface Model (DSM), captures elevation surface objects,like plants. comparing two models, CHM provides detailed insights height vegetation, enabling accurate assessments canopy cover plant growth agricultural forested landscapes.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"dsm-and-dtm-are-available","dir":"Articles","previous_headings":"Canopy Height Models","what":"DSM and DTM are available","title":"High Throughput Phenotyping","text":"","code":"# Load DSM, DTM, mask and shapefile url <- \"https://github.com/TiagoOlivoto/images/raw/refs/heads/master/pliman/dsm/\" dsm <- mosaic_input(paste0(paste0(url, \"dsm.tif\")), info = FALSE) dtm <- mosaic_input(paste0(paste0(url, \"dtm.tif\")), info = FALSE) msk <- mosaic_input(paste0(paste0(url, \"mask.tif\")), info = FALSE) shp <- shapefile_input(paste0(paste0(url, \"shapefile.rds\")), info = FALSE)  # Visualize the DSM and DTM side by side.  # The argument nc = 1 means that the plots will be displayed in a single column. mosaic_plot(c(dsm, dtm)) # Compute the Canopy Height Model (CHM) by subtracting the DTM from the DSM. # The `mask` parameter specifies the regions to be used, and `mask_soil = FALSE`  # means that areas identified by the mask are considered non-soil (i.e., representing the plants). res <- mosaic_chm(dsm = dsm,                   dtm = dtm,                   mask = msk,                   mask_soil = FALSE)   #> ── Canopy Height-Model generation ─────────────────── \"2025-08-23 | 16:09:48\" ── #> ℹ Building the canopy height model...✔ Building the canopy height model [1.8s]  # Extract canopy height values from the CHM using the provided shapefile. # This will associate the height values with the polygons in the shapefile. chmvals <- mosaic_chm_extract(res, shp)  # Visualize the DSM with a custom color palette to represent different elevation levels. pal <- custom_palette(c(\"#8B4513\", \"#B2DF8A\", \"forestgreen\"), n = 10) bm <- mosaic_view(dsm, color_regions = pal) #> ℹ Using `downsample = 2` to match the max_pixels constraint. #> Number of pixels is above 1e+06.Only about 1e+06 pixels will be shown. #> You can increase the value of `maxpixels` to 1000980 to avoid this.  # Overlay the shapefile on top of the DSM visualization, using the \"coverage\" attribute  # from the shapefile to define the regions of interest. bm + shapefile_view(chmvals, attribute = \"coverage\")"},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"building-dtm-from-dsm","dir":"Articles","previous_headings":"Canopy Height Models","what":"Building DTM from DSM","title":"High Throughput Phenotyping","text":"field experiments, Digital Terrain Model (DTM) frequently obtained sowing represents bare soil. , derivate DTM DSM? DTM provided, mosaic_chm() derive DTM DSM using interpolation strategy.","code":"# Interpolate DTM using a moving window res2 <- mosaic_chm(   dsm,   mask = msk,   window_size = c(4, 4),   mask_soil = FALSE ) #> ── Canopy Height-Model generation ─────────────────── \"2025-08-23 | 16:09:58\" ── #> ℹ Extracting ground points for each moving window...✔ Extracting ground points for each moving window [1.5s] #> ℹ Interpolating ground points...✔ Interpolating ground points [3.1s] #> ℹ Resampling and masking the interpolated raster...✔ Resampling and masking the interpolated raster [1.3s] #> ℹ Building the canopy height model...✔ Building the canopy height model [1.1s]  # Extract CHM values chmvals2 <- mosaic_chm_extract(res2, shp)   # Quantile 95 bm + shapefile_view(chmvals2, attribute = \"q95\") # Entropy # bm + shapefile_view(chmvals2, attribute = \"entropy\")"},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"counting-and-measuring-distance-between-plants","dir":"Articles","previous_headings":"","what":"Counting and measuring distance between plants","title":"High Throughput Phenotyping","text":"example, use RGB orthomosaic potato field analyze segment individual plants within plots. analysis involves loading mosaic corresponding shapefile, cropping mosaic area defined shapefile, segmenting individual plants using custom vegetation index. map_individuals = TRUE used, important metrics average distance plants coefficient variation cropping row also computed. interactive map shows segmented potato plants within row. Note plots rendered due absence identified plants. important highlight structure res object: map_individuals = TRUE used, result_individ_map object contains distances plant within plots. default, mapping occurs horizontal direction. objects means cvs hold average distances coefficients variation, respectively. , ’ll explore two contrasting plots demonstrate information can valuable assessing plot uniformity.","code":"# Download and load orthomosaic and shapefile url <- \"https://github.com/TiagoOlivoto/images/raw/refs/heads/master/pliman/potato/\" mos <-    mosaic_input(paste0(url, \"potato.tif\")) shp <- shapefile_input(paste0(url, \"potato.rds\"))  bm <- mosaic_view(mos)  res <-   mosaic_analyze(     mosaic = mos,     basemap = bm,     shapefile = shp,     plot_index = \"GLI\",     segment_individuals = TRUE,     map_individuals = TRUE,     map_direction = \"horizontal\",    # default     attribute = \"cv\"   )  pal <- c( \"#fde725\", \"#5ec962\", \"#21918c\", \"#3b528b\", \"#440154\") p1 <- shapefile_view(res$result_plot_summ, attribute = \"cv\", color_regions = pal) p2 <- shapefile_view(res$result_indiv, type = \"centroid\", attribute = \"area\")  (bm + p1) | p2 names(res) res[[\"result_individ_map\"]][[\"distances\"]][[\"B01_P0001\"]] library(patchwork) pmean <-   ggplot(res$result_plot_summ, aes(x = mean_distance)) +   geom_histogram() +   labs(x = \"Average distance between plants\",        y = \"Number of plots\")  pcv <-   ggplot(res$result_plot_summ, aes(x = cv)) +   geom_histogram(bins = 10) +   labs(x = \"Coefficient of variation (%)\",        y = \"Number of plots\")  pmean + pcv library(dplyr) par(mfrow = c(2, 1)) p1 <-    res$result_indiv |>    filter(plot_id == \"P0184\")  # plot  p1plot <-    res$result_plot_summ |>    filter(plot_id == \"P0184\")  plot1 <- mosaic_crop(mos, shapefile = p1plot, buffer = 0.2) coords <- p1[, c(\"x\", \"y\")] |> sf::st_drop_geometry() |> arrange(x) mosaic_plot_rgb(plot1, main = \"P0184: Average distance: 0.243 m; CV: 14.1%\") lines(coords, lwd = 2) shapefile_plot(p1plot, add = TRUE, border = \"blue\", lwd = 3) points(p1$x, p1$y, pch = 16,  cex = 2, col = \"red\")     p2 <-    res$result_indiv |>    filter(plot_id == \"P0204\") p2plot <-    res$result_plot_summ |>    filter(plot_id == \"P0204\")  plot2 <- mosaic_crop(mos, shapefile = p2plot, buffer = 0.2) coords2 <- p2[, c(\"x\", \"y\")] |> sf::st_drop_geometry() |> arrange(x) mosaic_plot_rgb(plot2, main = \"P0204: Average distance: 0.325 m; CV: 64.0%\") lines(coords2, lwd = 2) shapefile_plot(p2plot, add = TRUE, border = \"blue\", lwd = 3) points(p2$x, p2$y, pch = 16,  cex = 2, col = \"red\")"},{"path":[]},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"challenges","dir":"Articles","previous_headings":"Handling complex backgrounds","what":"Challenges","title":"High Throughput Phenotyping","text":"Threshold-based methods often struggle complex backgrounds typical field experiments, diverse soil types, colors, textures introduce considerable variability. variability reduces contrast plants soil, complicating computation vegetation indexes orthomosaics. soil plant pixels similar reflectance values, thresholding fails separate accurately, leading erroneous plant segmentation, turn affects vegetation index calculations, plant measurements, analytical outputs. instance, section, use orthomosaic field complex soil backgrounds, generously provided Lucas Côrredo-UFV, illustrate limitations threshold-based segmentation can overcome using simple alternatives based complex machine learning-based methods. take closer look orthomosaic, ’ll notice soil background complex, varying colors textures make challenging separate plants. complexity poses significant challenge threshold-based segmentation methods, rely clear distinctions plants soil accurately identify measure vegetation indexes. Early material ’ve seen GLI index good option segment plants soil. However, case, segmentation using threshold-based methods may effective due complex background. segmentation results indicate threshold-based method struggles distinguish plants soil, resulting inaccurate plant identification measurements. challenge highlights need alternative methods capable handling complex backgrounds effectively.","code":"url <- \"https://github.com/TiagoOlivoto/images/raw/refs/heads/master/pliman/citrus/\" mosaic <-    mosaic_input(paste0(url, \"citrus_mos.tif\"), info = FALSE) shp <- shapefile_input(paste0(url, \"citrus_shp.rds\"), info = FALSE) bm <- mosaic_view(mosaic, r = 1, g = 2, b = 3, max_pixels = 5e6) #> ℹ The number of pixels is very high, which might slow the rendering process. #> ℹ Using `downsample = 3` to match the max_pixels constraint. bm seg <- mosaic_segment(mosaic, index = \"GLI\", r = 1, g = 2, b = 3) mosaic_plot(seg)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"when-vegetation-indexes-are-insufficient","dir":"Articles","previous_headings":"Handling complex backgrounds","what":"When vegetation indexes are insufficient","title":"High Throughput Phenotyping","text":"Threshold-based methods often fail distinguish plants soil, making necessary explore strategies beyond vegetation indexes. robust approach involves using machine learning, particularly deep learning models, enhance plant segmentation analysis orthomosaics. models can identify intricate patterns features, offering superior differentiation plants soil compared traditional methods. However, models yet integrated pliman 3.0. , can enhance segmentation simpler approaches? solution lies leveraging 3D perspective Canopy Height Model (CHM).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"do-we-really-need-ai-based-models","dir":"Articles","previous_headings":"Handling complex backgrounds","what":"Do we really need AI-based models?","title":"High Throughput Phenotyping","text":"improve plant segmentation, incorporating digital surface model (DSM) can highly effective, provides valuable height information objects within orthomosaic. mosaic_chm_mask() function allows generating mask Canopy Height Model (CHM) derived using mosaic_chm() function. mask enables segmentation based plant height instead relying solely color, can precisely distinguish plants soil, particularly complex backgrounds. method offers straightforward, non-AI solution overcoming segmentation challenges, delivering enhanced plant isolation without need machine learning algorithms, mainly examples like , orange trees relatively tall, facilitating separation plants soil.  Great advance! Now, mask retains pixels 0.5 3 meters height, effectively isolating plants soil. mask can now used mosaic_analyze() segment plants calculate vegetation indexes accurately. identified plants displayed map, color-coded mean NGRDI (Normalized Green-Red Difference Index) values. Thias visualization highlights plant distribution relative health across field, making easier identify variations vegetation index values assess plant vigor. results show CHM-based segmentation method effectively isolates plants soil, providing accurate plant identification measurements. approach offers simple yet powerful alternative threshold-based methods, demonstrating value leveraging 3D information enhance plant segmentation orthomosaics. , explore individual plant data gain deeper insights plant health across field.","code":"dsm <- mosaic_input(paste0(url, \"citrus_dsm.tif\"), info = FALSE) # create a mask, retaining only pixels between 1 and 5 meters  mask <- mosaic_chm_mask(   dsm = dsm,   window_size = c(3, 3),  # Window size for interpolating the DTM   lower = 0.5,            # Lower limit for the mask (height)   upper = 3               # Upper limit for the mask (height) )  mosaic_plot(mask) # Analyze the segmented mosaic data mos <- mosaic_analyze(   mosaic = mosaic,                # The input mosaic   basemap = bm,                   # The basemap for visualization.   r = 1, g = 2, b = 3,            # Specify the red, green, and blue channels   mask = mask,                    # Apply the mask created previously   # dsm = dsm,                    # or directly use the DSM   # dsm_lower = 0.5,              # or directly use the DSM   # dsm_upper = 3,                # or directly use the DSM   #dsm_window_size = c(3, 3)      # or directly use the DSM   shapefile = shp,                # Shapefile to outline regions of interest   segment_individuals = TRUE,     # Enable segmentation   plot_index = c(\"NGRDI\", \"GLI\"), # Vegetation indexes to compute for each plant   lower_noise = 0,                # Avoid removing small plants   filter = 10,                    # Size of the filter applied to reduce noise   watershed = FALSE               # Disable watershed algorithm ) #> ── Analyzing the mosaic ──────────────────── Started on 2025-08-23 | 16:11:01 ── #> ℹ Cropping the mosaic to the shapefile extent...✔ Cropping the mosaic to the shapefile extent [26ms] #> ℹ Computing vegetation indexes...✔ Computing vegetation indexes [9.9s] #>  #> ── Analyzing block 1 ── #>  #> ℹ Segmenting individuals...✔ Segmenting individuals [20.1s] #> ℹ Extracting plant-level features...✔ Extracting plant-level features [2.2s] #> ℹ Extracting plot-level features...✔ Extracting plot-level features [1.9s] #> ℹ Binding the extracted features...✔ Binding the extracted features [16ms] #> ℹ Summarizing the results...                             ── Mosaic successfully analyzed ─────────── Finished on 2025-08-23 | 16:11:38 ── #> ℹ Summarizing the results...✔ Summarizing the results [2s]  # Summary mos$result_plot_summ #> Simple feature collection with 1 feature and 18 fields #> Geometry type: POLYGON #> Dimension:     XY #> Bounding box:  xmin: 723911.2 ymin: 7702727 xmax: 723974.3 ymax: 7702835 #> Projected CRS: WGS 84 / UTM zone 23S #> # A tibble: 1 × 19 #>   block plot_id   row column     n area_sum  area coverage perimeter length #>   <chr> <chr>   <dbl>  <dbl> <dbl>    <dbl> <dbl>    <dbl>     <dbl>  <dbl> #> 1 B01   P0001       1      1   223    4120.  18.5     1.46      5.47   1.43 #> # ℹ 9 more variables: width <dbl>, diam_min <dbl>, diam_mean <dbl>, #> #   diam_max <dbl>, mean.NGRDI <dbl>, mean.GLI <dbl>, individual <chr>, #> #   plot_area [m^2], geometry <POLYGON [m]> bm +   shapefile_view(mos$result_indiv[-1, ],                  attribute = \"diam_mean\",                  alpha.regions = 0.6) coords <- shapefile_measures(mos$result_indiv[-1, ]) model <- shapefile_interpolate(coords, z = \"mean.NGRDI\") mosaic_plot_rgb(mosaic)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/htp.html","id":"vectorizing-field-masks","dir":"Articles","previous_headings":"Handling complex backgrounds","what":"Vectorizing field masks","title":"High Throughput Phenotyping","text":"section, use another orthomosaic citrus field provided Lucas Côrredo-UFV. dataset includes RGB multispectral indices, well mask derived digital surface model, enhancing ability differentiate features field.   section, take different approach previous example, using mask file create sf object allows vegetation index extraction individual level. Specifically, vectorize raster mask using mosaic_vectorize() function. mosaic_vectorize() function converts raster mask (SpatRaster object) vectorized sf object, customizable options morphological operations filtering enhance object detection segmentation. function includes option watershed segmentation, , enabled, applies watershed-based segmentation distinguish touching objects, like needed case. Morphological operations (opening, closing, filter, erode, dilate) allow customization, helping refine mask removing noise, filling small gaps, smoothing object edges. lower_size upper_size arguments allow size-based filtering, topn_lower topn_upper select objects based area. settings, mosaic_vectorize() enables vectorization tailored individual vegetation elements, optimizing extraction vegetation indices plant level. Let’s vectorize binary mask using filter = 10 remove noises erode = 10 erode 10 pixels edges object avoid edge effects shapefile representing individual plants, can now extract vegetation indices plant level. Instead applying mosaic_analyze(), ’ll use mosaic_index() compute specific multispectral indices.","code":"url <- \"https://github.com/TiagoOlivoto/images/raw/refs/heads/master/pliman/multispec/\" rgb <- mosaic_input(paste0(url, \"citrus_rgb.tif\"), info = FALSE) mes <- mosaic_input(paste0(url, \"citrus_ms.tif\"), info = FALSE) mask <- mosaic_input(paste0(url, \"citrus_mask.tif\"), info = FALSE)  mosaic_plot_rgb(rgb) mosaic_plot(mask) bm <- mosaic_view(rgb, r = 1, g = 2, b = 3) #> ℹ Using `downsample = 3` to match the max_pixels #> constraint.  # Vectorize the shapefile shp <- mosaic_vectorize(mask,                          filter = 10,                         erode = 15) bm + shapefile_view(shp) vind <-   mosaic_index(mes,                index = c(\"RDVI\", \"NDVI\"),                b = 1,                r = 2,                nir = 3,                re = 4,                g = NA) #> ── Computing rasters for 2 indices ──────────────────── Started at \"16:11:58\" ── #> ■■■■■■■■■■■■■■■■                 1/2 | ETA:  1s■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  2/2 | ETA:  0s #> ── 2 vegetation indices computed ─────────── Ended at \"2025-08-23 | 16:12:01\" ── results <- mosaic_extract(vind, shp) #>   |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |=================                                                     |  24%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  55%  |                                                                              |=======================================                               |  56%  |                                                                              |========================================                              |  57%  |                                                                              |=========================================                             |  58%  |                                                                              |=========================================                             |  59%  |                                                                              |==========================================                            |  60%  |                                                                              |==========================================                            |  61%  |                                                                              |===========================================                           |  61%  |                                                                              |===========================================                           |  62%  |                                                                              |============================================                          |  62%  |                                                                              |============================================                          |  63%  |                                                                              |=============================================                         |  64%  |                                                                              |=============================================                         |  65%  |                                                                              |==============================================                        |  65%  |                                                                              |==============================================                        |  66%  |                                                                              |===============================================                       |  66%  |                                                                              |===============================================                       |  67%  |                                                                              |===============================================                       |  68%  |                                                                              |================================================                      |  68%  |                                                                              |================================================                      |  69%  |                                                                              |=================================================                     |  70%  |                                                                              |==================================================                    |  71%  |                                                                              |==================================================                    |  72%  |                                                                              |===================================================                   |  72%  |                                                                              |===================================================                   |  73%  |                                                                              |====================================================                  |  74%  |                                                                              |====================================================                  |  75%  |                                                                              |=====================================================                 |  76%  |                                                                              |======================================================                |  77%  |                                                                              |======================================================                |  78%  |                                                                              |=======================================================               |  78%  |                                                                              |=======================================================               |  79%  |                                                                              |========================================================              |  80%  |                                                                              |=========================================================             |  81%  |                                                                              |=========================================================             |  82%  |                                                                              |==========================================================            |  82%  |                                                                              |==========================================================            |  83%  |                                                                              |==========================================================            |  84%  |                                                                              |===========================================================           |  84%  |                                                                              |===========================================================           |  85%  |                                                                              |============================================================          |  85%  |                                                                              |============================================================          |  86%  |                                                                              |=============================================================         |  87%  |                                                                              |=============================================================         |  88%  |                                                                              |==============================================================        |  88%  |                                                                              |==============================================================        |  89%  |                                                                              |===============================================================       |  89%  |                                                                              |===============================================================       |  90%  |                                                                              |================================================================      |  91%  |                                                                              |================================================================      |  92%  |                                                                              |=================================================================     |  93%  |                                                                              |==================================================================    |  94%  |                                                                              |==================================================================    |  95%  |                                                                              |===================================================================   |  95%  |                                                                              |===================================================================   |  96%  |                                                                              |====================================================================  |  97%  |                                                                              |===================================================================== |  98%  |                                                                              |===================================================================== |  99%  |                                                                              |======================================================================|  99%  |                                                                              |======================================================================| 100%  # overlay the shapefile to the basemap bm + shapefile_view(   results,   attribute = \"median.NDVI\" )"},{"path":"https://nepem-ufsc.github.io/pliman/articles/indexes.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting started","title":"Image indexes","text":"vignette, learn color space indexes provided package, focus RGB color space, HSB color space, CIE-Lab color space. Throughout vignette, delve underlying formulas methodologies used converting colors different color spaces, ensuring comprehensive understanding transformations work.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/articles/indexes.html","id":"rgb-color-space","dir":"Articles","previous_headings":"","what":"RGB Color Space","title":"Image indexes","text":"RGB (Red, Green, Blue) color space widely used color representation computer graphics digital imaging. pliman package, provide range indexes analyze manipulate color data within RGB color space:","code":""},{"path":[]},{"path":"https://nepem-ufsc.github.io/pliman/articles/indexes.html","id":"multispectral-vegetation-indexes","dir":"Articles","previous_headings":"RGB Color Space","what":"Multispectral vegetation indexes","title":"Image indexes","text":"{pliman} provides tools analyze 5 bands , generally B, G, R, RE (red-edge) NIR (near-infrared). following build-indexes available.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/articles/indexes.html","id":"hyperspectral-vegetation-indexes-indexes","dir":"Articles","previous_headings":"RGB Color Space","what":"Hyperspectral vegetation indexes indexes","title":"Image indexes","text":"Hyperspectral vegetation indexes mathematical combinations spectral reflectance values specific wavelengths, designed highlight particular vegetation properties chlorophyll content, biomass, plant stress. indexes utilize narrow bands electromagnetic spectrum, allowing precise assessment vegetation health physiological status. indexes listed adapted use (Wyvern Space), satellite-based hyperspectral imaging platform provides high-resolution spectral data. Usefull references Broadband greenness vegetation indexes Band Arithmetic function Index Database Comparison RGB Indices","code":""},{"path":"https://nepem-ufsc.github.io/pliman/articles/indexes.html","id":"hsb-color-space","dir":"Articles","previous_headings":"","what":"HSB Color Space","title":"Image indexes","text":"HSB (Hue, Saturation, Brightness) color space alternative color representation emphasizes perceptual aspects color.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/articles/indexes.html","id":"conversion-to-cie-lab","dir":"Articles","previous_headings":"HSB Color Space","what":"Conversion to CIE-Lab","title":"Image indexes","text":"rgb_to_hsb() function can used convert RGB HSB color space. conversion performed according described Karcher Richardson (2003). max (R,G,B) = R, H = 60 * (G - B) / (max(R,G,B) - min(R,G,B)) max (R,G,B) = G, H = 60 * (2 + (B - R) / (max(R,G,B) - min(R,G,B)) max (R,G,B) = B, H = 60 * (4 + (R - G) / (max(R,G,B) - min(R,G,B)) S = (max(R,G,B) - min(R,G,B)) / max(R,G,B) B = max(R,G,B)","code":""},{"path":[]},{"path":"https://nepem-ufsc.github.io/pliman/articles/indexes.html","id":"cie-lab-color-space","dir":"Articles","previous_headings":"","what":"CIE-Lab Color Space","title":"Image indexes","text":"CIE-Lab (CIELAB) color space color model approximates human vision often used color difference analysis color correction. pliman package, support conversion RGB Lab color space.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/articles/indexes.html","id":"conversion-to-cie-lab-1","dir":"Articles","previous_headings":"CIE-Lab Color Space","what":"Conversion to CIE-Lab","title":"Image indexes","text":"conversion RGB Lab performed rgb_to_lab() function pliman package. involves several steps, including transformation RGB sRGB, sRGB XYZ, XYZ Lab. understand specific formulas steps involved conversion, please refer detailed formulas.","code":""},{"path":[]},{"path":[]},{"path":"https://nepem-ufsc.github.io/pliman/articles/leaf_area.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting started","title":"Measure leaf area using leaf images","text":"can use analyze_objects() compute object features area, perimeter, radius, etc. can used, example, compute leaf area. Let’s compute leaf area leaves analyze_objects(). First, use image_segmentation() identify candidate indexes segment foreground (leaves) background.   B (Blue) NB (Normalized Blue) two possible candidates segment leaves background. use NB index (default option analyze_objects()). measurement leaf area approach can done two main ways: 1) using object known area, 2) knowing image resolution dpi (dots per inch).","code":"library(pliman) #> ╭ Welcome to pliman version \"3.1.0\"! ──────────────────────────────╮ #> │                                                                  │ #> │   Developed collaboratively by NEPEM <https://nepemufsc.com>     │ #> │   Group lead: Prof. Tiago Olivoto                                │ #> │   For citation, type `citation('pliman')`                        │ #> │   We welcome your feedback and suggestions!                      │ #> │                                                                  │ #> ╰────────────── Simplifying high-throughput plant phenotyping in R ╯ path <- \"https://raw.githubusercontent.com/TiagoOlivoto/images/master/pliman\" leaves <-    image_import(\"leaves2.jpg\",                path = path,                plot = TRUE) image_index(leaves)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/leaf_area.html","id":"using-an-object-of-known-area","dir":"Articles","previous_headings":"Getting started","what":"Using an object of known area","title":"Measure leaf area using leaf images","text":"Count number objects (leaves case) , use argument marker = \"id\" function analyze_objects() obtain identification object (leaf), allowing adjustment leaf area.  Note “holes” leaves resulted segmentation one leaf one object (e.g., 5, 8, 22, 25, 18, 28). affect total leaf area, area individual leaves average leaf area. can solved either setting argument fill_hull = TRUE watershed = FALSE (don’t implement watershed-based object segmentation). Let’s see much better can go.  Almost ! Due morphology leaf composed objects 2 23, segmented two objects. can solved setting argument object_size = \"large\" change default (medium) values tolerance extension arguments.  objects touching , argument watershed = FALSE better option.  ! Now, leaves identified correctly, measures given pixel units. next step convert measures metric units. Convert leaf area area known object function get_measures() used adjust leaf area using object 10, square side 5 cm (25 cm2^2).","code":"count <- analyze_objects(leaves, marker = \"id\") #> ℹ Processing a single image. Please, wait. #> ✔ Image Successfully analyzed! [759ms] count <-   analyze_objects(leaves,                   marker = \"id\",                   fill_hull = TRUE) #> ℹ Processing a single image. Please, wait. #> ✔ Image Successfully analyzed! [769ms] count <-   analyze_objects(leaves,                   marker = \"id\",                   fill_hull = TRUE,                   object_size = \"large\") #> ℹ Processing a single image. Please, wait. #> ✔ Image Successfully analyzed! [917ms] analyze_objects(leaves,                 watershed = FALSE) #> ℹ Processing a single image. Please, wait. #> ✔ Image Successfully analyzed! [381ms] area <-   get_measures(count,                id = 11,                area ~ 25) #> ----------------------------------------- #> measures corrected with: #> object id: 11 #> area     : 25 #> ----------------------------------------- #> Total    : 801.522  #> Average  : 36.433  #> ----------------------------------------- # plot the area to the segmented image image_segment(leaves, index = \"NB\", verbose = FALSE) plot_measures(area,               measure = \"area\",               col = \"red\") # default is \"white\""},{"path":"https://nepem-ufsc.github.io/pliman/articles/leaf_area.html","id":"knowing-the-image-resolution-in-dpi-dots-per-inch","dir":"Articles","previous_headings":"Getting started","what":"knowing the image resolution in dpi (dots per inch)","title":"Measure leaf area using leaf images","text":"image resolution known, measures pixels obtained analyze_objects() corrected image resolution. function dpi() can used compute dpi image, provided size object known. See dpi section details. case, estimated resolution considering calibration object 10 ~50.5 DPIs. inform value dpi argument get_measures().","code":"area2 <- get_measures(count, dpi = 50.5) plot(leaves) plot_measures(area2,               measure = \"area\",               vjust = -60,               col = \"gray\") # default is \"white\""},{"path":"https://nepem-ufsc.github.io/pliman/articles/leaf_area.html","id":"a-little-bit-more","dir":"Articles","previous_headings":"","what":"A little bit more!","title":"Measure leaf area using leaf images","text":"link find examples use {pliman} analyze plant images. Source code images can downloaded . can also find talk (Portuguese language) {pliman} . Lights, camera, {pliman}!","code":""},{"path":[]},{"path":"https://nepem-ufsc.github.io/pliman/articles/manipulation.html","id":"importing-images","dir":"Articles","previous_headings":"Image manipulation","what":"Importing images","title":"Image manipulation with pliman","text":"import list images, argument pattern function image_import() used. images match pattern name imported list.","code":"library(pliman) #> ╭ Welcome to pliman version \"3.1.0\"! ──────────────────────────────╮ #> │                                                                  │ #> │   Developed collaboratively by NEPEM <https://nepemufsc.com>     │ #> │   Group lead: Prof. Tiago Olivoto                                │ #> │   For citation, type `citation('pliman')`                        │ #> │   We welcome your feedback and suggestions!                      │ #> │                                                                  │ #> ╰────────────── Simplifying high-throughput plant phenotyping in R ╯ soy <- image_pliman(\"soybean_touch.jpg\") soy_list <-    image_import(pattern = \"sev_\",                path = image_pliman()) # choose path directory names(soy_list) #> [1] \"sev_back.jpg\"    \"sev_healthy.jpg\" \"sev_leaf.jpg\"    \"sev_leaf_nb.jpg\" #> [5] \"sev_sympt.jpg\""},{"path":"https://nepem-ufsc.github.io/pliman/articles/manipulation.html","id":"displaying-images","dir":"Articles","previous_headings":"Image manipulation","what":"Displaying images","title":"Image manipulation with pliman","text":"Single images displayed plot(). combining images, function image_combine() used. Users can inform either comma-separated list objects list objects class Image.","code":"# Single images plot(soy) # Combine images image_combine(soy, soy) # Combine images image_combine(soy_list, ncol = 5)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/manipulation.html","id":"manipulating-images","dir":"Articles","previous_headings":"Image manipulation","what":"Manipulating images","title":"Image manipulation with pliman","text":"pliman provides set image_*() functions perform image manipulation transformation unique images list images based EBImage package.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/articles/manipulation.html","id":"resize-an-image","dir":"Articles","previous_headings":"Image manipulation > Manipulating images","what":"Resize an image","title":"Image manipulation with pliman","text":"Sometimes resizing high-resolution images needed reduce processing time. function image_resize() used resize image. argument rel_size can used resize image relative size. example, setting rel_size = 50 image width 1280 x 720, new image size 640 x 360. useful speed time analysis computed analyze_objects() measure_disease().","code":"image_dimension(soy) #> ── Image dimension ───────────────────────────────────────────────────────────── #> Width : 825 #> Height: 648 soy_resized <- image_resize(soy, rel_size = 50) image_dimension(soy_resized) #> ── Image dimension ───────────────────────────────────────────────────────────── #> Width : 412 #> Height: 324"},{"path":"https://nepem-ufsc.github.io/pliman/articles/manipulation.html","id":"crop-an-image","dir":"Articles","previous_headings":"Image manipulation > Manipulating images","what":"Crop an image","title":"Image manipulation with pliman","text":"Cropping images useful remove noises image edge, well reduce size images processing. crop image, function image_crop() used. Users need inform numeric vector indicating pixel range (width height) maintained cropped image.  width height informed, image cropped vertically horizontally.  width height missing, iterative process image cropping performed. Additionally, automated cropping process can performed. case, image automatically cropped area objects edge five pixels default.  function image_trim() used trim pixels image edges.","code":"crop1 <-   image_crop(soy,              width = 55:750,              height = 20:623,              plot = TRUE) crop2 <-   image_crop(soy,              width = 55:750,              plot = TRUE) # only run in an iterative section image_crop(soy) auto_crop <- image_autocrop(soy, plot = TRUE) # trim 50 pixels from all edges soy_trim <- image_trim(soy, edge = 50, plot = TRUE) # The same is achieved with soy_trim2 <-   image_trim(soy,              top = 50,              bottom = 50,              left = 50,              right = 50,              plot = TRUE)  # trim 100 pixels from top and bottom soy_trim3 <-   image_trim(soy,              top = 100,              bottom = 100,              plot = TRUE) # trim to 5 pixels around objects' area"},{"path":"https://nepem-ufsc.github.io/pliman/articles/manipulation.html","id":"dpi","dir":"Articles","previous_headings":"Image manipulation > Manipulating images","what":"Image resolution (DPI)","title":"Image manipulation with pliman","text":"function dpi() runs interactive function compute image resolution given known distance informed user. compute image resolution (dpi) user must use left button mouse create line known distance. can done, example, using template known distance image (e.g., leaves.JPG).","code":"# only run in an interactive section leaves <- image_import(\"./data/leaf_area/leaves.JPG\") dpi(leaves)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/manipulation.html","id":"rotate-an-image","dir":"Articles","previous_headings":"Image manipulation > Manipulating images","what":"Rotate an image","title":"Image manipulation with pliman","text":"image_rotate() used rotates image clockwise given angle.","code":"soy_rotated <- image_rotate(soy, angle = 45, plot = TRUE)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/manipulation.html","id":"horizontal-and-vertical-reflection","dir":"Articles","previous_headings":"Image manipulation > Manipulating images","what":"Horizontal and vertical reflection","title":"Image manipulation with pliman","text":"image_hreflect() image_vreflect() performs vertical horizontal reflection images, respectively.","code":"soy_hrefl <- image_hreflect(soy) soy_vrefl <- image_vreflect(soy) image_combine(soy, soy_hrefl, soy_vrefl, ncol = 3)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/manipulation.html","id":"horizontal-and-vertical-conversion","dir":"Articles","previous_headings":"Image manipulation > Manipulating images","what":"Horizontal and vertical conversion","title":"Image manipulation with pliman","text":"image_horizontal() image_vertical() converts (needed) image horizontal vertical image, respectively.","code":"soy_h <- image_horizontal(soy) soy_v <- image_vertical(soy) image_combine(soy, soy_h, soy_v, ncol = 3)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/manipulation.html","id":"filter-blur-contrast-dilatation-and-erosion","dir":"Articles","previous_headings":"Image manipulation > Manipulating images","what":"Filter, blur, contrast, dilatation, and erosion","title":"Image manipulation with pliman","text":"","code":"soy_filter <- image_filter(soy) soy_blur <- image_blur(soy) soy_contrast <- image_contrast(soy) soy_dilatation <- image_dilate(soy) soy_erosion <- image_erode(soy) image_combine(soy, soy_filter, soy_blur, soy_contrast, soy_dilatation, soy_erosion)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/manipulation.html","id":"exporting-images","dir":"Articles","previous_headings":"Image manipulation > Manipulating images","what":"Exporting images","title":"Image manipulation with pliman","text":"export images current directory, use function image_export(). list images exported, images saved considering name extension present list. extension present, images saved *.jpg files.","code":"image_export(soy, \"exported.jpg\")"},{"path":"https://nepem-ufsc.github.io/pliman/articles/manipulation.html","id":"a-little-bit-more","dir":"Articles","previous_headings":"","what":"A little bit more!","title":"Image manipulation with pliman","text":"link find examples use {pliman} analyze plant images. Source code images can downloaded . can also find talk (Portuguese language) {pliman} . Lights, camera, {pliman}!","code":""},{"path":[]},{"path":"https://nepem-ufsc.github.io/pliman/articles/phytopatometry.html","id":"single-images","dir":"Articles","previous_headings":"","what":"Single images","title":"Phytopatometry in R with the package pliman","text":"","code":"library(pliman) #> ╭ Welcome to pliman version \"3.1.0\"! ──────────────────────────────╮ #> │                                                                  │ #> │   Developed collaboratively by NEPEM <https://nepemufsc.com>     │ #> │   Group lead: Prof. Tiago Olivoto                                │ #> │   For citation, type `citation('pliman')`                        │ #> │   We welcome your feedback and suggestions!                      │ #> │                                                                  │ #> ╰────────────── Simplifying high-throughput plant phenotyping in R ╯ # set the path directory path_soy <- \"https://raw.githubusercontent.com/TiagoOlivoto/images/master/pliman\" # import images img <- image_import(\"leaf.jpg\", path = path_soy) healthy <- image_import(\"healthy.jpg\", path = path_soy) symptoms <- image_import(\"sympt.jpg\", path = path_soy) background <- image_import(\"back.jpg\", path = path_soy) image_combine(img, healthy, symptoms, background, ncol = 4)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/phytopatometry.html","id":"image-palettes","dir":"Articles","previous_headings":"","what":"Image palettes","title":"Phytopatometry in R with the package pliman","text":"Sample palettes can created manually sampling small areas representative images producing composite image represents desired classes (background, healthy, symptomatic tissues). Another approach use image_palette() function generate sample color palettes.    Alternatively, users can create mask instead displaying original image.","code":"pals <- image_palette(img, npal = 8, return_pal = TRUE) #> ℹ Processing a single image. Please, wait. #> ✔ Image Successfully analyzed! [937ms]     image_combine(pals$palette_list, ncol = 4) # default settings res <-   measure_disease(img = img,                   img_healthy = healthy,                   img_symptoms = symptoms,                   img_background = background) #> ℹ Processing a single image. Please, wait. #> ✔ Image Successfully analyzed! [940ms]     res$severity #>    healthy symptomatic #> 1 89.41419    10.58581 # create a personalized mask res2 <-    measure_disease(img = img,                   img_healthy = healthy,                   img_symptoms = symptoms,                   img_background = background,                   show_original = FALSE, # create a mask                   show_contour = FALSE, # hide the contour line                   col_background = \"white\", # default                   col_lesions = \"red\", # default                   col_leaf = \"green\") # default #> ℹ Processing a single image. Please, wait. #> ✔ Image Successfully analyzed! [1.2s]        res2$severity #>    healthy symptomatic #> 1 89.12594    10.87406"},{"path":"https://nepem-ufsc.github.io/pliman/articles/phytopatometry.html","id":"variations-in-image-palettes","dir":"Articles","previous_headings":"","what":"Variations in image palettes","title":"Phytopatometry in R with the package pliman","text":"results may vary depending palettes chosen subjective due researcher’s experience. following example, present second variation color palettes, necrotic area assumed diseased tissue. Therefore, symptomatic area smaller previous example.","code":"# import images healthy2 <- image_import(\"healthy2.jpg\", path = path_soy) symptoms2 <- image_import(\"sympt2.jpg\", path = path_soy) background2 <- image_import(\"back2.jpg\", path = path_soy) image_combine(healthy2, symptoms2, background2, ncol = 3) res3 <-   measure_disease(img = img,                   img_healthy = healthy2,                   img_symptoms = symptoms2,                   img_background = background2) #> ℹ Processing a single image. Please, wait. #> ✔ Image Successfully analyzed! [920ms]     res3$severity #>    healthy symptomatic #> 1 93.70262    6.297382"},{"path":"https://nepem-ufsc.github.io/pliman/articles/phytopatometry.html","id":"lesion-features","dir":"Articles","previous_headings":"","what":"Lesion features","title":"Phytopatometry in R with the package pliman","text":"","code":"res4 <-   measure_disease(img = img,                   img_healthy = healthy,                   img_symptoms = symptoms,                   img_background = background,                   show_features = TRUE,                   marker = \"area\") #> ℹ Processing a single image. Please, wait. #> ✔ Image Successfully analyzed! [824ms]     res4$shape #>    id       mx       my area perimeter radius_mean radius_min radius_max #> 1   1 221.3165 113.4328 1031 199.61017   22.385350  0.5540181  39.303781 #> 2   2 189.7396 129.3218 1325 252.96551   20.485982  1.7037877  38.799639 #> 3   3 177.8770 213.1486 3732 477.54625   50.090770  1.0902575  94.465812 #> 4   4 209.8401 193.4394 1828 255.48023   23.996324  1.5966013  42.398981 #> 5   5 263.2815 192.5938  142  45.48528    6.358657  4.4175177   8.445866 #> 6   6 119.5743 201.5020  100  36.79899    5.228316  3.3866985   6.858005 #> 8   8 144.9601 260.6239   73  30.55635    4.455795  2.9165344   5.893080 #> 9   9 210.8900 328.2504  927 149.46804   18.429302  7.4482266  30.835115 #> 11 11 280.3464 323.9627  271  64.69848    9.081303  5.3468492  12.656433 #> 12 12 347.0344 334.8566  292  67.11270    9.362710  5.4703505  12.763533 #> 15 15 183.8025 384.5571 1873 192.19596   24.893179 12.8303409  38.668805 #> 16 16 333.2704 369.1409  154  47.04163    6.653785  4.2700345   9.079004 #> 17 17 249.6548 376.3188  148  47.45584    6.708013  3.3705340   9.715189 #> 19 19 172.3723 449.2197 2254 281.35029   28.651469 12.6030915  47.507444 #> 23 23 109.2006 464.1006  267  72.69848    8.948391  3.5339436  13.739762 #> 24 24 122.6708 492.3326  941 134.63961   17.881356  9.6681628  28.326603 #> 25 25 149.0925 520.2243 1291 164.53911   21.110835 11.0842927  32.910027 #>     radius_sd diam_mean  diam_min  diam_max  maj_axis  min_axis    length #> 1  11.2387019  44.77070  1.108036  78.60756 24.156267  6.570653  76.56860 #> 2   9.0009555  40.97196  3.407575  77.59928 19.673400 10.643388  66.44392 #> 3  25.4804934 100.18154  2.180515 188.93162 54.673996 12.943501 185.16314 #> 4  10.1528815  47.99265  3.193203  84.79796 22.384645 13.318187  73.96521 #> 5   1.2039912  12.71731  8.835035  16.89173  5.315765  3.686707  15.63089 #> 6   1.0354915  10.45663  6.773397  13.71601  4.183570  3.297236  12.95079 #> 8   0.8150592   8.91159  5.833069  11.78616  3.669126  2.651668  11.13429 #> 9   6.4491505  36.85860 14.896453  61.67023 17.899320  7.779947  60.30752 #> 11  2.0643425  18.16261 10.693698  25.31287  7.932278  4.871938  24.62782 #> 12  2.0362289  18.72542 10.940701  25.52707  8.065112  5.166262  25.00000 #> 15  7.4860986  49.78636 25.660682  77.33761 22.941735 12.208977  73.66650 #> 16  1.3897121  13.30757  8.540069  18.15801  5.608257  3.834645  17.24808 #> 17  1.7199164  13.41603  6.741068  19.43038  5.985572  3.472223  18.38034 #> 19  9.8999251  57.30294 25.206183  95.01489 26.392194 14.898455  87.42711 #> 23  2.8680352  17.89678  7.067887  27.47952  8.113634  4.726704  26.00297 #> 24  5.5775852  35.76271 19.336326  56.65321 16.806900  8.253155  54.07933 #> 25  6.0422992  42.22167 22.168585  65.82005 19.273430 10.509904  62.91489 #>        width #> 1  22.625870 #> 2  37.438748 #> 3  46.019408 #> 4  46.409925 #> 5  10.656511 #> 6   9.701347 #> 8   7.941107 #> 9  23.673758 #> 11 14.817363 #> 12 15.199658 #> 15 34.959699 #> 16 11.608204 #> 17 10.650662 #> 19 54.480476 #> 23 14.011945 #> 24 22.456618 #> 25 32.794445 res4$statistics #>        stat      value #> 1         n    17.0000 #> 2  min_area    73.0000 #> 3 mean_area   979.3529 #> 4  max_area  3732.0000 #> 5   sd_area  1002.9329 #> 6  sum_area 16649.0000"},{"path":"https://nepem-ufsc.github.io/pliman/articles/phytopatometry.html","id":"interactive-disease-measurements","dir":"Articles","previous_headings":"","what":"Interactive disease measurements","title":"Phytopatometry in R with the package pliman","text":"alternative approach measuring disease percentage available measure_disease_iter() function. function offers interactive interface empowers users manually select sample colors directly image. , provides highly customizable analysis method. One advantage using measure_disease_iter() ability utilize “mapview” viewer, enhances analysis process offering zoom-options. feature allows users closely examine specific areas image, enabling detailed inspection accurate disease measurement.","code":"img <- image_pliman(\"sev_leaf.jpg\", plot = TRUE) measure_disease_iter(img, viewer = \"mapview\")"},{"path":"https://nepem-ufsc.github.io/pliman/articles/phytopatometry.html","id":"a-little-bit-more","dir":"Articles","previous_headings":"","what":"A little bit more!","title":"Phytopatometry in R with the package pliman","text":"link find examples use {pliman} analyze plant images. Source code images can downloaded . can also find talk (Portuguese language) {pliman} . Lights, camera, {pliman}!","code":""},{"path":"https://nepem-ufsc.github.io/pliman/articles/polygons.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting started","title":"Analyzing polygons with pliman","text":"polygon plane figure described finite number straight-line segments connected form closed polygonal chain (Singer, 1993)1. Given , may conclude image objects can expressed polygons n vertices. pliman set useful functions (draw_*()) draw common shapes circles, squares, triangles, rectangles n-tagons. Another group poly_*() functions can used analyze polygons. Let’s start simple example, related area perimeter square.  Now, Let’s see happens start hexagon increase number sides 1000.  Note n→∞n \\\\infty, sum sides becomes circumference circle, given 2πr2\\pi r, area becomes πr2\\pi r^2. cool, pliman mainly designed analyze plant image analysis. , use polygons? Let’s see can use functions obtain useful information.","code":"library(pliman) #> ╭ Welcome to pliman version \"3.1.0\"! ──────────────────────────────╮ #> │                                                                  │ #> │   Developed collaboratively by NEPEM <https://nepemufsc.com>     │ #> │   Group lead: Prof. Tiago Olivoto                                │ #> │   For citation, type `citation('pliman')`                        │ #> │   We welcome your feedback and suggestions!                      │ #> │                                                                  │ #> ╰────────────── Simplifying high-throughput plant phenotyping in R ╯ square <- draw_square(side = 1) poly_area(square) #> [1] 1 poly_perimeter(square) #> [1] 3 shapes <- list(side6 <- draw_n_tagon(6, plot = FALSE),                side12 <- draw_n_tagon(12, plot = FALSE),                side24 <- draw_n_tagon(24, plot = FALSE),                side100 <- draw_n_tagon(100, plot = FALSE),                side500 <- draw_n_tagon(500, plot = FALSE),                side100 <- draw_n_tagon(1000, plot = FALSE)) plot_polygon(shapes, merge = FALSE) #> [[1]] #> NULL #>  #> [[2]] #> NULL #>  #> [[3]] #> NULL #>  #> [[4]] #> NULL #>  #> [[5]] #> NULL #>  #> [[6]] #> NULL  poly_area(shapes) #> [1] 2.598076 3.000000 3.105829 3.139526 3.141510 3.141572 poly_perimeter(shapes) #> [1] 5.000000 5.694019 6.004205 6.219330 6.270578 6.276892 link <- \"https://raw.githubusercontent.com/TiagoOlivoto/tiagoolivoto/master/static/tutorials/pliman_lca/imgs/leaves.jpg\" leaves <- image_import(link, plot = TRUE) cont <- object_contour(leaves, watershed = FALSE, index = \"HI\") # plotting the polygon plot_polygon(cont)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/polygons.html","id":"object-measures","dir":"Articles","previous_headings":"","what":"Object measures","title":"Analyzing polygons with pliman","text":"Nice! can use contour object obtain useful information related shape. reduce amount output, use five samples: 2, 4, 13, 24, 35.  current version pliman, able compute following measures. details, see Chen & Wang (2005)2, Claude (2008)3, Montero et al. 20094.","code":"cont <- cont[c(\"2\", \"4\", \"13\", \"24\", \"41\")] plot_polygon(cont)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/polygons.html","id":"area","dir":"Articles","previous_headings":"Object measures","what":"Area","title":"Analyzing polygons with pliman","text":"area shape computed using Shoelace Formula (Lee Lim, 2017)5, follows =12|∑=1n(xiyi+1−xi+1yi)| =\\frac{1}{2}\\left|\\sum_{=1}^{n}\\left(x_{} y_{+1}-x_{+1}y_{}\\right)\\right|","code":"poly_area(cont) #> [1] 45075.0 20793.5 15183.5  4144.0  1688.0"},{"path":"https://nepem-ufsc.github.io/pliman/articles/polygons.html","id":"perimeter","dir":"Articles","previous_headings":"Object measures","what":"Perimeter","title":"Analyzing polygons with pliman","text":"perimeter computed sum euclidean distance every point shape. distances can obtained poly_distpts().","code":"poly_perimeter(cont) #>         2         4        13        24        41  #> 1290.1413  630.7128  565.7422  291.5929  603.1543  # perimeter of a circle with radius equals to 2 circle <- draw_circle(radius = 2, plot = FALSE) poly_perimeter(circle) #> [1] 12.56635  # check the result 2*pi*2 #> [1] 12.56637"},{"path":"https://nepem-ufsc.github.io/pliman/articles/polygons.html","id":"radius","dir":"Articles","previous_headings":"Object measures","what":"Radius","title":"Analyzing polygons with pliman","text":"radius pixel object contour computed distance object centroid (also called ‘center mass’). distances can obtained poly_centdist(). average, maximum minimum radius can obtained.","code":"dists <- poly_centdist(cont)  # statistics for the radius mean_list(dists) #>         2         4        13        24        41  #> 119.55450  85.22870  72.13064  39.10193  73.70601 min_list(dists) #>         2         4        13        24        41  #> 68.938361 62.146291 48.670983 25.480450  2.638939 max_list(dists) #>         2         4        13        24        41  #> 171.20105 129.75938 108.46217  61.56336 147.04645 sd_list(dists) #>        2        4       13       24       41  #> 20.94407 16.84946 14.62283 10.26425 42.27660  # average radius of the circle above poly_centdist(circle) |> mean_list() #> [1] 1.999998"},{"path":"https://nepem-ufsc.github.io/pliman/articles/polygons.html","id":"length-and-width","dir":"Articles","previous_headings":"Object measures","what":"Length and width","title":"Analyzing polygons with pliman","text":"length width object computed poly_lw() difference maximum minimum x y coordinates object aligned poly_align().","code":"aligned <- poly_align(cont) # compute length and width poly_lw(cont) #>        length     width #> [1,] 314.3777 265.87632 #> [2,] 235.4453 138.61494 #> [3,] 186.3901 140.53457 #> [4,] 116.0408  56.15904 #> [5,] 292.2781  10.17229"},{"path":"https://nepem-ufsc.github.io/pliman/articles/polygons.html","id":"circularity-eccentricity-caliper-and-elongation","dir":"Articles","previous_headings":"Object measures","what":"Circularity, eccentricity, caliper, and elongation","title":"Analyzing polygons with pliman","text":"Circularity measure (Montero et al. 2009)6 also called shape compactness, roundness measure object. given C=P2/AC = P^2 / , PP perimeter AA area object. Since measure dependent scale, normalized circularity can used. case, assumed unity circle. measure invariant translation, rotation, scaling transformations, dimensionless. given : Cn=P2/4πACn = P^2 / 4 \\pi poly_circularity_haralick() computes Haralick’s circularity (CH). method based computation Euclidean distances object centroid boundary pixel. set distances, mean (mm) standard deviation (ss) computed. statistical parameters used ratio calculates circularity, CH, shape, CH=m/sdCH =  m/sd poly_convexity() Computes convexity shape using ratio perimeter convex hull perimeter polygon. poly_eccentricity() Computes eccentricity shape using ratio eigenvalues (inertia axes coordinates). poly_elongation() Computes elongation shape 1 - width / length poly_caliper() Computes caliper (Also called Feret’s diameter). Users can use function poly_measures() compute object measures single call. image resolution known, , measures can corrected get_measures(). image resolution can obtained using known distance image. example, white square side 5 cm. , using dpi() resolution can obtained. case, dpi ~50.","code":"poly_circularity(cont) #>         2         4        13        24        41  #>  36.92656  19.13091  21.07974  20.51796 215.51845 poly_circularity_norm(cont) #>          2          4         13         24         41  #> 0.34030714 0.65686211 0.59613497 0.61245704 0.05830763  # normalized circularity for different shapes draw_square(plot = FALSE) |> poly_circularity_norm() #> [1] 1.396263 draw_circle(plot = FALSE) |> poly_circularity_norm() #> [1] 0.9999967 poly_circularity_haralick(cont) #>        2        4       13       24       41  #> 5.708275 5.058245 4.932743 3.809527 1.743423 poly_convexity(cont) #>         2         4        13        24        41  #> 0.6435196 0.8850799 0.7579630 0.9099463 0.7222449 poly_eccentricity(cont) #>             [,1] #> [1,] 0.833397171 #> [2,] 0.421770889 #> [3,] 0.599180391 #> [4,] 0.297943286 #> [5,] 0.001438398 poly_elongation(cont) #>           [,1] #> [1,] 0.1542773 #> [2,] 0.4112648 #> [3,] 0.2460192 #> [4,] 0.5160407 #> [5,] 0.9651965 poly_caliper(cont) #>        2        4       13       24       41  #> 317.5106 229.5125 187.4807 115.1347 253.3338 (measures <- poly_measures(cont)) #>    id        x        y    area area_ch perimeter radius_mean radius_min #> 2   1 911.0558 190.1729 45075.0   57540 1290.1413   119.55450  68.938361 #> 4   2 689.1227 171.8705 20793.5   21924  630.7128    85.22870  62.146291 #> 13  3 870.4033 485.5803 15183.5   16554  565.7422    72.13064  48.670983 #> 24  4 846.2110 625.7005  4144.0    4433  291.5929    39.10193  25.480450 #> 41  5 472.9797 784.6601  1688.0    2167  603.1543    73.70601   2.638939 #>    radius_max radius_sd radius_ratio diam_mean   diam_min diam_max  caliper #> 2   171.20105  20.94407     2.483393 239.10899 137.876721 342.4021 314.3777 #> 4   129.75938  16.84946     2.087967 170.45741 124.292582 259.5188 235.4453 #> 13  108.46217  14.62283     2.228477 144.26129  97.341966 216.9243 186.3901 #> 24   61.56336  10.26425     2.416102  78.20386  50.960900 123.1267 116.0408 #> 41  147.04645  42.27660    55.721805 147.41202   5.277878 294.0929 292.2781 #>      length     width  solidity convexity elongation circularity #> 2  314.3777 265.87632 0.7833681 0.6435196  0.1542773    36.92656 #> 4  235.4453 138.61494 0.9484355 0.8850799  0.4112648    19.13091 #> 13 186.3901 140.53457 0.9172103 0.7579630  0.2460192    21.07974 #> 24 116.0408  56.15904 0.9348071 0.9099463  0.5160407    20.51796 #> 41 292.2781  10.17229 0.7789571 0.7222449  0.9651965   215.51845 #>    circularity_haralick circularity_norm eccentricity       pcv #> 2              5.708275       0.34030714  0.833397171 2.6693543 #> 4              5.058245       0.65686211  0.421770889 0.8422071 #> 13             4.932743       0.59613497  0.599180391 1.1910148 #> 24             3.809527       0.61245704  0.297943286 1.7042851 #> 41             1.743423       0.05830763  0.001438398 0.6421213 (measures_cor <- get_measures(measures, dpi = 50)) #>    id        x        y      area   area_ch perimeter radius_mean radius_min #> 2   1 911.0558 190.1729 116.32235 148.49003  65.53918     6.07337    3.50207 #> 4   2 689.1227 171.8705  53.66054  56.57795  32.04021     4.32962    3.15703 #> 13  3 870.4033 485.5803  39.18315  42.71991  28.73970     3.66424    2.47249 #> 24  4 846.2110 625.7005  10.69417  11.43998  14.81292     1.98638    1.29441 #> 41  5 472.9797 784.6600   4.35612   5.59225  30.64024     3.74427    0.13406 #>    radius_max radius_sd radius_ratio diam_mean diam_min diam_max  caliper #> 2     8.69701   1.06396      0.12616  12.14674  7.00414 17.39403 15.97039 #> 4     6.59178   0.85595      0.10607   8.65924  6.31406 13.18355 11.96062 #> 13    5.50988   0.74284      0.11321   7.32847  4.94497 11.01976  9.46862 #> 24    3.12742   0.52142      0.12274   3.97276  2.58881  6.25484  5.89487 #> 41    7.46996   2.14765      2.83067   7.48853  0.26812 14.93992 14.84773 #>      length    width solidity convexity elongation circularity #> 2  15.97039 13.50652  0.03980   0.64352    0.15428    36.92656 #> 4  11.96062  7.04164  0.04818   0.88508    0.41126    19.13091 #> 13  9.46862  7.13916  0.04659   0.75796    0.24602    21.07974 #> 24  5.89487  2.85288  0.04749   0.90995    0.51604    20.51796 #> 41 14.84773  0.51675  0.03957   0.72224    0.96520   215.51845 #>    circularity_haralick circularity_norm eccentricity     pcv     pcv #> 2               5.70828          0.34031      0.83340 2.66935 2.66935 #> 4               5.05825          0.65686      0.42177 0.84221 0.84221 #> 13              4.93274          0.59613      0.59918 1.19101 1.19101 #> 24              3.80953          0.61246      0.29794 1.70429 1.70429 #> 41              1.74342          0.05831      0.00144 0.64212 0.64212"},{"path":"https://nepem-ufsc.github.io/pliman/articles/polygons.html","id":"a-little-bit-more","dir":"Articles","previous_headings":"","what":"A little bit more!","title":"Analyzing polygons with pliman","text":"useful functions can used manipulate coordinates. following example, show features implemented pliman. Just simplicity, use object 2.","code":"o2 <- cont[[\"2\"]] plot_polygon(o2)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/polygons.html","id":"rotate-polygons","dir":"Articles","previous_headings":"A little bit more!","what":"Rotate polygons","title":"Analyzing polygons with pliman","text":"poly_rotate() can used rotate polygon coordinates angle (0-360 degrees) trigonometric direction (anti-clockwise).","code":"rot <- poly_rotate(o2, angle = 45)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/polygons.html","id":"flip-polygons","dir":"Articles","previous_headings":"A little bit more!","what":"Flip polygons","title":"Analyzing polygons with pliman","text":"poly_flip_x() poly_flip_y() can used flip shapes along x y axis, respectively.","code":"flip <- list(   fx = poly_flip_x(o2),   fy = poly_flip_y(o2) ) plot_polygon(flip, merge = FALSE, aspect_ratio = 1) #> $fx #> NULL #>  #> $fy #> NULL"},{"path":"https://nepem-ufsc.github.io/pliman/articles/polygons.html","id":"sample-points","dir":"Articles","previous_headings":"A little bit more!","what":"Sample points","title":"Analyzing polygons with pliman","text":"poly_sample() samples n coordinates among existing points, poly_sample_prop() samples proportion coordinates among existing.","code":"# sample 50 coordinates poly_sample(o2, n = 50) |> plot_polygon() # sample 10% of the coordinates poly_sample_prop(o2, prop = 0.1) |> plot_polygon()"},{"path":"https://nepem-ufsc.github.io/pliman/articles/polygons.html","id":"smooth-polygons","dir":"Articles","previous_headings":"A little bit more!","what":"Smooth polygons","title":"Analyzing polygons with pliman","text":"poly_smooth() smooths polygon contour combining sampling prop coordinate points interpolating using vertices vertices.","code":"smooths <-    list(     s1 <- poly_smooth(o2, prop = 0.2, plot = FALSE),     s2 <- poly_smooth(o2, prop = 0.1, plot = FALSE),     s1 <- poly_smooth(o2, prop = 0.05, plot = FALSE)   ) plot_polygon(smooths, merge = FALSE, ncol = 3) #> [[1]] #> NULL #>  #> [[2]] #> NULL #>  #> [[3]] #> NULL"},{"path":"https://nepem-ufsc.github.io/pliman/articles/polygons.html","id":"add-noise-to-a-polygon","dir":"Articles","previous_headings":"A little bit more!","what":"Add noise to a polygon","title":"Analyzing polygons with pliman","text":"poly_jitter() adds small amount noise set point coordinates. See base::jitter() details.","code":"poly_jitter(o2, noise_x = 5, noise_y = 5) |> plot_polygon()"},{"path":"https://nepem-ufsc.github.io/pliman/articles/polygons.html","id":"a-little-bit-more-1","dir":"Articles","previous_headings":"","what":"A little bit more!","title":"Analyzing polygons with pliman","text":"link find examples use {pliman} analyze plant images. Source code images can downloaded . can also find talk (Portuguese language) {pliman} . Lights, camera, {pliman}!","code":""},{"path":"https://nepem-ufsc.github.io/pliman/articles/segmentation.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting started","title":"Image segmentation with pliman","text":"Image segmentation process partitioning digital image multiple segments (sets pixels image objects). context plant image analysis, segmentation used simplify representation image something easier analyze. example, using count_objects() count crop grains, first grains need isolated (segmented) background. pliman following functions can used segment image. pliman following functions can used segment image. image_binary() produce binary (black white) image image_segment() produce segmented image (image objects white background). image_segment_iter() segment image iteratively. functions segment image based value image index, may one RGB bands operation bands. Internally, functions call image_index() compute indexes. following indexes currently available. , use argument index\" test segmentation based RGB normalized values. Users can also provide index explicitly providing formula. e.g., index = \"R-B\".   example, can see distribution RGB values (first row) normalized RGB values (second row). two peaks represent grains (smaller peak) blue background (larger peak). clearer difference peaks, better image segmentation.","code":"library(pliman) #> ╭ Welcome to pliman version \"3.1.0\"! ──────────────────────────────╮ #> │                                                                  │ #> │   Developed collaboratively by NEPEM <https://nepemufsc.com>     │ #> │   Group lead: Prof. Tiago Olivoto                                │ #> │   For citation, type `citation('pliman')`                        │ #> │   We welcome your feedback and suggestions!                      │ #> │                                                                  │ #> ╰────────────── Simplifying high-throughput plant phenotyping in R ╯ soy <- image_pliman(\"soybean_touch.jpg\") # Compute the indexes # Only show the first 6 to reduce the image size indexes <- image_index(soy, index = pliman_indexes_rgb()[1:6], plot = FALSE)  # Create a raster plot with the RGB values plot(indexes) # Create a density plot with the RGB values plot(indexes, type = \"density\")"},{"path":"https://nepem-ufsc.github.io/pliman/articles/segmentation.html","id":"segment-an-image","dir":"Articles","previous_headings":"Getting started","what":"Segment an image","title":"Image segmentation with pliman","text":"function image_segmentation() used segment images using image indexes. example, use indexes computed see image segmented. output function can used input function analyze_objects().   seems \"NB\" index provided better segmentation. \"R\" \"NR\" resulted inverted segmented image, .e., grains considered background remaining ‘selected’ image. circumvent problem, can use argument invert functions.","code":"segmented <- image_segment(soy, index = c(\"R, G, B, NR, NG, NB\")) plot(segmented$NB) image_segment(soy,               index = c(\"R, NR\"),               invert = TRUE)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/segmentation.html","id":"iterative-segmentation","dir":"Articles","previous_headings":"Getting started","what":"Iterative segmentation","title":"Image segmentation with pliman","text":"function image_segment_iter() provides iterative image segmentation, returning proportions segmented pixels. useful one segmentation procedure needed. Users can choose many segmentation perform, using argument nseg.  Using soybean sample leaf (), use function image_segment_iter segment diseased tissue healthy tissue. aim segment symptoms two classes, namely, necrosis (brown areas) chlorosis (yellow areas), compute percentage symptom class. \"VARI\" seems suitable index segment symptoms (necrosis chlorosis) healthy tissues. \"GLI\" can used segment necrosis chlorosis. Knowing , can now use image_segment_iter() explicitly indicating indexes, follows  can observed 30.28% original image characterized symptoms (necrosis chlorosis). (symptomatic area), 25.92% necrotic areas. 7.85% total area considered necrotic areas (30.288 ×\\times 0.2592 103464/1317600 ×\\times 100) 22.43% (30.28 - 7.85 (399075 - 103464) / 1317600 ×\\times 100) considered chlorotic areas. Users can use argument threshold controls segmentation made. default (threshold = \"Otsu\"), threshold value based Otsu’s method used reduce grayscale image binary image. numeric value informed, value used threshold. Inform non-numeric value different \"Otsu\" iteratively chosen threshold based raster plot showing pixel intensity index. image_segmentation_iter(), vector (allows mixed (numeric character) type) length nseg can used.  Users can set argument threshold specific case, depending aims segmentation.","code":"seg_iter <- image_pliman(\"sev_leaf_nb.jpg\", plot = TRUE) image_segment_iter(seg_iter,                    nseg = 2, # two segmentations                    index = c(\"VARI\", \"GLI\"),                    ncol = 3) #>      image  pixels   percent #> 1 original 1317600 100.00000 #> 2     seg1  397044  30.13388 #> 3     seg2  102621  25.84625 seg_iter1 <-   image_segment_iter(seg_iter,                      nseg = 2, # two segmentations                      index = c(\"VARI\", \"GLI\"),                      threshold = c(0, \"Otsu\"),                      ncol = 3,                      plot = FALSE) #>      image  pixels   percent #> 1 original 1317600 100.00000 #> 2     seg1  103605   7.86316 #> 3     seg2   82395  79.52802 seg_iter2 <-   image_segment_iter(seg_iter,                      nseg = 2, # two segmentations                      index = c(\"VARI\", \"GLI\"),                      threshold = c(0.5, \"Otsu\"),                      ncol = 3,                      plot = FALSE) #>      image  pixels   percent #> 1 original 1317600 100.00000 #> 2     seg1  321999  24.43830 #> 3     seg2  101175  31.42091  image_combine(seg_iter1$images$seg1,               seg_iter2$images$seg1)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/segmentation.html","id":"producing-a-binary-image","dir":"Articles","previous_headings":"","what":"Producing a binary image","title":"Image segmentation with pliman","text":"can also produce binary image image_binary(). Just curiosity, use indexes \"B\" (blue) \"NB\" (normalized blue). default, image_binary() rescales image 30% size original image speed computation time. Use argument resize = FALSE produce binary image original size.","code":"binary <- image_binary(soy) # original image size image_binary(soy,              index = c(\"B, NB\"),              resize = FALSE)"},{"path":"https://nepem-ufsc.github.io/pliman/articles/segmentation.html","id":"a-little-bit-more","dir":"Articles","previous_headings":"","what":"A little bit more!","title":"Image segmentation with pliman","text":"link find examples use {pliman} analyze plant images. Source code images can downloaded . can also find talk (Portuguese language) {pliman} . Lights, camera, {pliman}!","code":""},{"path":"https://nepem-ufsc.github.io/pliman/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Tiago Olivoto. Author, maintainer.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Olivoto T (2022). “Lights, camera, pliman! R package plant image analysis.” Methods Ecology Evolution, 13(4), 789-798. doi:10.1111/2041-210X.13803.","code":"@Article{,   title = {Lights, camera, pliman! An R package for plant image analysis},   author = {Tiago Olivoto},   year = {2022},   journal = {Methods in Ecology and Evolution},   volume = {13},   number = {4},   pages = {789-798},   doi = {10.1111/2041-210X.13803}, }"},{"path":[]},{"path":"https://nepem-ufsc.github.io/pliman/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://nepem-ufsc.github.io/pliman/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement [INSERT CONTACT METHOD]. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://nepem-ufsc.github.io/pliman/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/ code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https:// www.contributor-covenant.org/translations.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/index.html","id":"pliman-","dir":"","previous_headings":"","what":"pliman","title":"pliman","text":"pliman package offers tools single batch image manipulation analysis (Olivoto, 2022), including quantification leaf area, disease severity assessment (Olivoto et al., 2022), object counting, extraction image indexes, shape measurement, object landmark identification, Elliptical Fourier Analysis object outlines, detailed Claude (2008). package also provides comprehensive pipeline generating shapefiles complex layouts supports high-throughput phenotyping RGB, multispectral, hyperspectral orthomosaics. functionality facilitates field phenotyping using UAV- satellite-based imagery. pliman also provides useful functions image transformation, binarization, segmentation, resolution. Please visit Examples page pliman website detailed documentation function.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"pliman","text":"Install latest stable version pliman CRAN : development version pliman can installed GitHub using pak package: Note: Windows user, also first download install latest version Rtools.","code":"install.packages(\"pliman\") pak::pkg_install(\"nepem-ufsc/pliman\")"},{"path":"https://nepem-ufsc.github.io/pliman/index.html","id":"analyze-objects","dir":"","previous_headings":"","what":"Analyze objects","title":"pliman","text":"function analyze_objects() can used analyze objects leaves, grains, pods, pollen image. default, measures returned pixel units. Users can adjust object measures get_measures() provided image resolution (Dots Per Inch) known. Another option use reference object image. last case, argument reference must set TRUE. two options identify reference object: color, using arguments back_fore_index fore_ref_index size, using arguments reference_larger reference_smaller cases, reference_area must declared. Let’s see analyze image flax grains containing reference object (rectangle 2x3 cm). , ’ll identify reference object size; , final results case metric units (cm).","code":"library(pliman) img <- image_pliman(\"flax_grains.jpg\") flax <-    analyze_objects(img,                   index = \"GRAY\",                   reference = TRUE,                   reference_larger = TRUE,                   reference_area = 6,                   marker = \"point\",                   marker_size = 0.5,                   marker_col = \"red\", # default is white                   show_contour = FALSE) # default is TRUE # summary statistics flax$statistics #        stat        value # 1         n 2.680000e+02 # 2  min_area 3.606989e-02 # 3 mean_area 6.250403e-02 # 4  max_area 1.262446e-01 # 5   sd_area 8.047152e-03 # 6  sum_area 1.675108e+01 # 7  coverage 5.388462e-02"},{"path":[]},{"path":"https://nepem-ufsc.github.io/pliman/index.html","id":"using-image-indexes","dir":"","previous_headings":"","what":"Using image indexes","title":"pliman","text":"compute percentage symptomatic leaf area can use measure_disease() function can use image index segment entire leaf background separate diseased tissue healthy tissue. Alternatively, can provide color palette samples measure_disease() function. approach, function fits general linear model (binomial family) RGB values image. uses color palette samples segment lesions healthy leaf. following example, compute symptomatic area soybean leaf. proportion healthy symptomatic areas given proportion total leaf area segmenting leaf background (blue).","code":"img <- image_pliman(\"sev_leaf.jpg\") # Computes the symptomatic area sev <-    measure_disease(img = img,                   index_lb = \"B\", # to remove the background                   index_dh = \"NGRDI\", # to isolate the diseased area                   threshold = c(\"Otsu\", 0), # You can also use the Otsu algorithm in both indexes (default)                   plot = TRUE) sev$severity #    healthy symptomatic # 1 92.63213    7.367868"},{"path":"https://nepem-ufsc.github.io/pliman/index.html","id":"interactive-disease-measurements","dir":"","previous_headings":"","what":"Interactive disease measurements","title":"pliman","text":"alternative approach measuring disease percentage available measure_disease_iter() function. function offers interactive interface empowers users manually select sample colors directly image. , provides highly customizable analysis method. One advantage using measure_disease_iter() ability utilize “mapview” viewer, enhances analysis process offering zoom-options. feature allows users closely examine specific areas image, enabling detailed inspection accurate disease measurement.","code":"img <- image_pliman(\"sev_leaf.jpg\", plot = TRUE)  # works only in an interactive section measure_disease_iter(img, viewer = \"mapview\")"},{"path":"https://nepem-ufsc.github.io/pliman/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"pliman","text":"","code":"citation(\"pliman\") Please, support this project by citing it in your publications!    Olivoto T (2022). \"Lights, camera, pliman! An R package for plant   image analysis.\" _Methods in Ecology and Evolution_, *13*(4),   789-798. doi:10.1111/2041-210X.13803   <https://doi.org/10.1111/2041-210X.13803>.  Uma entrada BibTeX para usuários(as) de LaTeX é    @Article{,     title = {Lights, camera, pliman! An R package for plant image analysis},     author = {Tiago Olivoto},     year = {2022},     journal = {Methods in Ecology and Evolution},     volume = {13},     number = {4},     pages = {789-798},     doi = {10.1111/2041-210X.13803},   }"},{"path":"https://nepem-ufsc.github.io/pliman/index.html","id":"getting-help","dir":"","previous_headings":"","what":"Getting help","title":"pliman","text":"come across clear bugs using package, please consider filing minimal reproducible example github. help developers address issue promptly. Suggestions criticisms aimed improving quality usability package highly encouraged. feedback valuable making {pliman} even better!","code":""},{"path":"https://nepem-ufsc.github.io/pliman/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"pliman","text":"Please note pliman project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://nepem-ufsc.github.io/pliman/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyzes objects in an image — analyze_objects","title":"Analyzes objects in an image — analyze_objects","text":"analyze_objects() provides tools counting extracting object features (e.g., area, perimeter, radius, pixel intensity) image. See Details section. analyze_objects_iter() provides iterative section measure object features using object known area. plot.anal_obj() produces histogram R, G, B values argument object_index used function analyze_objects().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyzes objects in an image — analyze_objects","text":"","code":"analyze_objects(   img,   foreground = NULL,   background = NULL,   pick_palettes = FALSE,   segment_objects = TRUE,   viewer = get_pliman_viewer(),   reference = FALSE,   reference_area = NULL,   back_fore_index = \"R/(G/B)\",   fore_ref_index = \"B-R\",   reference_img = NULL,   reference_larger = FALSE,   reference_smaller = FALSE,   pattern = NULL,   parallel = FALSE,   workers = NULL,   watershed = TRUE,   veins = FALSE,   sigma_veins = 1,   ab_angles = FALSE,   ab_angles_percentiles = c(0.25, 0.75),   width_at = FALSE,   width_at_percentiles = c(0.05, 0.25, 0.5, 0.75, 0.95),   haralick = FALSE,   har_nbins = 32,   har_scales = 1,   har_band = 1,   smooth = FALSE,   pcv = FALSE,   pcv_niter = 100,   resize = FALSE,   trim = FALSE,   fill_hull = FALSE,   erode = FALSE,   dilate = FALSE,   opening = FALSE,   closing = FALSE,   filter = FALSE,   invert = FALSE,   object_size = \"medium\",   index = \"NB\",   r = 1,   g = 2,   b = 3,   re = 4,   nir = 5,   object_index = NULL,   pixel_level_index = FALSE,   return_mask = FALSE,   efourier = FALSE,   nharm = 10,   threshold = \"Otsu\",   k = 0.1,   windowsize = NULL,   tolerance = NULL,   extension = NULL,   lower_noise = 0.1,   lower_size = NULL,   upper_size = NULL,   topn_lower = NULL,   topn_upper = NULL,   lower_eccent = NULL,   upper_eccent = NULL,   lower_circ = NULL,   upper_circ = NULL,   randomize = TRUE,   nrows = 1000,   plot = TRUE,   show_original = TRUE,   show_chull = FALSE,   show_contour = TRUE,   show_bbox = FALSE,   contour_col = \"red\",   contour_size = 1,   show_lw = FALSE,   show_background = TRUE,   show_segmentation = FALSE,   col_foreground = NULL,   col_background = NULL,   marker = FALSE,   marker_col = NULL,   marker_size = NULL,   save_image = FALSE,   prefix = \"proc_\",   dir_original = NULL,   dir_processed = NULL,   verbose = TRUE )  # S3 method for class 'anal_obj' plot(   x,   which = \"measure\",   measure = \"area\",   type = c(\"density\", \"histogram\"),   ... )  # S3 method for class 'anal_obj_ls' plot(   x,   which = \"measure\",   measure = \"area\",   type = c(\"density\", \"histogram\"),   ... )  analyze_objects_iter(pattern, known_area, verbose = TRUE, ...)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyzes objects in an image — analyze_objects","text":"img image analyzed. foreground, background, reference_img color palette foregrond, background, reference object, respectively (optional). chacarceter used (eg., foreground = \"fore\"), function search current working directory valid image named \"fore\". pick_palettes Logical argument indicating wheater user needs pick color palettes foreground background image. TRUE pick_palette() called internally user can sample color points representing foreground background. segment_objects Segment objects image? Defaults TRUE. case, objects segmented using index defined index argument, object analyzed individually. segment_objects = FALSE used, objects segmented entire image analyzed. useful, example, analyzing image without background, object_index computed entire image, like index crop canopy. viewer viewer option. option controls type viewer use interactive plotting (eg., pick_palettes = TRUE).  provided, value retrieved using get_pliman_viewer(). reference Logical indicate reference object present image. useful adjust measures images obtained standard resolution (e.g., field images). See details section. reference_area known area reference objects. measures objects image corrected using unit area informed . back_fore_index character value indicate index segment foreground (objects reference) background. Defaults \"R/(G/B)\". index optimized segment white backgrounds green leaves blue reference object. fore_ref_index character value indicate index segment objects reference object. can either available index pliman (see pliman_indexes() index computed R, G, B bands. Defaults \"B-R\". index optimized segment green leaves blue reference object white background removed. reference_larger, reference_smaller Logical argument indicating larger/smaller object image must used reference object. valid reference set TRUE reference_area indicates area reference object. IMPORTANT. reference_smaller used, objects area smaller 1% mean objects ignored. used remove possible noise image dust. , sure reference object area removed cutpoint. pattern pattern file name used identify images imported. example, pattern = \"im\" images current working directory name matches pattern (e.g., img1.-, image1.-, im2.-) imported list. Providing number pattern (e.g., pattern = \"1\") select images named 1.-, 2.-, . error returned pattern matches file supported (e.g., img1.pdf). parallel TRUE processes images asynchronously (parallel) separate R sessions running background machine. may speed processing time, especially pattern used informed. object_index informed, multiple sections used extract RGB values object image. may significantly speed processing time image lots objects (say >1000). workers positive numeric scalar function specifying number parallel processes can active time. default, number sections set 30% available cores. watershed TRUE (default) performs watershed-based object detection. detect objects even touching one . FALSE, pixels connected set foreground pixels set unique object. faster able segment touching objects. veins Logical argument indicating whether vein features computed. call object_edge() applies Sobel-Feldman Operator detect edges. result proportion edges relation entire area object(s) image. Note OPERATION IMAGE LEVEL, OBJECT!. sigma_veins Gaussian kernel standard deviation used gaussian blur edge detection algorithm ab_angles Logical argument indicating whether apex base angles computed. Defaults FALSE. TRUE, poly_apex_base_angle() called base apex angles computed considering 25th 75th percentiles object height. percentiles can changed argument ab_angles_percentiles. ab_angles_percentiles percentiles indicating heights object angle computed (apex bottom). Defaults c(0.25, 0.75), means considering 25th 75th percentiles object height. width_at Logical. TRUE, widths object given set quantiles height computed. width_at_percentiles vector heights along vertical axis object width computed. default value c(0.05, 0.25, 0.5, 0.75, 0.95), means function return width 5th, 25th, 50th, 75th, 95th percentiles object's height. haralick Logical value indicating whether Haralick features computed. Defaults FALSE. har_nbins integer indicating number bins using compute Haralick matrix. Defaults 32. See Details har_scales integer vector indicating number scales use compute Haralick features. See Details. har_band band compute Haralick features (1 = R, 2 = G, 3 = B). Defaults 1. allowed value har_band = \"GRAY\". smooth whether object contours smoothed poly_smooth(). Defaults FALSE. smooth use numeric value indicating number interactions used smooth contours. pcv Computes Perimeter Complexity Value? Defaults FALSE. pcv_niter integer specifying number smoothing iterations computing  Perimeter Complexity Value. Defaults 100. resize Resize image processing? Defaults FALSE. Use numeric value range 0-100 (proportion size original image). trim Number pixels removed edges analysis. edges images often shaded, can affect image analysis. edges images can removed specifying number pixels. Defaults FALSE (trimmed edges). fill_hull Fill holes binary image? Defaults FALSE. useful fill holes objects portions color similar background. IMPORTANT: Objects touching can combined one single object, may underestimate number objects image. opening, closing, filter, erode, dilate Morphological operations (brush size) dilate puts mask every background pixel, sets foreground pixels covered mask foreground. erode puts mask every foreground pixel, sets background pixels covered mask background. opening performs erosion followed dilation. helps remove small objects preserving shape size larger objects. closing performs dilatation followed erosion. helps fill small holes preserving shape size larger objects. filter performs median filtering binary image. Provide positive integer > 1 indicate size median filtering. Higher values efficient remove noise background can dramatically impact perimeter objects, mainly irregular perimeters leaves serrated edges. invert Inverts binary image desired. useful process images black background. Defaults FALSE. reference = TRUE use, invert can declared logical vector length 2 (eg., invert = c(FALSE, TRUE). case, segmentation objects reference foreground using back_fore_index performed using default (inverted), segmentation objects reference performed inverting selection (selecting pixels higher threshold). object_size size object. Used automatically set tolerance extension parameters. One following. \"small\" (e.g, wheat grains), \"medium\" (e.g, soybean grains), \"large\"(e.g, peanut grains), \"elarge\" (e.g, soybean pods)`. index character value specifying target mode conversion binary image foreground background declared. Defaults \"NB\" (normalized blue). See image_index() details. User can also calculate index using bands names, e.g. index = \"R+B/G\" r, g, b, re, nir red, green, blue, red-edge, near-infrared bands image, respectively. Defaults 1, 2, 3, 4, 5, respectively. multispectral image provided (5 bands), check order bands, frequently presented 'BGR' format. object_index Defaults FALSE. index informed, average value object returned. can R, G, B values operation involving , e.g., object_index = \"R/B\". case, return object image, average value R/B ratio. Use pliman_indexes_eq() see equations available indexes. pixel_level_index Return indexes computed object_index pixel level? Defaults FALSE avoid returning large data.frames. return_mask Returns mask analyzed image? Defaults FALSE. efourier Logical argument indicating Elliptical Fourier computed object. call efourier() internally. efourier = TRUE used, standard normalized Fourier coefficients returned. nharm integer indicating number harmonics use. Defaults 10. details see efourier(). threshold theshold method used. default (threshold = \"Otsu\"), threshold value based Otsu's method used reduce grayscale image binary image. numeric value informed, value used threshold. threshold = \"adaptive\", adaptive thresholding (Shafait et al. 2008) used, depend k windowsize arguments. non-numeric value different \"Otsu\" \"adaptive\" used, iterative section allow choose threshold based raster plot showing pixel intensity index. k numeric range 0-1. k high, local threshold values tend lower. k low, local threshold value tend higher. windowsize windowsize controls number local neighborhood adaptive thresholding. default set 1/3 * minxy, minxy minimum dimension image (pixels). tolerance minimum height object units image intensity highest point (seed) point contacts another object (checked every contact pixel). height smaller tolerance, object combined one neighbors, highest. extension Radius neighborhood pixels detection neighboring objects. Higher value smooths small objects. lower_noise prevent noise affecting image analysis, objects lesser 10% mean area objects removed (lower_noise = 0.1). Increasing value remove larger noises (dust points), can remove desired objects . define explicit lower upper size, use lower_size upper_size arguments. lower_size, upper_size Lower upper limits size image analysis. Plant images often contain dirt dust.  Upper limit set NULL, .e., upper limit used. One can set known area use lower_size = 0 select objects (advised). Objects matches size given range sizes can selected setting two arguments. example, lower_size = 120 upper_size = 140, objects size greater equal 120 less equal 140 considered. topn_lower, topn_upper Select top n objects based area. topn_lower selects n elements smallest area whereas topn_upper selects n objects largest area. lower_eccent, upper_eccent, lower_circ, upper_circ Lower upper limit object eccentricity/circularity image analysis. Users may use arguments remove objects square papers scale (low eccentricity) cut petioles (high eccentricity) images. Defaults NULL (.e., lower upper limits). randomize Randomize lines training model? nrows number lines used training step. Defaults 2000. plot Show image processing? show_original Show count objects original image? show_chull Show convex hull around objects? Defaults FALSE. show_contour Show contour line around objects? Defaults TRUE. show_bbox Show bounding box around objects? Defaults FALSE. contour_col, contour_size color size contour line around objects. Defaults contour_col = \"red\" contour_size = 1. show_lw TRUE, plots length width lines object calling plot_lw(). show_background Show background? Defaults TRUE. white background shown default show_original = FALSE. show_segmentation Shows object segmentation colored random permutations. Defaults FALSE. col_foreground, col_background Foreground background color image processing. Defaults NULL, \"black\", \"white\" used, respectively. marker, marker_col, marker_size type, color size object marker. Defaults NULL, plots object id. Use marker = \"point\" show point object marker = FALSE omit object marker. save_image Save image processing? image saved current working directory named proc_* * image name given img. prefix prefix included processed images. Defaults \"proc_\". dir_original, dir_processed directory containing original processed images. Defaults NULL. case, function search image img current working directory. processing, save_image = TRUE, processed image also saved directory. can either full path, e.g., \"C:/Desktop/imgs\", subfolder within current working directory, e.g., \"/imgs\". verbose TRUE (default) summary shown console. x object class anal_obj. plot. Either 'measure' (object measures) 'index' (object index). Defaults \"measure\". measure measure plot. Defaults \"area\". type type plot. Either \"hist\" \"density\". Partial matches recognized. ... Depends function: analyze_objects_iter(), arguments passed analyze_objects(). known_area known area template object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyzes objects in an image — analyze_objects","text":"analyze_objects() returns list following objects: results data frame following variables object image: id:  object identification. x,y:  x y coordinates center mass object. area:  area object (pixels). area_ch:  area convex hull around object (pixels). perimeter: perimeter (pixels). radius_min, radius_mean, radius_max: minimum, mean, maximum radius (pixels), respectively. radius_sd: standard deviation mean radius (pixels). diam_min, diam_mean, diam_max: minimum, mean, maximum diameter (pixels), respectively. major_axis, minor_axis: elliptical fit major minor axes (pixels). caliper: longest distance two points margin object. See poly_caliper() details length, width length width objects (pixels). measures obtained range x y coordinates aligning object poly_align(). radius_ratio: radius ratio given radius_max / radius_min. theta: object angle (radians). eccentricity: elliptical eccentricity computed using ratio eigen values (inertia axes coordinates). form_factor (Wu et al., 2007):  difference leaf circle. defined 4*pi*/P, area P perimeter object. narrow_factor (Wu et al., 2007): Narrow factor (caliper / length). asp_ratio (Wu et al., 2007): Aspect ratio (length / width). rectangularity (Wu et al., 2007): similarity leaf rectangle (length * width/ area). pd_ratio (Wu et al., 2007): Ratio perimeter diameter (perimeter / caliper) plw_ratio (Wu et al., 2007): Perimeter ratio length width (perimeter / (length + width)) solidity: object solidity given area / area_ch. convexity: convexity object computed using ratio perimeter convex hull perimeter polygon. elongation: elongation object computed 1 - width / length. circularity: object circularity given perimeter ^ 2 / area. circularity_haralick: Haralick's circularity (CH), computed CH =  m/sd, m sd mean standard deviations pixels perimeter centroid object. circularity_norm: normalized circularity (Cn), unity circle. measure computed Cn = perimeter ^ 2 / 4*pi*area invariant translation, rotation, scaling transformations, dimensionless. asm: angular second-moment feature. con: contrast feature cor: Correlation measures linear dependency gray levels neighboring pixels. var: variance gray levels pixels. idm: Inverse Difference Moment (IDM), .e., local homogeneity. sav: Sum Average. sva: Sum Variance. sen: Sum Entropy. dva: Difference Variance. den: Difference Entropy f12: Difference Variance. f13: angular second-moment feature. statistics: data frame summary statistics area objects. count: pattern used, shows number objects image. obj_rgb: object_index used, returns R, G, B values pixel object. object_index: object_index used, returns index computed object. Elliptical Fourier Analysis: efourier = TRUE used, following objects returned. efourier: Fourier coefficients.  details see efourier(). efourier_norm: normalized Fourier coefficients. details see efourier_norm(). efourier_error: error original data  reconstructed outline. details see efourier_error(). efourier_power: spectrum harmonic Fourier power. details see efourier_power(). veins: veins = TRUE used, returns, image, proportion veins (fact object edges) related total object(s)' area. analyze_objects_iter() returns data.frame containing features described results object analyze_objects(). plot.anal_obj() returns trellis object containing distribution pixels, optionally  object facet = TRUE used.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Analyzes objects in an image — analyze_objects","text":"binary image first generated segment foreground background. argument index useful choose proper index segment image (see image_binary() details). also possible provide color palettes background foreground (arguments background foreground, respectively). used, general linear model (binomial family) fitted RGB values segment fore- background. , number objects  foreground counted. setting arguments lower_size upper_size, possible set threshold lower upper sizes objects, respectively. argument object_size can used set pre-defined values tolerance extension depending image resolution. influence watershed-based object segmentation. Users can also tune tolerance extension explicitly better precision watershed segmentation. watershed = FALSE used, pixels connected set foreground pixels img set unique object. faster, especially large number objects, able segment touching objects. ways correct measures based reference object. reference object known area (reference_area) used image reference = TRUE used, measures objects corrected, considering unit measure informed reference_area. two main ways work reference objects. first, provide reference object contrasting color background object interest. case, arguments back_fore_index fore_ref_index can used define index first segment reference object objects measured background, reference object objects measured. second one use reference object similar color objects measured, contrasting size. example, counting small brown grains, can use brown reference template area larger (says 3 times area grains) uses reference_larger = TRUE. , larger object image used reference object. particularly useful images captured background light, example  2. types: () suggested reference object much larger objects interest (mainly watershed = TRUE). cases, reference object can broken several pieces due watershed algorithm. (ii) Since reference object increase mean area object, argument lower_noise can increased. default (lower_noise = 0.1) objects lesser 10% mean area objects removed. Since mean area increased, increasing lower_noise remove dust noises reliably. argument reference_smaller can used way using pattern, possible process several images common pattern names stored current working directory subdirectory informed dir_original. speed computation time, one can set parallel = TRUE. analyze_objects_iter() can used process several images using object known area template. case, images current working directory match pattern processed. image, function compute features objects show identification (id) object. user needs inform id known object. , given known_area, measures adjusted. end, data.frame adjusted measures returned. useful images taken different heights. cases, image resolution conserved. Consequently, measures adjusted using argument dpi get_measures(), since image different resolution. NOTE: work interactive section. Additional measures: default, measures computed, mainly due computational efficiency user needs simple measures area, length, width. haralick = TRUE, function computes 13 Haralick texture features object based gray-level co-occurrence matrix (Haralick et al. 1979). Haralick features depend configuration parameters har_nbins har_scales. har_nbins controls number bins used compute Haralick matrix. smaller har_nbins can give accurate estimates correlation number events per bin higher. higher value give sensitivity. har_scales controls number scales used compute Haralick features. Since Haralick features compute correlation intensities neighboring pixels possible identify textures different scales, e.g., texture repeated every two pixels 10 pixels. default, Haralick features computed R band. chance default, use argument har_band. example, har_band = 2 compute features green band. Additionaly, har_band = \"GRAY\" can used. case, grayscale (0.299 * R + 0.587 * G + 0.114 * B) used. efourier = TRUE used, Elliptical Fourier Analysis (Kuhl Giardina, 1982) computed object contour using efourier(). veins = TRUE (experimental), vein features computed. call object_edge() applies Sobel-Feldman Operator detect edges. result proportion edges relation entire area object(s) image. Note OPERATION IMAGE LEVEL, OBJECT LEVEL! , vein features need computed leaves, strongly suggested use one leaf per image. ab_angles = TRUE apex base angles object computed poly_apex_base_angle(). default, function computes angle first pixel apex object two pixels slice object 25th percentile object height (apex angle). base angle computed way first base pixel. width_at = TRUE, width  5th, 25th, 50th, 75th, 95th percentiles object height computed default. quantiles can adjusted width_at_percentiles argument.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Analyzes objects in an image — analyze_objects","text":"Claude, J. (2008) Morphometrics R, Use R! series, Springer 316 pp. Gupta, S., Rosenthal, D. M., Stinchcombe, J. R., & Baucom, R. S. (2020). remarkable morphological diversity leaf shape sweet potato (Ipomoea batatas): influence genetics, environment, G×E. New Phytologist, 225(5), 2183–2195. doi:10.1111/NPH.16286 Haralick, R.M., K. Shanmugam, . Dinstein. 1973. Textural Features Image Classification. IEEE Transactions Systems, Man, Cybernetics SMC-3(6): 610–621. doi:10.1109/TSMC.1973.4309314 Kuhl, F. P., Giardina, C. R. (1982). Elliptic Fourier features closed contour. Computer Graphics Image Processing 18, 236-258. doi: doi:10.1016/0146-664X(82)90034-X Lee, Y., & Lim, W. (2017). Shoelace Formula: Connecting Area Polygon Vector Cross Product. Mathematics Teacher, 110(8), 631–636. doi:10.5951/mathteacher.110.8.0631 Montero, R. S., Bribiesca, E., Santiago, R., & Bribiesca, E. (2009). State Art Compactness Circularity Measures. International Mathematical Forum, 4(27), 1305–1335. Chen, C.H., P.S.P. Wang. 2005. Handbook Pattern Recognition Computer Vision. 3rd ed. World Scientific. Wu, S. G., Bao, F. S., Xu, E. Y., Wang, Y.-X., Chang, Y.-F., Xiang, Q.-L. (2007). Leaf Recognition Algorithm Plant Classification Using Probabilistic Neural Network. 2007 IEEE International Symposium Signal Processing Information Technology, 11–16. doi:10.1109/ISSPIT.2007.4458016","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Analyzes objects in an image — analyze_objects","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyzes objects in an image — analyze_objects","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"soybean_touch.jpg\") obj <- analyze_objects(img) obj$statistics  ########################### Example 1 ######################### # Enumerate the objects in the original image # Return the top-5 grains with the largest area top <-  analyze_objects(img,                  marker = \"id\",                  topn_upper = 5) top$results   #' ########################### Example 1 ######################### # Correct the measures based on the area of the largest ob ject # note that since the reference object  img <- image_pliman(\"flax_grains.jpg\") res <-   analyze_objects(img,                   index = \"GRAY\",                   marker = \"point\",                   show_contour = FALSE,                   reference = TRUE,                   reference_area = 6,                   reference_larger = TRUE,                   lower_noise = 0.3) }  if (interactive() && requireNamespace(\"EBImage\")) { library(pliman)  img <- image_pliman(\"soy_green.jpg\") # Segment the foreground (grains) using the normalized blue index (NB, default) # Shows the average value of the blue index in each object  rgb <-    analyze_objects(img,                    marker = \"id\",                    object_index = \"B\",                    pixel_level_index = TRUE) # density of area plot(rgb)  # histogram of perimeter plot(rgb, measure = \"perimeter\", type = \"histogram\") # or 'hist'  # density of the blue (B) index plot(rgb, which = \"index\") }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects_minimal.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyzes objects in an image — analyze_objects_minimal","title":"Analyzes objects in an image — analyze_objects_minimal","text":"lighter option analyze_objects()","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects_minimal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyzes objects in an image — analyze_objects_minimal","text":"","code":"analyze_objects_minimal(   img,   segment_objects = TRUE,   reference = FALSE,   reference_area = NULL,   back_fore_index = \"R/(G/B)\",   fore_ref_index = \"B-R\",   reference_larger = FALSE,   reference_smaller = FALSE,   pattern = NULL,   parallel = FALSE,   workers = NULL,   watershed = TRUE,   fill_hull = FALSE,   opening = FALSE,   closing = FALSE,   filter = FALSE,   erode = FALSE,   dilate = FALSE,   invert = FALSE,   object_size = \"medium\",   index = \"NB\",   r = 1,   g = 2,   b = 3,   re = 4,   nir = 5,   threshold = \"Otsu\",   tolerance = NULL,   extension = NULL,   lower_noise = 0.1,   lower_size = NULL,   upper_size = NULL,   topn_lower = NULL,   topn_upper = NULL,   lower_eccent = NULL,   upper_eccent = NULL,   lower_circ = NULL,   upper_circ = NULL,   plot = TRUE,   show_original = TRUE,   show_contour = TRUE,   contour_col = \"red\",   contour_size = 1,   col_foreground = NULL,   col_background = NULL,   marker = FALSE,   marker_col = NULL,   marker_size = NULL,   save_image = FALSE,   prefix = \"proc_\",   dir_original = NULL,   dir_processed = NULL,   verbose = TRUE )  # S3 method for class 'anal_obj_minimal' plot(   x,   which = \"measure\",   measure = \"area\",   type = c(\"density\", \"histogram\"),   ... )  # S3 method for class 'anal_obj_ls_minimal' plot(   x,   which = \"measure\",   measure = \"area\",   type = c(\"density\", \"histogram\"),   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects_minimal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyzes objects in an image — analyze_objects_minimal","text":"img image analyzed. segment_objects Segment objects image? Defaults TRUE. case, objects segmented using index defined index argument, object analyzed individually. segment_objects = FALSE used, objects segmented entire image analyzed. useful, example, analyzing image without background, object_index computed entire image, like index crop canopy. reference Logical indicate reference object present image. useful adjust measures images obtained standard resolution (e.g., field images). See details section. reference_area known area reference objects. measures objects image corrected using unit area informed . back_fore_index character value indicate index segment foreground (objects reference) background. Defaults \"R/(G/B)\". index optimized segment white backgrounds green leaves blue reference object. fore_ref_index character value indicate index segment objects reference object. can either available index pliman (see pliman_indexes() index computed R, G, B bands. Defaults \"B-R\". index optimized segment green leaves blue reference object white background removed. reference_larger, reference_smaller Logical argument indicating larger/smaller object image must used reference object. valid reference set TRUE reference_area indicates area reference object. IMPORTANT. reference_smaller used, objects area smaller 1% mean objects ignored. used remove possible noise image dust. , sure reference object area removed cutpoint. pattern pattern file name used identify images imported. example, pattern = \"im\" images current working directory name matches pattern (e.g., img1.-, image1.-, im2.-) imported list. Providing number pattern (e.g., pattern = \"1\") select images named 1.-, 2.-, . error returned pattern matches file supported (e.g., img1.pdf). parallel TRUE processes images asynchronously (parallel) separate R sessions running background machine. may speed processing time, especially pattern used informed. object_index informed, multiple sections used extract RGB values object image. may significantly speed processing time image lots objects (say >1000). workers positive numeric scalar function specifying number parallel processes can active time. default, number sections set 30% available cores. watershed TRUE (default) performs watershed-based object detection. detect objects even touching one . FALSE, pixels connected set foreground pixels set unique object. faster able segment touching objects. fill_hull Fill holes binary image? Defaults FALSE. useful fill holes objects portions color similar background. IMPORTANT: Objects touching can combined one single object, may underestimate number objects image. opening, closing, filter, erode, dilate Morphological operations (brush size) dilate puts mask every background pixel, sets foreground pixels covered mask foreground. erode puts mask every foreground pixel, sets background pixels covered mask background. opening performs erosion followed dilation. helps remove small objects preserving shape size larger objects. closing performs dilatation followed erosion. helps fill small holes preserving shape size larger objects. filter performs median filtering binary image. Provide positive integer > 1 indicate size median filtering. Higher values efficient remove noise background can dramatically impact perimeter objects, mainly irregular perimeters leaves serrated edges. invert Inverts binary image desired. useful process images black background. Defaults FALSE. reference = TRUE use, invert can declared logical vector length 2 (eg., invert = c(FALSE, TRUE). case, segmentation objects reference foreground using back_fore_index performed using default (inverted), segmentation objects reference performed inverting selection (selecting pixels higher threshold). object_size size object. Used automatically set tolerance extension parameters. One following. \"small\" (e.g, wheat grains), \"medium\" (e.g, soybean grains), \"large\"(e.g, peanut grains), \"elarge\" (e.g, soybean pods)`. index character value specifying target mode conversion binary image foreground background declared. Defaults \"NB\" (normalized blue). See image_index() details. User can also calculate index using bands names, e.g. index = \"R+B/G\" r, g, b, re, nir red, green, blue, red-edge, near-infrared bands image, respectively. Defaults 1, 2, 3, 4, 5, respectively. multispectral image provided (5 bands), check order bands, frequently presented 'BGR' format. threshold theshold method used. default (threshold = \"Otsu\"), threshold value based Otsu's method used reduce grayscale image binary image. numeric value informed, value used threshold. threshold = \"adaptive\", adaptive thresholding (Shafait et al. 2008) used, depend k windowsize arguments. non-numeric value different \"Otsu\" \"adaptive\" used, iterative section allow choose threshold based raster plot showing pixel intensity index. tolerance minimum height object units image intensity highest point (seed) point contacts another object (checked every contact pixel). height smaller tolerance, object combined one neighbors, highest. extension Radius neighborhood pixels detection neighboring objects. Higher value smooths small objects. lower_noise prevent noise affecting image analysis, objects lesser 10% mean area objects removed (lower_noise = 0.1). Increasing value remove larger noises (dust points), can remove desired objects . define explicit lower upper size, use lower_size upper_size arguments. lower_size, upper_size Lower upper limits size image analysis. Plant images often contain dirt dust.  Upper limit set NULL, .e., upper limit used. One can set known area use lower_size = 0 select objects (advised). Objects matches size given range sizes can selected setting two arguments. example, lower_size = 120 upper_size = 140, objects size greater equal 120 less equal 140 considered. topn_lower, topn_upper Select top n objects based area. topn_lower selects n elements smallest area whereas topn_upper selects n objects largest area. lower_eccent, upper_eccent, lower_circ, upper_circ Lower upper limit object eccentricity/circularity image analysis. Users may use arguments remove objects square papers scale (low eccentricity) cut petioles (high eccentricity) images. Defaults NULL (.e., lower upper limits). plot Show image processing? show_original Show count objects original image? show_contour Show contour line around objects? Defaults TRUE. contour_col, contour_size color size contour line around objects. Defaults contour_col = \"red\" contour_size = 1. col_foreground, col_background Foreground background color image processing. Defaults NULL, \"black\", \"white\" used, respectively. marker, marker_col, marker_size type, color size object marker. Defaults NULL, plots object id. Use marker = \"point\" show point object marker = FALSE omit object marker. save_image Save image processing? image saved current working directory named proc_* * image name given img. prefix prefix included processed images. Defaults \"proc_\". dir_original, dir_processed directory containing original processed images. Defaults NULL. case, function search image img current working directory. processing, save_image = TRUE, processed image also saved directory. can either full path, e.g., \"C:/Desktop/imgs\", subfolder within current working directory, e.g., \"/imgs\". verbose TRUE (default) summary shown console. x object class anal_obj. plot. Either 'measure' (object measures) 'index' (object index). Defaults \"measure\". measure measure plot. Defaults \"area\". type type plot. Either \"hist\" \"density\". Partial matches recognized. ... Depends function: analyze_objects_iter(), arguments passed analyze_objects().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects_minimal.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Analyzes objects in an image — analyze_objects_minimal","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects_minimal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyzes objects in an image — analyze_objects_minimal","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"soybean_touch.jpg\") obj <- analyze_objects(img) obj$statistics  }  if (interactive() && requireNamespace(\"EBImage\")) { library(pliman)  img <- image_pliman(\"soy_green.jpg\") # Segment the foreground (grains) using the normalized blue index (NB, default) # Shows the average value of the blue index in each object  rgb <- analyze_objects_minimal(img) # density of area plot(rgb)  # histogram of area plot(rgb, type = \"histogram\") # or 'hist' }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects_shp.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyzes objects using shapefiles — analyze_objects_shp","title":"Analyzes objects using shapefiles — analyze_objects_shp","text":"Analyzes objects using shapefiles","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects_shp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyzes objects using shapefiles — analyze_objects_shp","text":"","code":"analyze_objects_shp(   img,   nrow = 1,   ncol = 1,   buffer_x = 0,   buffer_y = 0,   prepare = FALSE,   segment_objects = TRUE,   viewer = get_pliman_viewer(),   index = \"R\",   r = 1,   g = 2,   b = 3,   re = 4,   nir = 5,   shapefile = NULL,   interactive = FALSE,   plot = FALSE,   parallel = FALSE,   workers = NULL,   watershed = TRUE,   opening = FALSE,   closing = FALSE,   filter = FALSE,   erode = FALSE,   dilate = FALSE,   object_size = \"medium\",   efourier = FALSE,   object_index = NULL,   veins = FALSE,   width_at = FALSE,   verbose = TRUE,   invert = FALSE,   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects_shp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyzes objects using shapefiles — analyze_objects_shp","text":"img Image object nrow, ncol number rows columns generate shapefile shapefile declared. Defaults 1. buffer_x, buffer_y Buffering factor width height, respectively, individual shape's side. value 0 0.5 0 means buffering 0.5 means complete buffering (default: 0). value 0.25 buffer shape 25% side. prepare Logical value indicating whether prepare image analysis using image_prepare() function. Defaults FALSE. Set TRUE interactively align crop image processing. segment_objects Segment objects image? Defaults TRUE. case, objects segmented using index defined index argument, object analyzed individually. segment_objects = FALSE used, objects segmented entire image analyzed. useful, example, analyzing image without background, object_index computed entire image, like index crop canopy. viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. index character value specifying target mode conversion binary image foreground background declared. Defaults \"NB\" (normalized blue). See image_index() details. User can also calculate index using bands names, e.g. index = \"R+B/G\" r, g, b, re, nir red, green, blue, red-edge, near-infrared bands image, respectively. Defaults 1, 2, 3, 4, 5, respectively. multispectral image provided (5 bands), check order bands, frequently presented 'BGR' format. shapefile (Optional) object created image_shp(). NULL (default), nrow ncol must declared. interactive FALSE (default) grid created automatically based image dimension number nrow/columns. interactive = TRUE, users must draw points diagonal desired bounding box contain grid. plot Plots processed images? Defaults FALSE. parallel TRUE processes images asynchronously (parallel) separate R sessions running background machine. may speed processing time, especially pattern used informed. object_index informed, multiple sections used extract RGB values object image. may significantly speed processing time image lots objects (say >1000). workers positive numeric scalar function specifying number parallel processes can active time. default, number sections set 30% available cores. watershed TRUE (default) performs watershed-based object detection. detect objects even touching one . FALSE, pixels connected set foreground pixels set unique object. faster able segment touching objects. opening, closing, filter, erode, dilate Morphological operations (brush size) dilate puts mask every background pixel, sets foreground pixels covered mask foreground. erode puts mask every foreground pixel, sets background pixels covered mask background. opening performs erosion followed dilation. helps remove small objects preserving shape size larger objects. closing performs dilatation followed erosion. helps fill small holes preserving shape size larger objects. filter performs median filtering binary image. Provide positive integer > 1 indicate size median filtering. Higher values efficient remove noise background can dramatically impact perimeter objects, mainly irregular perimeters leaves serrated edges. object_size Argument control control watershed segmentation. See analyze_objects() details. efourier Logical argument indicating Elliptical Fourier computed object. call efourier() internally. efourier = TRUE used, standard normalized Fourier coefficients returned. object_index Defaults FALSE. index informed, average value object returned. can R, G, B values operation involving , e.g., object_index = \"R/B\". case, return object image, average value R/B ratio. Use pliman_indexes_eq() see equations available indexes. veins Logical argument indicating whether vein features computed. call object_edge() applies Sobel-Feldman Operator detect edges. result proportion edges relation entire area object(s) image. Note OPERATION IMAGE LEVEL, OBJECT!. width_at Logical. TRUE, widths object given set quantiles height computed. verbose TRUE (default) summary shown console. invert Inverts binary image desired. useful process images black background. Defaults FALSE. reference = TRUE use, invert can declared logical vector length 2 (eg., invert = c(FALSE, TRUE). case, segmentation objects reference foreground using back_fore_index performed using default (inverted), segmentation objects reference performed inverting selection (selecting pixels higher threshold). ... Aditional arguments passed analyze_objects.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects_shp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyzes objects using shapefiles — analyze_objects_shp","text":"object class anal_obj. See details Value section analyze_objects().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects_shp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Analyzes objects using shapefiles — analyze_objects_shp","text":"analyze_objects_shp function performs object analysis image generates shapefiles representing analyzed objects. function first prepares image analysis using image_prepare() function prepare argument set TRUE. shapefile object provided, number rows columns splitting image obtained shapefile. Otherwise, image split multiple sub-images based specified number rows columns using object_split_shp() function. objects sub-image analyzed using analyze_objects() function, results stored list. parallel processing enabled, analysis performed parallel using multiple workers. output object provides access various components analysis results, analyzed object coordinates properties. Additionally, shapefiles representing analyzed objects included output object analysis visualization.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/analyze_objects_shp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyzes objects using shapefiles — analyze_objects_shp","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman)  # Computes the DGCI index for each flax leaf flax <- image_pliman(\"flax_leaves.jpg\", plot =TRUE) res <-    analyze_objects_shp(flax,                        nrow = 3,                        ncol = 5,                        plot = FALSE,                        object_index = \"DGCI\") plot(flax) plot(res$shapefiles) plot_measures(res, measure = \"DGCI\") }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/apply_fun_to_imgs.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply a function to images — apply_fun_to_imgs","title":"Apply a function to images — apply_fun_to_imgs","text":"functions pliman can applied list images, can ideal deal lots images, mainly high resolution. curiosity, 6000 x 4000 image use nearly 570 Megabytes RAM. , impossible deal lots images within R. apply_fun_to_img() applies function images stored given directory follows: Create vector image names contain given pattern name. Import image list. Apply function imported image. Export mutated image computer. parallel set FALSE (default), images processed sequentially, means one image needs imported, processed, exported image can processed. parallel set TRUE,  images processed asynchronously (parallel) separate R sessions (3) running background machine. may speed processing time lots images need processed.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/apply_fun_to_imgs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply a function to images — apply_fun_to_imgs","text":"","code":"apply_fun_to_imgs(   pattern,   fun,   ...,   dir_original = NULL,   dir_processed = NULL,   prefix = \"\",   suffix = \"\",   parallel = FALSE,   workers = 3,   verbose = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/apply_fun_to_imgs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply a function to images — apply_fun_to_imgs","text":"pattern pattern match images' names. fun function apply images. ... Arguments passed fun. dir_original, dir_processed directory containing original processed images. Defaults NULL, means current working directory considered. processed image overwrite original image unless prefix/suffix used subfolder informed dir_processed argument. prefix, suffix prefix /suffix included name processed images. Defaults \"\". parallel TRUE processes images asynchronously (parallel) separate R sessions (3 default) running background machine. may speed processing time, especially pattern used informed. workers positive numeric scalar function specifying number parallel processes can active time. Defaults 3. verbose Shows progress console? Defaults TRUE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/apply_fun_to_imgs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply a function to images — apply_fun_to_imgs","text":"Nothing. processed images saved current working directory.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/apply_fun_to_imgs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply a function to images — apply_fun_to_imgs","text":"","code":"# apply_fun_to_imgs(\"pattern\", image_resize, rel_size = 50)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/as_image.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an Image object — as_image","title":"Create an Image object — as_image","text":"function simple wrapper around EBImage::Image().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/as_image.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an Image object — as_image","text":"","code":"as_image(data, ...)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/as_image.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an Image object — as_image","text":"data vector array containing pixel intensities image. missing, default 1x1 zero-filled array used. ... Additional arguments passed EBImage::Image().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/as_image.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an Image object — as_image","text":"Image object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/as_image.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an Image object — as_image","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- as_image(rnorm(150 * 150 * 3),          dim = c(150, 150, 3),          colormode = 'Color') plot(img) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/calibrate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calibrates distances of landmarks — calibrate","title":"Calibrates distances of landmarks — calibrate","text":"Calibrating actual size possible interlandmark distance image known. calibrate() can used determine size known distance (cm) graph. invite users photograph object together scale (e.g., ruler, micrometer...).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/calibrate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calibrates distances of landmarks — calibrate","text":"","code":"calibrate(img, viewer = get_pliman_viewer())"},{"path":"https://nepem-ufsc.github.io/pliman/reference/calibrate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calibrates distances of landmarks — calibrate","text":"img Image object viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/calibrate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calibrates distances of landmarks — calibrate","text":"numeric (double) scalar value indicating scale (pixels per unit known distance).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/calibrate.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calibrates distances of landmarks — calibrate","text":"Claude, J. (2008) Morphometrics R, Use R! series, Springer 316 pp.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/calibrate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calibrates distances of landmarks — calibrate","text":"","code":"if(isTRUE(interactive())){ library(pliman) #### compute scale (dots per unit of known distance) #### # only works in an interactive section # objects_300dpi.jpg has a known resolution of 300 dpi img <- image_pliman(\"objects_300dpi.jpg\") # Larger square: 10 x 10 cm # 1) Run the function calibrate() # 2) Use the left mouse button to create a line in the larger square # 3) Declare a known distance (10 cm) # 4) See the computed scale (pixels per cm) calibrate(img)  # scale ~118 # 118 * 2.54 ~300 DPI }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/ccc.html","id":null,"dir":"Reference","previous_headings":"","what":"Lin's Concordance Correlation Coefficient (CCC) — ccc","title":"Lin's Concordance Correlation Coefficient (CCC) — ccc","text":"Computes Lin's Concordance Correlation Coefficient (CCC) observed predicted values. Also returns Pearson's correlation coefficient root mean squared error (RMSE). input grouped data frame (grouped_df), function return results group.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/ccc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lin's Concordance Correlation Coefficient (CCC) — ccc","text":"","code":"ccc(data, real, predito)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/ccc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lin's Concordance Correlation Coefficient (CCC) — ccc","text":"data data frame containing columns observed predicted values. real column name (unquoted) corresponding observed values. predito column name (unquoted) corresponding predicted values.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/ccc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lin's Concordance Correlation Coefficient (CCC) — ccc","text":"data frame following columns: r: Pearson correlation coefficient ccc: Lin's Concordance Correlation Coefficient rmse: Root mean squared error","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/ccc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Lin's Concordance Correlation Coefficient (CCC) — ccc","text":"CCC defined : $$\\rho_c = \\frac{2 \\cdot \\text{Cov}(x, y)}{\\text{Var}(x) + \\text{Var}(y) + (\\bar{x} - \\bar{y})^2}$$ : \\(\\text{Cov}(x, y)\\) covariance observed predicted values \\(\\text{Var}(x)\\) \\(\\text{Var}(y)\\) variances observed predicted values \\(\\bar{x}\\) \\(\\bar{y}\\) means observed predicted values","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/ccc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lin's Concordance Correlation Coefficient (CCC) — ccc","text":"","code":"library(dplyr) #>  #> Attaching package: 'dplyr' #> The following object is masked from 'package:pliman': #>  #>     %>% #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(pliman) df <- data.frame(   group = rep(c(\"A\", \"B\"), each = 5),   real = c(1:5, 2:6),   predicted = c(1.1, 2, 2.9, 4.1, 5, 2.2, 3.1, 4, 4.8, 6.1) )  # Without grouping ccc(df, real, predicted) #>          r       ccc      rmse #> 1 0.997498 0.9970678 0.1140175  # With grouping df |>   group_by(group) |>   ccc(real, predicted) #> # A tibble: 2 × 4 #>   group     r   ccc   rmse #>   <chr> <dbl> <dbl>  <dbl> #> 1 A     0.999 0.999 0.0775 #> 2 B     0.996 0.995 0.141"},{"path":"https://nepem-ufsc.github.io/pliman/reference/clear_pliman_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Clear cached files created by pliman — clear_pliman_cache","title":"Clear cached files created by pliman — clear_pliman_cache","text":"Deletes cached .rds files used functions object_scatter(). can either remove entire cache directory files older given number days.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/clear_pliman_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clear cached files created by pliman — clear_pliman_cache","text":"","code":"clear_pliman_cache(all = TRUE, days = NULL)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/clear_pliman_cache.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clear cached files created by pliman — clear_pliman_cache","text":"Logical. TRUE (default), deletes entire cache directory. days Integer (optional). provided, removes files older days. Ignored = TRUE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/clear_pliman_cache.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clear cached files created by pliman — clear_pliman_cache","text":"Invisibly returns TRUE operation successful.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/clear_pliman_cache.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clear cached files created by pliman — clear_pliman_cache","text":"","code":"if(interactive()){ # Clear everything clear_pliman_cache()  # Clear only files older than 7 days clear_pliman_cache(all = FALSE, days = 7) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/contours.html","id":null,"dir":"Reference","previous_headings":"","what":"Contour outlines from five leaves — contours","title":"Contour outlines from five leaves — contours","text":"list contour outlines five leaves. may used example functions efourier()","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/contours.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Contour outlines from five leaves — contours","text":"list five objects leaf_1 leaf_2 leaf_3 leaf_4 leaf_5 object data.frame coordinates outline perimeter","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/contours.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Contour outlines from five leaves — contours","text":"Personal data. images obtained Flavia data set downlodable https://flavia.sourceforge.net/","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/contours.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Contour outlines from five leaves — contours","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/custom_palette.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Custom Color Palette — custom_palette","title":"Generate Custom Color Palette — custom_palette","text":"function generates custom color palette using specified colors number colors.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/custom_palette.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Custom Color Palette — custom_palette","text":"","code":"custom_palette(   colors = c(\"yellow\", \"#53CC67\", \"#009B95\", \"#00588B\", \"#4B0055\"),   n = 5 )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/custom_palette.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Custom Color Palette — custom_palette","text":"colors vector colors create color palette. Default c(\"steelblue\", \"salmon\", \"forestgreen\"). n number gradient colors color palette. Default 100.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/custom_palette.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Custom Color Palette — custom_palette","text":"vector colors representing custom color palette.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/custom_palette.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Custom Color Palette — custom_palette","text":"","code":"# Generate a custom color palette with default colors and 10 colors custom_palette() #> [1] \"#FFFF00\" \"#53CC67\" \"#009B95\" \"#00588B\" \"#4B0055\"  # Generate a custom color palette with specified colors and 20 colors custom_palette(colors = c(\"blue\", \"red\"), n = 20) #>  [1] \"#0000FF\" \"#0D00F1\" \"#1A00E4\" \"#2800D6\" \"#3500C9\" \"#4300BB\" \"#5000AE\" #>  [8] \"#5D00A1\" \"#6B0093\" \"#780086\" \"#860078\" \"#93006B\" \"#A1005D\" \"#AE0050\" #> [15] \"#BB0043\" \"#C90035\" \"#D60028\" \"#E4001A\" \"#F1000D\" \"#FF0000\"  # example code library(pliman) custom_palette(n = 5) #> [1] \"#FFFF00\" \"#53CC67\" \"#009B95\" \"#00588B\" \"#4B0055\""},{"path":"https://nepem-ufsc.github.io/pliman/reference/dist_transform.html","id":null,"dir":"Reference","previous_headings":"","what":"Distance map transform — dist_transform","title":"Distance map transform — dist_transform","text":"Computes distance map transform binary image. distance map matrix contains pixel distance nearest background pixel.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/dist_transform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distance map transform — dist_transform","text":"","code":"dist_transform(binary)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/dist_transform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Distance map transform — dist_transform","text":"binary binary image","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/dist_transform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Distance map transform — dist_transform","text":"Image object array, pixels containing distances nearest background points","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/dist_transform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Distance map transform — dist_transform","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"soybean_touch.jpg\") binary <- image_binary(img, \"B\")[[1]] wts <- dist_transform(binary) range(wts) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier.html","id":null,"dir":"Reference","previous_headings":"","what":"Elliptical Fourier Analysis — efourier","title":"Elliptical Fourier Analysis — efourier","text":"Computes Elliptical Fourier Analysis closed outlines based x y-coordinates coordinates.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elliptical Fourier Analysis — efourier","text":"","code":"efourier(x, nharm = 10, align = FALSE, center = FALSE, smooth_iter = 0)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elliptical Fourier Analysis — efourier","text":"x matrix, data.frame list perimeter coordinates, often produced object_contour() vector landmarks produced landmarks() landmarks_regradi(). nharm integer indicating number harmonics use. Defaults 10. align Align objects computing Fourier analysis? Defaults FALSE. TRUE, object first aligned along major caliper poly_align(). center Center objects origin computing Fourier analysis? Defaults FALSE. TRUE, object first centered origin poly_center(). smooth_iter number smoothing iterations perform. smooth perimeter objects using poly_smooth().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Elliptical Fourier Analysis — efourier","text":"list class efourier : harmonic coefficients (, bn, cn dn) estimates coordinates centroid configuration (a0 c0). number rows (points) perimeter outline (nr). number harmonics used (nharm). original coordinates (coords). x list perimeter coordinates, list efourier objects returned object class iefourier_lst.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Elliptical Fourier Analysis — efourier","text":"Adapted Claude (2008). pp. 222-223.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Elliptical Fourier Analysis — efourier","text":"Claude, J. (2008) Morphometrics R, Use R! series, Springer 316 pp. Kuhl, F. P., Giardina, C. R. (1982). Elliptic Fourier features closed contour. Computer Graphics Image Processing 18, 236-258. doi: doi:10.1016/0146-664X(82)90034-X","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Elliptical Fourier Analysis — efourier","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) leaf1 <- contours[[4]] plot_polygon(leaf1)  #### default options # 10 harmonics (default) # without alignment  ef <- efourier(leaf1) efourier_coefs(ef)  # object is aligned along the major caliper with `poly_align()` # object is centered on the origin with `poly_center()` # using a list of object coordinates ef2 <- efourier(contours, align = TRUE, center = TRUE) efourier_coefs(ef2)  # reconstruct the perimeter of the object # Use only the first one for simplicity plot_polygon(contours[[1]] |> poly_align() |> poly_center()) efourier_inv(ef2[[1]]) |> plot_contour(col = \"red\", lwd = 4) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_coefs.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Fourier coefficients — efourier_coefs","title":"Get Fourier coefficients — efourier_coefs","text":"Extracts Fourier coefficients objects computed efourier() efourier_norm() returning 'ready--analyze' data frame.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_coefs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Fourier coefficients — efourier_coefs","text":"","code":"efourier_coefs(x)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_coefs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Fourier coefficients — efourier_coefs","text":"x object computed efourier() efourier_norm().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_coefs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Fourier coefficients — efourier_coefs","text":"data.frame object","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_coefs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Fourier coefficients — efourier_coefs","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman)  # a list of objects efourier(contours) |> efourier_coefs()  # one object, normalized coefficients efourier(contours[[4]]) |>   efourier_norm() |>   efourier_coefs() }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Erros between the original and reconstructed outline — efourier_error","title":"Erros between the original and reconstructed outline — efourier_error","text":"Computes sum squared distances original data reconstructed outline. allows examining reconstructed outlines addition successive contributing harmonics indicated argument nharm.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Erros between the original and reconstructed outline — efourier_error","text":"","code":"efourier_error(   x,   nharm = NULL,   type = c(\"error\", \"outline\", \"deviations\"),   plot = TRUE,   ncol = NULL,   nrow = NULL )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Erros between the original and reconstructed outline — efourier_error","text":"x object computed efourier(). nharm integer vector integers indicating number harmonics use. specified number harmonics used x used. type type plot produce. default, line plot sum squared distances (y-axis) number harmonics (x-axis) produced. type = \"outline\" used, plot original polygon constructed outline produced. type = \"deviations\" used, plot deviations original outline reconstructed outline (y-axis) points along outline (x-axis) produced. plot logical inform plot produced. Defaults TRUE. ncol, nrow number rows columns plot grid. Defaults NULL, .e., square grid produced.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Erros between the original and reconstructed outline — efourier_error","text":"list objects: dev_points list deviations (distances) original predicted outline pixel outline. data.frame object minimum, maximum average deviations (based outline points). x object class efourier_lst, list returned.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_error.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Erros between the original and reconstructed outline — efourier_error","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) ef <-   contours[[1]] |>   efourier(nharm = 30)  efourier_error(ef)  efourier_error(ef,                nharm = 30,                type = \"outline\")  efourier_error(ef,                nharm = c(1, 4, 20),                type = \"deviations\") }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_inv.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse Elliptical Fourier Analysis — efourier_inv","title":"Inverse Elliptical Fourier Analysis — efourier_inv","text":"Performs inverse elliptical Fourier transformation construct shape, given list Fourier coefficients computed efourier().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_inv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse Elliptical Fourier Analysis — efourier_inv","text":"","code":"efourier_inv(x, nharm = NULL, a0 = NULL, c0 = NULL, npoints = 500)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_inv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse Elliptical Fourier Analysis — efourier_inv","text":"x object class efourier efourier_lst computed efourier(). nharm integer indicating number harmonics use. specified number harmonics used x used. a0, c0 estimates coordinates centroid configuration. NULL (default), generated coordinates centered position original shape given efourier(). npoints number interpolated points constructed outline. Defaults 500.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_inv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inverse Elliptical Fourier Analysis — efourier_inv","text":"Adapted Claude (2008). pp. 223.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_inv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Inverse Elliptical Fourier Analysis — efourier_inv","text":"Claude, J. (2008) Morphometrics R, Use R! series, Springer 316 pp.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_inv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse Elliptical Fourier Analysis — efourier_inv","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) plot_polygon(contours, aspect_ratio = 1) # without alignment ef <- efourier(contours, nharm = 10, align = FALSE) ief <- efourier_inv(ef) plot_contour(ief, col = \"red\", lwd = 2) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalized Fourier coefficients — efourier_norm","title":"Normalized Fourier coefficients — efourier_norm","text":"first harmonic defines ellipse best fits outlines. One can use parameters first harmonic \"normalize\" data can invariant size, rotation, starting position outline trace. approach referred literature normalized elliptic Fourier. efourier_norm() calculates new set Fourier coefficients , Bn, Cn, Dn one can use multivariate analyses (Claude, 2008).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalized Fourier coefficients — efourier_norm","text":"","code":"efourier_norm(x, start = FALSE)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalized Fourier coefficients — efourier_norm","text":"x object computed efourier(). start Logical value telling whether position starting point preserved .","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalized Fourier coefficients — efourier_norm","text":"list following components: , B, C, D harmonic coefficients. size magnitude semi-major axis first fitting ellipse. theta angle, radians, starting semi-major axis first fitting ellipse. psi orientation first fitting ellipse a0 c0, harmonic coefficients. lnef concatenation coefficients. nharm number harmonics used.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_norm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normalized Fourier coefficients — efourier_norm","text":"Adapted Claude (2008). pp. 226.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_norm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Normalized Fourier coefficients — efourier_norm","text":"Claude, J. (2008) Morphometrics R, Use R! series, Springer 316 pp.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalized Fourier coefficients — efourier_norm","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) leaf1 <- contours[[4]] plot_polygon(leaf1)  # compute the Fourier coefficients ef <- efourier(leaf1) efourier_coefs(ef)  # Normalized Fourier coefficients  efn <- efourier_norm(ef) efourier_coefs(efn) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_power.html","id":null,"dir":"Reference","previous_headings":"","what":"Power in Fourier Analysis — efourier_power","title":"Power in Fourier Analysis — efourier_power","text":"Computes spectrum harmonic Fourier power. power proportional harmonic amplitude can considered measure shape information. rank harmonic increases, power decreases adds less less information. can evaluate number harmonics must select, cumulative power gathers 99% total cumulative power (Claude, 2008).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_power.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power in Fourier Analysis — efourier_power","text":"","code":"efourier_power(   x,   first = TRUE,   thresh = c(0.8, 0.85, 0.9, 0.95, 0.99, 0.999),   plot = TRUE,   ncol = NULL,   nrow = NULL )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_power.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power in Fourier Analysis — efourier_power","text":"x object class efouriercomputed efourier(). first Logical argument indicating whether include first harmonic computing power. See Details. thresh numeric vector indicating threshold power. number harmonics needed thresholds computed. plot Logical argument indicating whether produce plot. ncol, nrow number rows columns plot grid. Defaults NULL, .e., square grid produced.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_power.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power in Fourier Analysis — efourier_power","text":"list objects: cum_power, data.frame object accumulated power depending number harmonics min_harm minimum number harmonics achieve given power.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_power.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Power in Fourier Analysis — efourier_power","text":"shape \"information\" contained first harmonic. surprising harmonic best fits outline, size ellipses decreases explaining successive residual variation. However, one may think first ellipse contain relevant shape information, especially differences one wants investigate concern complex outlines. using first = FALSE possible remove first harmonic computation. working set outlines, high-rank-harmonics can contain information may allow groups distinguished (Claude, 2008). Adapted Claude (2008). pp. 229.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_power.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power in Fourier Analysis — efourier_power","text":"Claude, J. (2008) Morphometrics R, Use R! series, Springer 316 pp.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_power.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power in Fourier Analysis — efourier_power","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) pw <- efourier(contours) |> efourier_power() }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_shape.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw shapes based on Fourier coefficients — efourier_shape","title":"Draw shapes based on Fourier coefficients — efourier_shape","text":"Calculates 'Fourier elliptical shape' given Fourier coefficients","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_shape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw shapes based on Fourier coefficients — efourier_shape","text":"","code":"efourier_shape(   an = NULL,   bn = NULL,   cn = NULL,   dn = NULL,   n = 1,   nharm = NULL,   npoints = 150,   alpha = 4,   plot = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_shape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw shapes based on Fourier coefficients — efourier_shape","text":"\\(a_n\\) Fourier coefficients calculate shape. bn \\(b_n\\) Fourier coefficients calculate shape. cn \\(c_n\\) Fourier coefficients calculate shape. dn \\(d_n\\) Fourier coefficients calculate shape. n number shapes generate. Defaults 1. one shape used, list coordinates returned. nharm number harmonics use. must less equal length *_n coefficients. npoints number points calculate. alpha power coefficient associated (usually decreasing) amplitude Fourier coefficients. plot Logical indicating Whether plot shape. Defaults TRUE","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_shape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw shapes based on Fourier coefficients — efourier_shape","text":"list components: x vector x-coordrdinates y vector y-coordrdinates.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_shape.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Draw shapes based on Fourier coefficients — efourier_shape","text":"efourier_shape can used specifying nharm alpha. coefficients sampled uniform distribution \\((-\\pi ; \\pi)\\) amplitude divided \\(harmonicrank ^ alpha\\). alpha lower 1, consecutive coefficients thus increase. See Claude (2008) pp.223 maths behind inverse ellipitical Fourier Adapted Claude (2008). pp. 223.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_shape.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Draw shapes based on Fourier coefficients — efourier_shape","text":"Claude, J. (2008) Morphometrics R, Use R! series, Springer 316 pp.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/efourier_shape.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw shapes based on Fourier coefficients — efourier_shape","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) # approximation of the third leaf's perimeter # 4 harmonics image_pliman(\"potato_leaves.jpg\", plot = TRUE)  efourier_shape(an = c(-7.34,  1.81,  -1.32, 0.50),                bn = c(-113.88, 21.90, -0.31, -6.14),                cn = c(-147.51, -20.89, 0.66, -14.06),                dn = c(-0.48, 2.36, -4.36, 3.03)) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/ellipse.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence ellipse — ellipse","title":"Confidence ellipse — ellipse","text":"Produces confidence ellipse iso-contour Gaussian distribution, allowing visualize 2D confidence interval.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/ellipse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence ellipse — ellipse","text":"","code":"ellipse(   x,   conf = 0.95,   np = 100,   plot = TRUE,   fill = \"green\",   alpha = 0.3,   random_fill = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/ellipse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence ellipse — ellipse","text":"x matrix, data.frame list perimeter coordinates, often produced object_contour(). conf confidence level. Defaults 0.95 np Number sampled points ellipse. plot Create plot? Defaults TRUE. fill color fill ellipse. Defaults \"green\". alpha alpha value define opacity ellipse. Defaults 0.3 random_fill Fill multiple ellipses random colors? Defaults TRUE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/ellipse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confidence ellipse — ellipse","text":"matrix coordinates points sampled ellipse.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/ellipse.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Confidence ellipse — ellipse","text":"Borrowed Claude (2008), pp. 85","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/ellipse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Confidence ellipse — ellipse","text":"Claude, J. (2008) Morphometrics R, Use R! series, Springer 316 pp.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/ellipse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidence ellipse — ellipse","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) ellipse(contours) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/entropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Shannon Entropy — entropy","title":"Compute Shannon Entropy — entropy","text":"function calculates Shannon entropy numeric vector.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/entropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Shannon Entropy — entropy","text":"","code":"entropy(x)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/entropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Shannon Entropy — entropy","text":"x numeric vector containing values entropy computed.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/entropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Shannon Entropy — entropy","text":"numeric value representing entropy.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/entropy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Shannon Entropy — entropy","text":"","code":"library(pliman) x <- c(1, 2, 2, 3, 3, 3, 4, 4, 4, 4) entropy(x) #> [1] 1.279854"},{"path":"https://nepem-ufsc.github.io/pliman/reference/get_pliman_viewer.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the value of the pliman_viewer option — get_pliman_viewer","title":"Get the value of the pliman_viewer option — get_pliman_viewer","text":"Retrieves current value pliman_viewer option used package.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/get_pliman_viewer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the value of the pliman_viewer option — get_pliman_viewer","text":"","code":"get_pliman_viewer()"},{"path":"https://nepem-ufsc.github.io/pliman/reference/get_pliman_viewer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the value of the pliman_viewer option — get_pliman_viewer","text":"current value pliman_viewer option.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/get_uuid.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract UUID from filenames — get_uuid","title":"Extract UUID from filenames — get_uuid","text":"function extracts UUID (Universal Unique Identifier) filename, using regular expression specifically identifies standard UUID format.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/get_uuid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract UUID from filenames — get_uuid","text":"","code":"get_uuid(filename)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/get_uuid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract UUID from filenames — get_uuid","text":"filename character vector containing filenames strings","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/get_uuid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract UUID from filenames — get_uuid","text":"character vector extracted UUIDs (NA none found)","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/get_uuid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract UUID from filenames — get_uuid","text":"","code":"library(pliman) file <- \"Grãos - contagem_f68bca60-c8cf-4272-9448-3f28891a97cd.jpg\" file2 <- \"Grãos - contagem_f68bca60-c8cf-4272-9448-3f8891a97cd.jpg\" get_uuid(file) #> [1] \"f68bca60-c8cf-4272-9448-3f28891a97cd\""},{"path":"https://nepem-ufsc.github.io/pliman/reference/ggplot_color.html","id":null,"dir":"Reference","previous_headings":"","what":"ggplot2-like colors generation — ggplot_color","title":"ggplot2-like colors generation — ggplot_color","text":"Generate ggplot2","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/ggplot_color.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ggplot2-like colors generation — ggplot_color","text":"","code":"ggplot_color(n = 1)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/ggplot_color.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ggplot2-like colors generation — ggplot_color","text":"n number colors. works well eight colours, becomes hard tell different colours apart.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/ggplot_color.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ggplot2-like colors generation — ggplot_color","text":"","code":"library(pliman) ggplot_color(n = 3) #> [1] \"#F8766D\" \"#00BA38\" \"#619CFF\""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_align.html","id":null,"dir":"Reference","previous_headings":"","what":"Aligns an Image object by hand — image_align","title":"Aligns an Image object by hand — image_align","text":"image_align() rotate image given line desired aligment along y axis corresponds alignment objects (e.g., field plots). default, aligment vertical, means drawed line angle < 90 degrees parallel x axis, rotation angle wil negative (anticlocwise rotation).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_align.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aligns an Image object by hand — image_align","text":"","code":"image_align(   img,   align = c(\"vertical\", \"horizontal\"),   viewer = get_pliman_viewer(),   plot = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_align.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aligns an Image object by hand — image_align","text":"img Image object align desired alignment. Either \"vertical\" (default) \"horizontal\". viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. plot Plots aligned image? Defaults TRUE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_align.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aligns an Image object by hand — image_align","text":"img aligned","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_align.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Aligns an Image object by hand — image_align","text":"image_align function aligns image along vertical horizontal axis based user-selected points. alignment can performed either base plotting system using mapview package interactive visualization. viewer option set \"base\", function prompts user select two points image define alignment line. viewer option set \"mapview\", function opens interactive map user can draw polyline define alignment line. alignment angle calculated based selected points, image rotated accordingly using image_rotate function. function returns aligned image object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_align.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aligns an Image object by hand — image_align","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) flax <- image_pliman(\"flax_leaves.jpg\", plot = TRUE) aligned <- image_align(flax) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Alpha Layer to an RGB Image — image_alpha","title":"Add Alpha Layer to an RGB Image — image_alpha","text":"function adds alpha (transparency) layer RGB image using EBImage package. alpha layer can specified single numeric value uniform transparency matrix/array matching dimensions image varying transparency.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Alpha Layer to an RGB Image — image_alpha","text":"","code":"image_alpha(img, mask)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Alpha Layer to an RGB Image — image_alpha","text":"img RGB image class Image EBImage package. image must RGB format (color mode 2). mask numeric value matrix/array specifying alpha layer: * mask single numeric value, sets uniform transparency level (0 fully transparent, 1 fully opaque). * mask matrix array, must dimensions image channels, allowing varying transparency.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_alpha.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Alpha Layer to an RGB Image — image_alpha","text":"Image object added alpha layer, maintaining RGBA format.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Alpha Layer to an RGB Image — image_alpha","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { # Load the EBImage package library(pliman)  # Load a sample RGB image img <- image_pliman(\"soybean_touch.jpg\")  # 50% transparency image_alpha(img, 0.5) |> plot()  # transparent background mask <- image_binary(img, \"NB\")[[1]] img_tb <- image_alpha(img, mask) plot(img_tb)  }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_augment.html","id":null,"dir":"Reference","previous_headings":"","what":"Augment Images — image_augment","title":"Augment Images — image_augment","text":"function takes image augments rotating multiple times.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_augment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Augment Images — image_augment","text":"","code":"image_augment(   img,   pattern = NULL,   times = 12,   type = \"export\",   dir_original = NULL,   dir_processed = NULL,   parallel = FALSE,   verbose = TRUE,   workers = NULL )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_augment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Augment Images — image_augment","text":"img Image object. pattern regular expression pattern select multiple images directory. times number times rotate image. type type output: \"export\" save images \"return\" return list augmented images. dir_original directory original images located. dir_processed directory processed images saved. parallel Whether perform image augmentation parallel. verbose Whether display progress messages. workers positive numeric scalar function specifying number parallel processes can active time. default, number sections set 30% available cores.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_augment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Augment Images — image_augment","text":"type \"export,\" augmented images saved. type \"return,\" list augmented images returned.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_augment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Augment Images — image_augment","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"sev_leaf.jpg\") imgs <- image_augment(img, type = \"return\", times = 4) image_combine(imgs) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_binary.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a binary image — image_binary","title":"Creates a binary image — image_binary","text":"Reduce color, color near-infrared, grayscale images binary image using given color channel (red, green blue) even color indexes. Otsu's thresholding method (Otsu, 1979) used automatically perform clustering-based image thresholding.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_binary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a binary image — image_binary","text":"","code":"image_binary(   img,   index = \"R\",   r = 1,   g = 2,   b = 3,   re = 4,   nir = 5,   return_class = \"ebimage\",   threshold = c(\"Otsu\", \"adaptive\"),   k = 0.1,   windowsize = NULL,   has_white_bg = FALSE,   resize = FALSE,   fill_hull = FALSE,   erode = FALSE,   dilate = FALSE,   opening = FALSE,   closing = FALSE,   filter = FALSE,   invert = FALSE,   plot = TRUE,   nrow = NULL,   ncol = NULL,   parallel = FALSE,   workers = NULL,   verbose = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_binary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a binary image — image_binary","text":"img image object. index character value (vector characters) specifying target mode conversion binary image. See available indexes pliman_indexes() image_index() details. r, g, b, re, nir red, green, blue, red-edge, near-infrared bands image, respectively. Defaults 1, 2, 3, 4, 5, respectively. multispectral image provided (5 bands), check order bands, frequently presented 'BGR' format. return_class class object returned. \"terra returns SpatRaster object number layers equal number indexes computed. \"ebimage\" (default) returns list Image objects, element one index computed. threshold theshold method used. default (threshold = \"Otsu\"), threshold value based Otsu's method used reduce grayscale image binary image. numeric value informed, value used threshold. threshold = \"adaptive\", adaptive thresholding (Shafait et al. 2008) used, depend k windowsize arguments. non-numeric value different \"Otsu\" \"adaptive\" used, iterative section allow choose threshold based raster plot showing pixel intensity index. k numeric range 0-1. k high, local threshold values tend lower. k low, local threshold value tend higher. windowsize windowsize controls number local neighborhood adaptive thresholding. default set 1/3 * minxy, minxy minimum dimension image (pixels). has_white_bg Logical indicating whether white background present. TRUE, pixels R, G, B values equals 1 considered NA. may useful compute image index objects , example, white background. cases, background considered threshold computation. resize Resize image processing? Defaults FALSE. Use numeric value percentage desired resizing. example, resize = 30, resized image 30% size original image. fill_hull Fill holes objects? Defaults FALSE. erode, dilate, opening, closing, filter Morphological operations (brush size) dilate puts mask every background pixel, sets foreground pixels covered mask foreground. erode puts mask every foreground pixel, sets background pixels covered mask background. opening performs erosion followed dilation. helps remove small objects preserving shape size larger objects. closing performs dilatation followed erosion. helps fill small holes preserving shape size larger objects. filter performs median filtering binary image. Provide positive integer > 1 indicate size median filtering. Higher values efficient remove noise background can dramatically impact perimeter objects, mainly irregular perimeters leaves serrated edges. Hierarchically, operations performed opening > closing > filter. value declared argument define brush size. invert Inverts binary image, desired. plot Show image processing? nrow, ncol number rows columns plot grid. Defaults NULL, .e., square grid produced. parallel Processes images asynchronously (parallel) separate R sessions running background machine. may speed processing time image list. number sections set 70% available cores. workers positive numeric scalar function specifying maximum number parallel processes can active time. verbose TRUE (default) summary shown console.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_binary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a binary image — image_binary","text":"list containing binary images. length depend number indexes used.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_binary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Creates a binary image — image_binary","text":"Otsu, N. 1979. Threshold selection method gray-level histograms. IEEE Trans Syst Man Cybern SMC-9(1): 62–66. doi:10.1109/tsmc.1979.4310076 Shafait, F., D. Keysers, T.M. Breuel. 2008. Efficient implementation local adaptive thresholding techniques using integral images. Document Recognition Retrieval XV. SPIE. p. 317–322 doi:10.1117/12.767755","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_binary.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Creates a binary image — image_binary","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_binary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a binary image — image_binary","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"soybean_touch.jpg\") image_binary(img, index = c(\"R, G\")) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_canny_edge.html","id":null,"dir":"Reference","previous_headings":"","what":"Canny Edge Detector — image_canny_edge","title":"Canny Edge Detector — image_canny_edge","text":"Canny Edge Detector Images. Adapted https://github.com/bnosac/image/tree/master/image.CannyEdges.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_canny_edge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Canny Edge Detector — image_canny_edge","text":"","code":"image_canny_edge(img, index = \"GRAY\", s = 5, low_thr = 10, high_thr = 20)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_canny_edge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Canny Edge Detector — image_canny_edge","text":"img Image object. index character string index used. Defaults \"GRAY\". s sigma, Gaussian filter variance. Defaults 5. low_thr lower threshold value algorithm. Defaults 10. high_thr upper threshold value algorithm. Defaults 20","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_canny_edge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Canny Edge Detector — image_canny_edge","text":"list Image object values 0 255, number pixels value 255 (pixels_nonzero).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_canny_edge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Canny Edge Detector — image_canny_edge","text":"","code":"if(interactive()){ library(pliman) img <- image_pliman(\"sev_leaf.jpg\") conts <- image_canny_edge(img, index = \"B\") par(mfrow = c(1, 2)) plot(img) plot(conts$edges) par(mfrow = c(1, 1)) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_combine.html","id":null,"dir":"Reference","previous_headings":"","what":"Combines images to a grid — image_combine","title":"Combines images to a grid — image_combine","text":"Combines several images grid","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_combine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combines images to a grid — image_combine","text":"","code":"image_combine(   ...,   labels = NULL,   nrow = NULL,   ncol = NULL,   col = \"black\",   verbose = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_combine.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combines images to a grid — image_combine","text":"... comma-separated name image objects list containing image objects. labels character vector length number objects ... indicate plot labels. nrow, ncol number rows columns plot grid. Defaults NULL, .e., square grid produced. col color plot labels. Defaults col = \"black\". verbose Shows name objects declared ... numeric sequence list names provided. Set FALSE supress text.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_combine.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combines images to a grid — image_combine","text":"grid images ...","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_combine.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Combines images to a grid — image_combine","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_combine.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combines images to a grid — image_combine","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img1 <- image_pliman(\"sev_leaf.jpg\") img2 <- image_pliman(\"sev_leaf_nb.jpg\") image_combine(img1, img2) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_contour_line.html","id":null,"dir":"Reference","previous_headings":"","what":"Smooth Contour Line Detection — image_contour_line","title":"Smooth Contour Line Detection — image_contour_line","text":"Smooth Contour Line Detection","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_contour_line.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smooth Contour Line Detection — image_contour_line","text":"","code":"image_contour_line(img, index = \"GRAY\", Q = 2)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_contour_line.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smooth Contour Line Detection — image_contour_line","text":"img Image object. index character string index used. Defaults \"GRAY\". Q numeric value pixel quantization step","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_contour_line.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Smooth Contour Line Detection — image_contour_line","text":"list contour lines.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_contour_line.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Smooth Contour Line Detection — image_contour_line","text":"","code":"if(interactive()){ library(pliman) img <- image_pliman(\"sev_leaf.jpg\") conts <- image_contour_line(img, index = \"B\") plot(img) plot_contour(conts, col = \"black\") }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_create.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an Image object of a given color — image_create","title":"Create an Image object of a given color — image_create","text":"image_create() can used create Image object desired color size.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_create.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an Image object of a given color — image_create","text":"","code":"image_create(color, width = 200, heigth = 200, plot = FALSE)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_create.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an Image object of a given color — image_create","text":"color either color name (listed grDevices::colors()), hexadecimal string form \"#rrggbb\". width, heigth width heigth image pixel units. plot Plots image creating ? Defaults FALSE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_create.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an Image object of a given color — image_create","text":"object class Image.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_create.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an Image object of a given color — image_create","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { image_create(\"red\") image_create(\"#009E73\", width = 300, heigth = 100) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_expand.html","id":null,"dir":"Reference","previous_headings":"","what":"Expands an image — image_expand","title":"Expands an image — image_expand","text":"Expands image towards left, top, right, bottom sampling pixels image edge. Users can choose many pixels (rows columns) sampled many pixels expansion .","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_expand.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expands an image — image_expand","text":"","code":"image_expand(   img,   left = NULL,   top = NULL,   right = NULL,   bottom = NULL,   edge = NULL,   sample_left = 10,   sample_top = 10,   sample_right = 10,   sample_bottom = 10,   random = FALSE,   filter = NULL,   plot = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_expand.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expands an image — image_expand","text":"img Image object. left, top, right, bottom number pixels expand left, top, right, bottom directions, respectively. edge number pixels expand directions. can used avoid calling arguments sample_left, sample_top, sample_right, sample_bottom number pixels sample side. Defaults 20. random Randomly sampling edge's pixels? Defaults FALSE. filter Apply median filter sampled pixels? Defaults FALSE. plot Plots extended image? defaults FALSE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_expand.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expands an image — image_expand","text":"Image object","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_expand.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expands an image — image_expand","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"soybean_touch.jpg\") image_expand(img, left = 200) image_expand(img, right = 150, bottom = 250, filter = 5) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Image indexes — image_index","title":"Image indexes — image_index","text":"image_index() Builds image indexes using Red, Green, Blue, Red-Edge, NIR bands. See page detailed list available indexes. S3 method plot() can used generate raster density plot index values computed image_index()","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Image indexes — image_index","text":"","code":"image_index(   img,   index = NULL,   r = 1,   g = 2,   b = 3,   re = 4,   nir = 5,   return_class = c(\"ebimage\", \"terra\"),   resize = FALSE,   has_white_bg = FALSE,   plot = TRUE,   nrow = NULL,   ncol = NULL,   max_pixels = 1e+05,   parallel = FALSE,   workers = NULL,   verbose = TRUE,   ... )  # S3 method for class 'image_index' plot(x, type = c(\"raster\", \"density\"), nrow = NULL, ncol = NULL, ...)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Image indexes — image_index","text":"img Image object. Multispectral mosaics can converted Image object using mosaic_as_ebimage(). index character value (vector characters) specifying target mode conversion binary image. Use pliman_indexes() details section see available indexes. Defaults NULL (normalized Red, Green, Blue). can also use \"RGB\" RGB , \"NRGB\" normalized RGB,  \"MULTISPECTRAL\" multispectral indices (provided NIR RE bands available) \"\" indexes. Users can also calculate index using band names, e.g., index = \"R+B/G\". r, g, b, re, nir red, green, blue, red-edge, near-infrared bands image, respectively. Defaults 1, 2, 3, 4, 5, respectively. multispectral image provided (5 bands), check order bands, frequently presented 'BGR' format. return_class class object returned. \"terra returns SpatRaster object number layers equal number indexes computed. \"ebimage\" (default) returns list Image objects, element one index computed. resize Resize image processing? Defaults resize = FALSE. Use resize = 50, resizes image 50% original size speed image processing. has_white_bg Logical indicating whether white background present. TRUE, pixels R, G, B values equals 1 considered NA. may useful compute image index objects , example, white background. cases, background considered threshold computation. plot Show image processing? nrow, ncol number rows columns plot grid. Defaults NULL, .e., square grid produced. max_pixels integer > 0. Maximum number cells plot index. max_pixels < npixels(img), downsampling performed plotting index. Using large number pixels may slow plotting time. parallel Processes images asynchronously (parallel) separate R sessions running background machine. may speed processing time image list. number sections set 70% available cores. workers positive numeric scalar function specifying maximum number parallel processes can active time. verbose TRUE (default) summary shown console. ... Additional arguments passed plot_index() customization. x object class image_index. type type plot. Use type = \"raster\" (default) produce raster plot showing intensity pixels image index type = \"density\" produce density plot pixels' intensity.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Image indexes — image_index","text":"list containing Grayscale images. length depend number indexes used. NULL object","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_index.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Image indexes — image_index","text":"type = \"raster\" (default), function calls plot_index() create raster plot index present x. type = \"density\", loop used create density plot index. types plots can arranged grid controlled ncol nrow arguments.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_index.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Image indexes — image_index","text":"Nobuyuki Otsu, \"threshold selection method gray-level histograms\". IEEE Trans. Sys., Man., Cyber. 9 (1): 62-66. 1979. doi:10.1109/TSMC.1979.4310076 Karcher, D.E., M.D. Richardson. 2003. Quantifying Turfgrass Color Using Digital Image Analysis. Crop Science 43(3): 943–951. doi:10.2135/cropsci2003.9430 Bannari, ., D. Morin, F. Bonn, .R. Huete. 1995. review vegetation indices. Remote Sensing Reviews 13(1–2): 95–120. doi:10.1080/02757259509532298","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_index.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Image indexes — image_index","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Image indexes — image_index","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"soybean_touch.jpg\") image_index(img, index = c(\"R, NR\")) } if (interactive() && requireNamespace(\"EBImage\")) { # Example for S3 method plot() library(pliman) img <- image_pliman(\"sev_leaf.jpg\") # compute the index ind <- image_index(img, index = c(\"R, G, B, NGRDI\"), plot = FALSE) plot(ind)  # density plot plot(ind, type = \"density\") }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_label.html","id":null,"dir":"Reference","previous_headings":"","what":"Label Connected Components in a Binary Image — image_label","title":"Label Connected Components in a Binary Image — image_label","text":"function labels connected components binary image allowing specified maximum gap pixels still considered part object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_label.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Label Connected Components in a Binary Image — image_label","text":"","code":"image_label(img, max_gap = 0)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_label.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Label Connected Components in a Binary Image — image_label","text":"img binary image matrix 1 represents foreground pixels 0 represents background pixels. compatible EBImage package. max_gap integer specifying maximum allowable gap (pixels) connected components considered part object. Default 1.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_label.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Label Connected Components in a Binary Image — image_label","text":"object class Image (EBImage package), connected component assigned unique integer label.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_label.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Label Connected Components in a Binary Image — image_label","text":"","code":"if(interactive()){ library(pliman) img <- matrix(c(   1, 1, 0, 0, 0, 1, 1, 1, 0,   0, 0, 0, 0, 0, 1, 0, 0, 0,   1, 1, 0, 0, 1, 1, 1, 0, 0,   0, 0, 0, 0, 0, 0, 0, 0, 1 ), nrow = 4, byrow = TRUE)  image_label(img, max_gap = 1) image_label(img, max_gap = 2) image_label(img, max_gap = 3) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_line_segment.html","id":null,"dir":"Reference","previous_headings":"","what":"Line Segment Detection in an Image — image_line_segment","title":"Line Segment Detection in an Image — image_line_segment","text":"Detects line segments digital image using Line Segment Detector (LSD), linear-time method controls false detections requires parameter tuning. Based Burns, Hanson, Riseman's method -contrario validation approach.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_line_segment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Line Segment Detection in an Image — image_line_segment","text":"","code":"image_line_segment(   img,   index = \"GRAY\",   scale = 0.8,   sigma_scale = 0.6,   quant = 2,   ang_th = 22.5,   log_eps = 0,   density_th = 0.7,   n_bins = 1024,   union = FALSE,   union_min_length = 5,   union_max_distance = 5,   union_ang_th = 7,   union_use_NFA = FALSE,   union_log_eps = 0 )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_line_segment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Line Segment Detection in an Image — image_line_segment","text":"img Image object. index character string index used. Defaults \"GRAY\". scale positive numeric value. Scales input image detection using Gaussian filtering. value <1 downscales, >1 upscales. Default 0.8. sigma_scale positive numeric value determining Gaussian filter sigma. scale <1, sigma = sigma_scale / scale; otherwise, sigma = sigma_scale. Default 0.6. quant positive numeric value controlling gradient quantization error. Default 2.0. ang_th numeric value (0-180) defining gradient angle tolerance degrees. Default 22.5. log_eps numeric detection threshold. Larger values make detection stricter. Default 0.0. density_th numeric value (0-1) defining minimum proportion supporting points rectangle. Default 0.7. n_bins positive integer specifying number bins pseudo-ordering gradient modulus. Default 1024. union Logical. TRUE, merges close line segments. Default FALSE. union_min_length Numeric. Minimum segment length merge. Default 5. union_max_distance Numeric. Maximum distance segments merge. Default 5. union_ang_th Numeric. Angle threshold merging segments. Default 7. union_use_NFA Logical. TRUE, uses NFA merging. Default FALSE. union_log_eps Numeric. Detection threshold merging. Default 0.0.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_line_segment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Line Segment Detection in an Image — image_line_segment","text":"list class lsd containing: n - Number detected line segments. lines - matrix detected segments (columns: x1, y1, x2, y2, width, p, -log_nfa). pixels - matrix assigning pixel detected segment (0 = unused pixels).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_line_segment.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Line Segment Detection in an Image — image_line_segment","text":"Grompone von Gioi, R., Jakubowicz, J., Morel, J.-M., & Randall, G. (2010). LSD: Fast Line Segment Detector False Detection Control. IEEE Transactions Pattern Analysis Machine Intelligence, 32(4), 722-732.doi:10.5201/ipol.2012.gjmr-lsd","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_line_segment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Line Segment Detection in an Image — image_line_segment","text":"","code":"library(pliman)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_prepare.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare an image — image_prepare","title":"Prepare an image — image_prepare","text":"function aligns crops image using either base mapview visualization. useful prepare images analyzed analyze_objects_shp()","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_prepare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare an image — image_prepare","text":"","code":"image_prepare(   img,   viewer = get_pliman_viewer(),   downsample = NULL,   max_pixels = 1e+06 )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_prepare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare an image — image_prepare","text":"img optional Image object viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. downsample integer; dimension number pixels/lines/bands etc skipped; Defaults NULL, find best downsampling factor approximate max_pixels value. max_pixels integer > 0. Maximum number cells use plot. max_pixels < npixels(img), regular sampling used plotting.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_prepare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare an image — image_prepare","text":"alighed/cropped image visualization analysis.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_prepare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare an image — image_prepare","text":"","code":"# Example usage: if (interactive() && requireNamespace(\"EBImage\")) { img <- image_pliman(\"mult_leaves.jpg\") image_prepare(img, viewer = \"mapview\") }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment.html","id":null,"dir":"Reference","previous_headings":"","what":"Image segmentation — image_segment","title":"Image segmentation — image_segment","text":"image_segment() reduces color, color near-infrared, grayscale images segmented image using given color channel (red, green blue) even color indexes (See image_index() details). Otsu's thresholding method (Otsu, 1979) used automatically perform clustering-based image thresholding. image_segment_iter() Provides iterative image segmentation, returning proportions segmented pixels.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Image segmentation — image_segment","text":"","code":"image_segment(   img,   index = NULL,   r = 1,   g = 2,   b = 3,   re = 4,   nir = 5,   threshold = c(\"Otsu\", \"adaptive\"),   k = 0.1,   windowsize = NULL,   col_background = NULL,   na_background = FALSE,   has_white_bg = FALSE,   fill_hull = FALSE,   erode = FALSE,   dilate = FALSE,   opening = FALSE,   closing = FALSE,   filter = FALSE,   invert = FALSE,   plot = TRUE,   nrow = NULL,   ncol = NULL,   parallel = FALSE,   workers = NULL,   verbose = TRUE )  image_segment_iter(   img,   nseg = 2,   index = NULL,   invert = NULL,   threshold = NULL,   k = 0.1,   windowsize = NULL,   has_white_bg = FALSE,   plot = TRUE,   verbose = TRUE,   nrow = NULL,   ncol = NULL,   parallel = FALSE,   workers = NULL,   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Image segmentation — image_segment","text":"img image object list image objects. index image_segment(), character value (vector characters) specifying target mode conversion binary image. See available indexes pliman_indexes().  See image_index() details. image_segment_iter() character vector characters length nseg. can either available index (described ) operation involving RGB values (e.g., \"B/R+G\"). r, g, b, re, nir red, green, blue, red-edge, near-infrared bands image, respectively. Defaults 1, 2, 3, 4, 5, respectively. multispectral image provided (5 bands), check order bands, frequently presented 'BGR' format. threshold theshold method used. default (threshold = \"Otsu\"), threshold value based Otsu's method used reduce grayscale image binary image. numeric value informed, value used threshold. threshold = \"adaptive\", adaptive thresholding (Shafait et al. 2008) used, depend k windowsize arguments. non-numeric value different \"Otsu\" \"adaptive\" used, iterative section allow choose threshold based raster plot showing pixel intensity index. k numeric range 0-1. k high, local threshold values tend lower. k low, local threshold value tend higher. windowsize windowsize controls number local neighborhood adaptive thresholding. default set 1/3 * minxy, minxy minimum dimension image (pixels). col_background color segmented background. Defaults NULL (white background). na_background Consider background NA? Defaults FALSE. has_white_bg Logical indicating whether white background present. TRUE, pixels R, G, B values equals 1 considered NA. may useful compute image index objects , example, white background. cases, background considered threshold computation. fill_hull Fill holes objects? Defaults FALSE. erode, dilate, opening, closing, filter Morphological operations (brush size) dilate puts mask every background pixel, sets foreground pixels covered mask foreground. erode puts mask every foreground pixel, sets background pixels covered mask background. opening performs erosion followed dilation. helps remove small objects preserving shape size larger objects. closing performs dilatation followed erosion. helps fill small holes preserving shape size larger objects. filter performs median filtering binary image. Provide positive integer > 1 indicate size median filtering. Higher values efficient remove noise background can dramatically impact perimeter objects, mainly irregular perimeters leaves serrated edges. Hierarchically, operations performed opening > closing > filter. value declared argument define brush size. invert Inverts binary image, desired. image_segmentation_iter() use vector length nseg. plot Show image processing? nrow, ncol number rows columns plot grid. Defaults NULL, .e., square grid produced. parallel Processes images asynchronously (parallel) separate R sessions running background machine. may speed processing time image list. number sections set 70% available cores. workers positive numeric scalar function specifying maximum number parallel processes can active time. verbose TRUE (default) summary shown console. nseg number iterative segmentation steps performed. ... Additional arguments passed image_segment().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Image segmentation — image_segment","text":"image_segment() returns list containing n objects n number indexes used. objects contains: image image RGB bands (layers) segmented object. mask mask logical values 0 1 segmented image. image_segment_iter() returns list (1) data frame proportion pixels segmented images (2) segmented images.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Image segmentation — image_segment","text":"Nobuyuki Otsu, \"threshold selection method gray-level histograms\". IEEE Trans. Sys., Man., Cyber. 9 (1): 62-66. 1979. doi:10.1109/TSMC.1979.4310076","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Image segmentation — image_segment","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Image segmentation — image_segment","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"soybean_touch.jpg\", plot = TRUE) image_segment(img, index = c(\"R, G, B\")) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_kmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Image segmentation using k-means clustering — image_segment_kmeans","title":"Image segmentation using k-means clustering — image_segment_kmeans","text":"Segments image objects using clustering k-means clustering algorithm","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_kmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Image segmentation using k-means clustering — image_segment_kmeans","text":"","code":"image_segment_kmeans(   img,   bands = 1:3,   nclasses = 2,   invert = FALSE,   opening = FALSE,   closing = FALSE,   filter = FALSE,   erode = FALSE,   dilate = FALSE,   fill_hull = FALSE,   plot = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_kmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Image segmentation using k-means clustering — image_segment_kmeans","text":"img Image object. bands numeric integer/vector indicating RGB band used segmentation. Defaults 1:3, .e., RGB bands used. nclasses number desired classes image segmentation. invert Invert segmentation? Defaults FALSE. TRUE binary matrix inverted. erode, dilate, opening, closing, filter Morphological operations (brush size) dilate puts mask every background pixel, sets foreground pixels covered mask foreground. erode puts mask every foreground pixel, sets background pixels covered mask background. opening performs erosion followed dilation. helps remove small objects preserving shape size larger objects. closing performs dilatation followed erosion. helps fill small holes preserving shape size larger objects. filter performs median filtering binary image. Provide positive integer > 1 indicate size median filtering. Higher values efficient remove noise background can dramatically impact perimeter objects, mainly irregular perimeters leaves serrated edges. Hierarchically, operations performed opening > closing > filter. value declared argument define brush size. fill_hull Fill holes objects? Defaults FALSE. plot Plot segmented image?","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_kmeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Image segmentation using k-means clustering — image_segment_kmeans","text":"list following values: image segmented image considering two classes (foreground background) clusters class pixel. example, ncluster = 3, clusters two-way matrix values ranging 1 3. masks list binary matrices showing segmentation.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_kmeans.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Image segmentation using k-means clustering — image_segment_kmeans","text":"Hartigan, J. . Wong, M. . (1979). Algorithm 136: K-means clustering algorithm. Applied Statistics, 28, 100–108. doi:10.2307/2346830","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_kmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Image segmentation using k-means clustering — image_segment_kmeans","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { img <- image_pliman(\"la_leaves.jpg\", plot = TRUE) seg <- image_segment_kmeans(img) seg <- image_segment_kmeans(img, fill_hull = TRUE, invert = TRUE, filter = 10) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_manual.html","id":null,"dir":"Reference","previous_headings":"","what":"Image segmentation by hand — image_segment_manual","title":"Image segmentation by hand — image_segment_manual","text":"R code function allows user manually segment image based parameters provided. works interactive section.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_manual.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Image segmentation by hand — image_segment_manual","text":"","code":"image_segment_manual(   img,   shape = c(\"free\", \"circle\", \"rectangle\"),   type = c(\"select\", \"remove\"),   viewer = get_pliman_viewer(),   resize = TRUE,   edge = 5,   plot = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_manual.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Image segmentation by hand — image_segment_manual","text":"img Image object. shape type shape use. Defaults \"free\". possible values \"circle\" \"rectangle\". Partial matching allowed. type type segmentation. default (type = \"select\") objects selected. Use type = \"remove\" remove selected area image. viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. resize default, segmented object resized fill original image size. Use resize = FALSE keep segmented object original scale. edge Number pixels add edge segmented object resize = TRUE. Defaults 5. plot Plot segmented object? Defaults TRUE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_manual.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Image segmentation by hand — image_segment_manual","text":"list segmented image mask used segmentation.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_manual.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Image segmentation by hand — image_segment_manual","text":"shape \"free\", allows user draw perimeter select/remove objects. shape \"circle\", allows user click center edge circle define desired area. shape \"rectangle\", allows user select two points define area.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_manual.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Image segmentation by hand — image_segment_manual","text":"","code":"if (interactive()) { img <- image_pliman(\"la_leaves.jpg\") seg <- image_segment_manual(img) plot(seg$mask)  }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_mask.html","id":null,"dir":"Reference","previous_headings":"","what":"Segment an Image object using a brush mask — image_segment_mask","title":"Segment an Image object using a brush mask — image_segment_mask","text":"combines make_mask() make_brush() segment Image object using brush desired size, shape, position.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_mask.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Segment an Image object using a brush mask — image_segment_mask","text":"","code":"image_segment_mask(   img,   size,   shape = \"disc\",   rel_pos_x = 0.5,   rel_pos_y = 0.5,   type = c(\"binary\", \"shadow\"),   col_background = \"white\",   plot = TRUE,   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_mask.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Segment an Image object using a brush mask — image_segment_mask","text":"img Image object size numeric containing size brush pixels. odd number; even numbers rounded next odd one. shape character vector indicating shape brush. Can \"box\", \"disc\", \"diamond\", \"Gaussian\" \"line\" Defaults \"disc\". rel_pos_x, rel_pos_y relative position include brush image. Defaults 0.5. means brush centered original image. Smaller values move brush toward left top, respectively. type Defines type mask. default, binary mask applied. results white pixels original image matches 0s pixels brush. type = \"shadow\" used, shadow mask produced col_background Background color image segmentation. Defaults \"white\". plot Plots generated mask? Defaults TRUE. ... arguments passed EBImage::makeBrush().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_mask.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Segment an Image object using a brush mask — image_segment_mask","text":"color Image object","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_segment_mask.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Segment an Image object using a brush mask — image_segment_mask","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { img <- image_pliman(\"soybean_touch.jpg\") plot(img) image_segment_mask(img, size = 601) image_segment_mask(img,                    size = 401,                    shape = \"diamond\",                    rel_pos_x = 0,                    rel_pos_y = 0,                    type = \"shadow\") }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_shp.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a shape file from an image — image_shp","title":"Construct a shape file from an image — image_shp","text":"Creates list object coordinates given desired number nrow columns. starts selecting 4 points corners objects interest plot space. , given nrow ncol, grid drawn objects' coordinates returned.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_shp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a shape file from an image — image_shp","text":"","code":"image_shp(   img,   nrow = 1,   ncol = 1,   buffer_x = 0,   buffer_y = 0,   interactive = FALSE,   viewer = get_pliman_viewer(),   col_line = \"red\",   size_line = 2,   col_text = \"red\",   size_text = 1,   plot = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_shp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a shape file from an image — image_shp","text":"img object class Image nrow number desired rows grid. Defaults 1. ncol number desired columns grid. Defaults 1. buffer_x, buffer_y Buffering factor width height, respectively, individual shape's side. value 0 0.5 0 means buffering 0.5 means complete buffering (default: 0). value 0.25 buffer shape 25% side. interactive FALSE (default) grid created automatically based image dimension number rows/columns. interactive = TRUE, users must draw points diagonal desired bounding box contain grid. viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. col_line, col_text color line/text grid. Defaults \"red\". size_line, size_text size line/text grid. Defaults 2.5. plot Plots grid image? Defaults TRUE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_shp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct a shape file from an image — image_shp","text":"list row * col objects containing plot coordinates.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_shp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct a shape file from an image — image_shp","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) flax <- image_pliman(\"flax_leaves.jpg\") shape <- image_shp(flax, nrow = 3, ncol = 5) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_square.html","id":null,"dir":"Reference","previous_headings":"","what":"Squares an image — image_square","title":"Squares an image — image_square","text":"Converts rectangular image square image expanding rows/columns using image_expand().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_square.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Squares an image — image_square","text":"","code":"image_square(img, plot = TRUE, ...)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_square.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Squares an image — image_square","text":"img Image object. plot Plots extended image? defaults FALSE. ... arguments passed image_expand().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_square.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Squares an image — image_square","text":"modified Image object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_square.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Squares an image — image_square","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"soybean_touch.jpg\") dim(img) square <- image_square(img) dim(square) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_thinning_guo_hall.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform Guo-Hall thinning on a binary image or list of binary images — image_thinning_guo_hall","title":"Perform Guo-Hall thinning on a binary image or list of binary images — image_thinning_guo_hall","text":"function performs Guo-Hall thinning algorithm (Guo Hall, 1989) binary image list binary images.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_thinning_guo_hall.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform Guo-Hall thinning on a binary image or list of binary images — image_thinning_guo_hall","text":"","code":"image_thinning_guo_hall(   img,   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE,   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_thinning_guo_hall.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform Guo-Hall thinning on a binary image or list of binary images — image_thinning_guo_hall","text":"img binary image list binary images thinned. can either single binary image class 'Image' list binary images. parallel Logical, whether perform thinning using multiple cores (parallel processing). TRUE, function use multiple cores processing available. Default FALSE. workers Integer, number workers (cores) use parallel processing. NULL (default), use 40% available cores. verbose Logical, whether display progress messages parallel processing. Default TRUE. plot Logical, whether plot thinned images. Default FALSE. ... Additional arguments passed image_binary() img binary image.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_thinning_guo_hall.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform Guo-Hall thinning on a binary image or list of binary images — image_thinning_guo_hall","text":"img single binary image, function returns thinned binary image. img list binary images, function returns list containing thinned binary images.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_thinning_guo_hall.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Perform Guo-Hall thinning on a binary image or list of binary images — image_thinning_guo_hall","text":"Guo, Z., R.W. Hall. 1989. Parallel thinning two-subiteration algorithms. Commun. ACM 32(3): 359–373. doi:10.1145/62065.62074","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_thinning_guo_hall.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform Guo-Hall thinning on a binary image or list of binary images — image_thinning_guo_hall","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"potato_leaves.jpg\", plot = TRUE) image_thinning_guo_hall(img, index = \"R\", plot = TRUE) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_to_mat.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an image to a data.frame — image_to_mat","title":"Convert an image to a data.frame — image_to_mat","text":"Given object image, converts data frame row corresponds intensity values pixel image.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_to_mat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an image to a data.frame — image_to_mat","text":"","code":"image_to_mat(img, parallel = FALSE, workers = NULL, verbose = TRUE)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_to_mat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an image to a data.frame — image_to_mat","text":"img image object. parallel Processes images asynchronously (parallel) separate R sessions running background machine. may speed processing time image list. number sections set 70% available cores. workers positive numeric scalar function specifying maximum number parallel processes can active time. verbose TRUE (default) summary shown console.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_to_mat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an image to a data.frame — image_to_mat","text":"list containing three matrices (R, G, B), data frame containing four columns: name image image R, G, B values.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_to_mat.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert an image to a data.frame — image_to_mat","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_to_mat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert an image to a data.frame — image_to_mat","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"sev_leaf.jpg\") dim(img) mat <- image_to_mat(img) dim(mat[[1]]) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_view.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an interactive map view of an image — image_view","title":"Create an interactive map view of an image — image_view","text":"function allows users interactively edit analyze image using mapview mapedit packages.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_view.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an interactive map view of an image — image_view","text":"","code":"image_view(   img,   object = NULL,   r = 1,   g = 2,   b = 3,   edit = FALSE,   alpha = 0.7,   attribute = \"area\",   title = \"Edit the image\",   show = c(\"rgb\", \"index\"),   index = \"B\",   max_pixels = 1e+06,   downsample = NULL,   color_regions = custom_palette(),   quantiles = c(0, 1),   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_view.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an interactive map view of an image — image_view","text":"img Image object. object (Optional). object computed analyze_objects(). object informed, additional layer added plot, showing contour analyzed objects, color gradient defined attribute. r, g, b layer Red, Green Blue band, respectively. Defaults 1, 2, 3. edit TRUE enable editing options using mapedit::editMap(). alpha transparency level rectangles' color (0 1). attribute name quantitative variable object_index used coloring rectangles. title title map view. Use provide short orientations user. show display option map view. Options \"rgb\" RGB view \"index\" index view. index index use index view. Defaults \"B\". max_pixels integer > 0. Maximum number cells use plot. max_pixels < npixels(img), regular sampling used plotting. downsample integer; dimension number pixels/lines/bands etc skipped; Defaults NULL, find best downsampling factor approximate max_pixels value. color_regions color palette displaying index values. Default custom_palette(). quantiles upper lower quantiles used color stretching. Set c(0, 1) ... Additional arguments passed downsample_fun.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_view.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an interactive map view of an image — image_view","text":"sf object, object returned mapedit::editMap().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/image_view.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an interactive map view of an image — image_view","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { # Example usage: img <- image_pliman(\"sev_leaf.jpg\") image_view(img) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks.html","id":null,"dir":"Reference","previous_headings":"","what":"Create image landmarks — landmarks","title":"Create image landmarks — landmarks","text":"interactive section user able click image select landmarks manually open. mouse click, point drawn upward counter shown console. n counts user press Esc, interactive process interrupted data.frame x y coordinates landmarks returned.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create image landmarks — landmarks","text":"","code":"landmarks(   img,   n = Inf,   viewer = get_pliman_viewer(),   scale = NULL,   calibrate = FALSE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create image landmarks — landmarks","text":"img Image object. n number landmarks produce. Defaults Inf. case, landmarks chosen user press Esc. viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. scale known scale coordinate values. NULL (default) scale = 1 used. calibrate logical argument indicating whether calibration step must performed picking landmarks. , calibrate() called internally. Users must select two points indicate known distance. scale value internally computed used correction coordinates (pixels unit known distance).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create image landmarks — landmarks","text":"data.frame x y-coordinates landmarks.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create image landmarks — landmarks","text":"Claude, J. (2008) Morphometrics R, Use R! series, Springer 316 pp.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create image landmarks — landmarks","text":"","code":"if(isTRUE(interactive())){ library(pliman) img <- image_pliman(\"potato_leaves.jpg\") x <- landmarks(img) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_add.html","id":null,"dir":"Reference","previous_headings":"","what":"Artificially inflates the number of landmarks — landmarks_add","title":"Artificially inflates the number of landmarks — landmarks_add","text":"Interpolates supplementary landmarks correspond mean coordinates two adjacent landmarks.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_add.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Artificially inflates the number of landmarks — landmarks_add","text":"","code":"landmarks_add(x, n = 3, smooth_iter = 0, plot = TRUE, nrow = NULL, ncol = NULL)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_add.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Artificially inflates the number of landmarks — landmarks_add","text":"x matrix, data.frame list perimeter coordinates, often produced object_contour(), landmarks(), landmarks_regradi(). n number iterations. Defaults 3. smooth_iter number smoothing iterations perform. smooth perimeter interpolated landmarks using poly_smooth(). plot Creates plot? Defaults TRUE. ncol, nrow number rows columns plot grid list used x. Defaults NULL, .e., square grid produced.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_add.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Artificially inflates the number of landmarks — landmarks_add","text":"Matrix interpolated coordinates.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_add.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Artificially inflates the number of landmarks — landmarks_add","text":"","code":"library(pliman)  # equally spaced landmarks plot_polygon(contours[[4]]) ldm <- landmarks_regradi(contours[[4]], plot = FALSE) points(ldm$coords, pch = 16) segments(mean(ldm$coords[,1]),          mean(ldm$coords[,2]),          ldm$coords[,1],          ldm$coords[,2])  ldm_add <- landmarks_add(ldm, plot = FALSE) points(ldm_add, col = \"red\") points(ldm$coords, pch = 16)  # smoothed version ldm_add_smo <- landmarks_add(ldm, plot = FALSE, smooth_iter = 10) lines(ldm_add_smo, col = \"blue\", lwd = 3)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_angle.html","id":null,"dir":"Reference","previous_headings":"","what":"Angles between landmarks — landmarks_angle","title":"Angles between landmarks — landmarks_angle","text":"Computes angle two interlandmark vectors using difference arguments using complex vectors (Claude, 2008).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_angle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Angles between landmarks — landmarks_angle","text":"","code":"landmarks_angle(x, unit = c(\"rad\", \"deg\"))"},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_angle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Angles between landmarks — landmarks_angle","text":"x object computed landmarks(). unit unit angle. Defaults radian (rad). Use unit = \"deg\" return angles degrees.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_angle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Angles between landmarks — landmarks_angle","text":"matrix angles landmark combination.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_angle.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Angles between landmarks — landmarks_angle","text":"Borrowed Claude (2008), pp. 50","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_angle.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Angles between landmarks — landmarks_angle","text":"Claude, J. (2008) Morphometrics R, Use R! series, Springer 316 pp.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_angle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Angles between landmarks — landmarks_angle","text":"","code":"if(isTRUE(interactive())){ library(pliman) img <- image_pliman(\"potato_leaves.jpg\") x <- landmarks(img) landmarks_angle(x) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_dist.html","id":null,"dir":"Reference","previous_headings":"","what":"Distances between landmarks — landmarks_dist","title":"Distances between landmarks — landmarks_dist","text":"Computes distance two landmarks square root sum squared differences coordinate (Claude, 2008).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_dist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distances between landmarks — landmarks_dist","text":"","code":"landmarks_dist(x)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_dist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Distances between landmarks — landmarks_dist","text":"x object computed landmarks().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_dist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Distances between landmarks — landmarks_dist","text":"matrix distances landmark combination.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_dist.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Distances between landmarks — landmarks_dist","text":"Borrowed Claude (2008), pp. 49","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_dist.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Distances between landmarks — landmarks_dist","text":"Claude, J. (2008) Morphometrics R, Use R! series, Springer 316 pp.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_dist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Distances between landmarks — landmarks_dist","text":"","code":"if(isTRUE(interactive())){ library(pliman) img <- image_pliman(\"potato_leaves.jpg\") x <- landmarks(img) landmarks_dist(x) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_regradi.html","id":null,"dir":"Reference","previous_headings":"","what":"Pseudolandmarks with equally spaced angles — landmarks_regradi","title":"Pseudolandmarks with equally spaced angles — landmarks_regradi","text":"Select n landmarks spaced regular sequence angles taken outline coordinates centroid.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_regradi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pseudolandmarks with equally spaced angles — landmarks_regradi","text":"","code":"landmarks_regradi(   x,   n = 50,   close = TRUE,   plot = TRUE,   ncol = NULL,   nrow = NULL )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_regradi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pseudolandmarks with equally spaced angles — landmarks_regradi","text":"x matrix, data.frame list perimeter coordinates, often produced object_contour(). n Number points sampled. Defaults 50. close Return closed polygon? Defaults TRUE. plot Create plot? Defaults TRUE. ncol, nrow number rows columns plot grid list used x. Defaults NULL, .e., square grid produced.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_regradi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pseudolandmarks with equally spaced angles — landmarks_regradi","text":"list following objects: pixindices: Vector radius indices. radii: Vector sampled radii lengths. Xc: centroid coordinate x axis. Yc: centroid coordinate y axis. coords: Coordinates sampled points arranged two-column matrix. x list, list objects described returned.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_regradi.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Pseudolandmarks with equally spaced angles — landmarks_regradi","text":"Borrowed Claude (2008), pp. 53","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_regradi.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pseudolandmarks with equally spaced angles — landmarks_regradi","text":"Claude, J. (2008) Morphometrics R, Use R! series, Springer 316 pp.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/landmarks_regradi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pseudolandmarks with equally spaced angles — landmarks_regradi","text":"","code":"library(pliman) plot_polygon(contours[[1]])  ldm <- landmarks_regradi(contours)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/leading_zeros.html","id":null,"dir":"Reference","previous_headings":"","what":"Add leading zeros to a numeric sequence — leading_zeros","title":"Add leading zeros to a numeric sequence — leading_zeros","text":"Add n leading zeros numeric sequence. useful create character vector rename files folder.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/leading_zeros.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add leading zeros to a numeric sequence — leading_zeros","text":"","code":"leading_zeros(x, n = 3)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/leading_zeros.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add leading zeros to a numeric sequence — leading_zeros","text":"x numeric vector list numeric vectors. n number leading zeros add. Defaults 3.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/leading_zeros.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add leading zeros to a numeric sequence — leading_zeros","text":"character vector list character vectors.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/leading_zeros.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add leading zeros to a numeric sequence — leading_zeros","text":"","code":"library(pliman) leading_zeros(1:5) #> [1] \"001\" \"002\" \"003\" \"004\" \"005\" leading_zeros(list(a = 1:3,                    b = 1:5),               n = 2) #> $a #> [1] \"01\" \"02\" \"03\" #>  #> $b #> [1] \"01\" \"02\" \"03\" \"04\" \"05\" #>"},{"path":"https://nepem-ufsc.github.io/pliman/reference/line_on_halfplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract mid‐lines from half‐plots — line_on_halfplot","title":"Extract mid‐lines from half‐plots — line_on_halfplot","text":"polygon sf object, computes line segment joining midpoints longer pair opposite edges (“half‐plot line”).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/line_on_halfplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract mid‐lines from half‐plots — line_on_halfplot","text":"","code":"line_on_halfplot(shapefile)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/line_on_halfplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract mid‐lines from half‐plots — line_on_halfplot","text":"shapefile sf object polygons. geometry must closed (first last coordinate coincide) st_coordinates(...) yields repeating start point.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/line_on_halfplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract mid‐lines from half‐plots — line_on_halfplot","text":"SpatVector (terra package) line geometries representing half‐plot midlines.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/line_on_halfplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract mid‐lines from half‐plots — line_on_halfplot","text":"","code":"if(interactive()){ library(pliman) shp <- shapefile_input( paste0(image_pliman(), \"/soy_shape.rds\")) mosaic <- mosaic_input( paste0(image_pliman(), \"/soy_dsm.tif\")) mosaic_plot(mosaic) half <- line_on_halfplot(shp) shapefile_plot(half, add = TRUE, col = \"blue\")  }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/make_brush.html","id":null,"dir":"Reference","previous_headings":"","what":"Makes a brush — make_brush","title":"Makes a brush — make_brush","text":"Generates brushes various sizes shapes can used structuring elements. See EBImage::makeBrush().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/make_brush.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Makes a brush — make_brush","text":"","code":"make_brush(size, shape = \"disc\", ...)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/make_brush.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Makes a brush — make_brush","text":"size numeric containing size brush pixels. odd number; even numbers rounded next odd one. shape character vector indicating shape brush. Can \"box\", \"disc\", \"diamond\", \"Gaussian\" \"line\" Defaults \"disc\". ... arguments passed EBImage::makeBrush().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/make_brush.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Makes a brush — make_brush","text":"2D matrix 0s 1s containing desired brush.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/make_brush.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Makes a brush — make_brush","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { make_brush(size = 51) |> image() make_brush(size = 51, shape = \"diamond\") |> image() }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/make_mask.html","id":null,"dir":"Reference","previous_headings":"","what":"Makes a mask in an image — make_mask","title":"Makes a mask in an image — make_mask","text":"Make mask using Image object brush.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/make_mask.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Makes a mask in an image — make_mask","text":"","code":"make_mask(img, brush, rel_pos_x = 0.5, rel_pos_y = 0.5, plot = TRUE)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/make_mask.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Makes a mask in an image — make_mask","text":"img Image object brush object created make_brush() rel_pos_x, rel_pos_y relative position include brush image. Defaults 0.5. means brush centered original image. Smaller values move brush toward left top, respectively. plot Plots generated mask? Defaults TRUE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/make_mask.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Makes a mask in an image — make_mask","text":"binary image 0s 1s.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/make_mask.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Makes a mask in an image — make_mask","text":"applies brush Image, selecting Image pixels match brush values equal 1. position brush original image controlled relative positions x (rel_pos_x) y (rel_pos_y) arguments.  size brush must smaller equal smaller dimension image.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/make_mask.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Makes a mask in an image — make_mask","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { img <- image_pliman(\"soybean_touch.jpg\") make_mask(img, brush = make_brush(size = 201)) make_mask(img,           brush = make_brush(size = 401, shape = \"diamond\"),           rel_pos_x = 0.1,           rel_pos_y = 0.8) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease.html","id":null,"dir":"Reference","previous_headings":"","what":"Performs plant disease measurements — measure_disease","title":"Performs plant disease measurements — measure_disease","text":"measure_disease() computes percentage symptomatic leaf area (optionally) counts compute shapes (area, perimeter, radius, etc.) lesions sample entire leaf using color palettes. See Details. measure_disease_iter() provides iterative section measure_disease(), user picks samples image create needed color palettes.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performs plant disease measurements — measure_disease","text":"","code":"measure_disease(   img,   img_healthy = NULL,   img_symptoms = NULL,   img_background = NULL,   pattern = NULL,   opening = c(10, 0),   closing = c(0, 0),   filter = c(0, 0),   erode = c(0, 0),   dilate = c(0, 0),   parallel = FALSE,   workers = NULL,   resize = FALSE,   fill_hull = TRUE,   index_lb = NULL,   index_dh = \"GLI\",   has_white_bg = FALSE,   threshold = NULL,   invert = FALSE,   lower_noise = 0.1,   lower_size = NULL,   upper_size = NULL,   topn_lower = NULL,   topn_upper = NULL,   randomize = TRUE,   nsample = 3000,   watershed = FALSE,   lesion_size = \"medium\",   tolerance = NULL,   extension = NULL,   show_features = FALSE,   show_segmentation = FALSE,   plot = TRUE,   show_original = TRUE,   show_background = TRUE,   show_contour = TRUE,   contour_col = \"white\",   contour_size = 1,   col_leaf = NULL,   col_lesions = NULL,   col_background = NULL,   marker = FALSE,   marker_col = NULL,   marker_size = NULL,   save_image = FALSE,   prefix = \"proc_\",   name = NULL,   dir_original = NULL,   dir_processed = NULL,   verbose = TRUE )  measure_disease_iter(   img,   has_background = TRUE,   r = 3,   by_leaf = FALSE,   viewer = get_pliman_viewer(),   opening = c(10, 0),   closing = c(0, 0),   filter = c(0, 0),   erode = c(0, 0),   dilate = c(0, 0),   show = \"rgb\",   index = \"NGRDI\",   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performs plant disease measurements — measure_disease","text":"img image analyzed. img_healthy color palette healthy tissues. img_symptoms color palette lesioned tissues. img_background color palette background (exists). arguments can either Image object stored global environment character value. chacarceter used (eg., img_healthy = \"leaf\"), function search current working directory valid image contains \"leaf\" name. Note two images matches pattern, error occour. pattern pattern file name used identify images processed. example, pattern = \"im\" images name matches pattern (e.g., img1.-, image1.-, im2.-) analyzed. Providing number pattern (e.g., pattern = \"1\") select images named 1.-, 2.-, . erode, dilate, opening, closing, filter Morphological operations (brush size) dilate puts mask every background pixel, sets foreground pixels covered mask foreground. erode puts mask every foreground pixel, sets background pixels covered mask background. opening performs erosion followed dilation. helps remove small objects preserving shape size larger objects. closing performs dilatation followed erosion. helps fill small holes preserving shape size larger objects. filter performs median filtering binary image. Provide positive integer > 1 indicate size median filtering. Higher values efficient remove noise background can dramatically impact perimeter objects, mainly irregular perimeters leaves serrated edges. Hierarchically, operations performed opening > closing > filter. value declared argument define brush size. parallel Processes images asynchronously (parallel) separate R sessions running background machine. may speed processing time, especially pattern used informed. number sections set 30% available cores. workers positive numeric scalar function specifying maximum number parallel processes can active time. resize Resize image processing? Defaults FALSE. Use numeric value range 0-100 (proportion size original image). fill_hull Fill holes image? Defaults TRUE. useful fill holes leaves, e.g., caused insect attack, ensuring hole area accounted leaf, background. index_lb index used segment foreground (e.g., leaf) background. declared, entire image area (pixels) considered computation severity. index_dh index used segment diseased healthy tissues img_healthy img_symptoms declared. Defaults \"GLI\". See image_index() details. has_white_bg Logical indicating whether white background present. TRUE, pixels R, G, B values equals 1 considered NA. may useful compute image index objects , example, white background. cases, background considered threshold computation. threshold default (threshold = NULL), threshold value based Otsu's method used reduce grayscale image binary image. numeric value informed, value used threshold. Inform non-numeric value different \"Otsu\" iteratively choose threshold based raster plot showing pixel intensity index. Must vector length 2 indicate threshold index_lb index_dh, respectively. invert Inverts binary image desired. useful process images black background. Defaults FALSE. lower_noise default, lesions lesser 10% mean area lesions removed (lower_noise = 0.1). Increasing value remove larger lesions. define explicit lower upper size (pixel unit), use lower_size upper_size arguments. lower_size Lower limit size image analysis. Leaf images often contain dirt dust. prevent dust affecting image analysis, lower limit analyzed size set 0.1, .e., objects lesser 10% mean objects removed. One can set known area use lower_limit = 0 select objects (advised). upper_size Upper limit size image analysis. Defaults NULL, .e., upper limit used. topn_lower, topn_upper Select top n lesions based area. topn_lower selects n lesions smallest area whereas topn_upper selects n lesions largest area. randomize Randomize lines training model? Defaults TRUE. nsample number sample pixels used training step. Defaults 3000. watershed TRUE (Default) implements Watershed Algorithm segment lesions connected fairly pixels considered two distinct lesions. FALSE, lesions connected pixel considered unique lesions. details see EBImage::watershed(). lesion_size size lesion. Used automatically tune tolerance extension parameters. One following. \"small\" (2-5 mm diameter, e.g, rust pustules), \"medium\" (0.5-1.0 cm diameter, e.g, wheat leaf spot), \"large\" (1-2 cm diameter, \"elarge\" (2-3 cm diameter, e.g, target spot soybean). tolerance minimum height object units image intensity highest point (seed) point contacts another object (checked every contact pixel). height smaller tolerance, object combined one neighbors, highest. Defaults NULL, .e., starting values set according argument lesion_size. extension Radius neighborhood pixels detection neighboring objects. Defaults 20. Higher value smooths small objects. show_features TRUE returnS lesion features number, area, perimeter, radius. Defaults FALSE. show_segmentation Shows object segmentation colored random permutations. Defaults TRUE. plot Show image processing? Defaults TRUE. show_original Show symptoms original image? show_background Show background? Defaults TRUE. white background shown default show_original = FALSE. show_contour Show contour line around lesions? Defaults TRUE. contour_col, contour_size color size contour line around objects. Defaults contour_col = \"white\" contour_size = 1. col_leaf Leaf color image processing. Defaults \"green\" col_lesions Symptoms color image processing. Defaults \"red\". col_background Background color image processing. Defaults \"NULL\". marker, marker_col, marker_size type, color size object marker. Defaults NULL, shows nothing. Use marker = \"point\" show point lesion marker = \"*\" \"*\" variable name shape data frame returned function. save_image Save image processing? image saved current working directory named proc_* * image name given img. prefix prefix included processed images. Defaults \"proc_\". name name image save. Use overwrite name image img. dir_original, dir_processed directory containing original processed images. Defaults NULL. case, function search image img current working directory. processing, save_image = TRUE, processed image also saved directory. can either full path, e.g., \"C:/Desktop/imgs\", subfolder within current working directory, e.g., \"/imgs\". verbose TRUE (default) summary shown console. has_background logical indicating image background segmented processing. r radius neighborhood pixels. Defaults 2. square drawn indicating selected pixels. by_leaf Compute severity leaf? TRUE, measure_disease_byl() called internallty severity computed object (leaf) image. background segmentation controlled argument index. viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. show show option mapview viewer, either \"rgb\" \"index\". index index shown show = \"rgb\". ... parameters passed measure_disease().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performs plant disease measurements — measure_disease","text":"measure_disease() returns list following objects: severity data frame percentage healthy symptomatic areas. shape,statistics show_features = TRUE used, returns shape (area, perimeter, etc.) lesion summary statistic results. measure_disease_iter() returns list following objects: results list objects returned measure_disease(). leaf color palettes healthy leaf. disease color palettes diseased leaf. background color palettes background.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Performs plant disease measurements — measure_disease","text":"measure_disease(), general linear model (binomial family) fitted RGB values used segment lesions healthy leaf. pallet background provided, function takes care details isolate computing number area lesions. using pattern possible process several images common pattern names stored current working directory subdirectory informed dir_original. img_healthy img_symptoms declared, RGB-based phenotyping foliar disease severity performed using index informed index_lb first segment leaf background index_dh segment diseased healthy tissues. measure_disease_iter() run interactive section. function, users able pick samples images iteratively create needed color palettes. process calls pick_palette() internally. has_background TRUE (default) color palette background first created. sample colors performed left-button mouse click continues user press Esc. , new sampling process performed sample color healthy tissues diseased tissues. generated palettes passed measure_disease(). arguments function can passed using ... (three dots). show_features = TRUE, function computes total 36 lesion features (23 shape features 13 texture features). Haralick texture features object based gray-level co-occurrence matrix (Haralick et al. 1979). See details analyze_objects().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Performs plant disease measurements — measure_disease","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performs plant disease measurements — measure_disease","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"sev_leaf_nb.jpg\") healthy <- image_pliman(\"sev_healthy.jpg\") lesions <- image_pliman(\"sev_sympt.jpg\") image_combine(img, healthy, lesions, ncol = 3)  sev <-  measure_disease(img = img,                  img_healthy = healthy,                  img_symptoms = lesions,                  lesion_size = \"large\",                  plot = TRUE)  # an interactive section measure_disease_iter(img) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease_byl.html","id":null,"dir":"Reference","previous_headings":"","what":"Performs plant disease measurements by leaf — measure_disease_byl","title":"Performs plant disease measurements by leaf — measure_disease_byl","text":"Computes percentage symptomatic leaf area using color palettes RGB indexes leaf image. allows, example, processing replicates treatment  obtaining results replication single image. , leaf samples first splitten object_split() , measure_disease() applied list leaves.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease_byl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performs plant disease measurements by leaf — measure_disease_byl","text":"","code":"measure_disease_byl(   img,   index = \"B\",   index_lb = \"B\",   index_dh = \"NGRDI\",   lower_size = NULL,   watershed = TRUE,   invert = FALSE,   fill_hull = FALSE,   opening = c(10, 0),   closing = c(0, 0),   filter = c(0, 0),   erode = c(0, 0),   dilate = c(0, 0),   threshold = \"Otsu\",   extension = NULL,   tolerance = NULL,   object_size = \"large\",   img_healthy = NULL,   img_symptoms = NULL,   plot = TRUE,   save_image = FALSE,   dir_original = NULL,   dir_processed = NULL,   pattern = NULL,   parallel = FALSE,   workers = NULL,   show_features = FALSE,   verbose = TRUE,   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease_byl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performs plant disease measurements by leaf — measure_disease_byl","text":"img image analyzed. index character value specifying target mode conversion binary segment leaves background. Defaults \"B\" (blue). See image_index() details. Personalized indexes can informed , e.g., index = \"R*G/B. index_lb index used segment foreground (e.g., leaf) background. declared, entire image area (pixels) considered computation severity. index_dh index used segment diseased healthy tissues img_healthy img_symptoms declared. Defaults \"GLI\". See image_index() details. lower_size prevent dust affecting object segmentation, objects lesser 10% mean objects removed. . One can set known area use lower_limit = 0 select objects (advised). watershed TRUE (default) performs watershed-based object detection. detect objects even touching one . FALSE, pixels connected set foreground pixels set unique object. faster able segment touching objects. invert Inverts binary image desired. useful process images black background. Defaults FALSE. reference = TRUE use, invert can declared logical vector length 2 (eg., invert = c(FALSE, TRUE). case, segmentation objects reference foreground using back_fore_index performed using default (inverted), segmentation objects reference performed inverting selection (selecting pixels higher threshold). fill_hull Fill holes binary image? Defaults FALSE. useful fill holes objects portions color similar background. IMPORTANT: Objects touching can combined one single object, may underestimate number objects image. opening, closing, filter, erode, dilate Morphological operations (brush size) dilate puts mask every background pixel, sets foreground pixels covered mask foreground. erode puts mask every foreground pixel, sets background pixels covered mask background. opening performs erosion followed dilation. helps remove small objects preserving shape size larger objects. closing performs dilatation followed erosion. helps fill small holes preserving shape size larger objects. filter performs median filtering binary image. Provide positive integer > 1 indicate size median filtering. Higher values efficient remove noise background can dramatically impact perimeter objects, mainly irregular perimeters leaves serrated edges. threshold theshold method used. default (threshold = \"Otsu\"), threshold value based Otsu's method used reduce grayscale image binary image. numeric value informed, value used threshold. threshold = \"adaptive\", adaptive thresholding (Shafait et al. 2008) used, depend k windowsize arguments. non-numeric value different \"Otsu\" \"adaptive\" used, iterative section allow choose threshold based raster plot showing pixel intensity index. extension Radius neighborhood pixels detection neighboring objects. Higher value smooths small objects. tolerance minimum height object units image intensity highest point (seed) point contacts another object (checked every contact pixel). height smaller tolerance, object combined one neighbors, highest. object_size size object. Used automatically set tolerance extension parameters. One following. \"small\" (e.g, wheat grains), \"medium\" (e.g, soybean grains), \"large\"(e.g, peanut grains), \"elarge\" (e.g, soybean pods)`. img_healthy color palette healthy tissues. img_symptoms color palette lesioned tissues. plot Show image processing? save_image Save image processing? image saved current working directory named proc_* * image name given img. dir_original, dir_processed directory containing original processed images. Defaults NULL. case, function search image img current working directory. processing, save_image = TRUE, processed image also saved directory. can either full path, e.g., \"C:/Desktop/imgs\", subfolder within current working directory, e.g., \"/imgs\". pattern pattern file name used identify images processed. example, pattern = \"im\" images name matches pattern (e.g., img1.-, image1.-, im2.-) analyzed. Providing number pattern (e.g., pattern = \"1\") select images named 1.-, 2.-, . parallel Processes images asynchronously (parallel) separate R sessions running background machine. may speed processing time, especially pattern used informed. number sections set 30% available cores. workers positive numeric scalar function specifying maximum number parallel processes can active time. show_features TRUE returnS lesion features number, area, perimeter, radius. Defaults FALSE. verbose TRUE (default) summary shown console. ... Additional arguments passed measure_disease().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease_byl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performs plant disease measurements by leaf — measure_disease_byl","text":"list following objects: severity data frame percentage healthy symptomatic areas leaf image(s). shape,statistics show_features = TRUE used, returns shape (area, perimeter, etc.) lesion summary statistic results.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease_byl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performs plant disease measurements by leaf — measure_disease_byl","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"mult_leaves.jpg\", plot = TRUE) sev <-  measure_disease_byl(img = img,                      index_lb = \"B\",                      index_dh = \"NGRDI\",                      workers = 2) sev$severity }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease_shp.html","id":null,"dir":"Reference","previous_headings":"","what":"Measure disease using shapefiles — measure_disease_shp","title":"Measure disease using shapefiles — measure_disease_shp","text":"function calls measure_disease() image polygon shapefile object generated image_shp() bind results read-ready data frames.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease_shp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Measure disease using shapefiles — measure_disease_shp","text":"","code":"measure_disease_shp(   img,   nrow = 1,   ncol = 1,   buffer_x = 0,   buffer_y = 0,   prepare = FALSE,   viewer = \"mapview\",   index_lb = \"HUE2\",   index_dh = \"NGRDI\",   pattern = NULL,   threshold = NULL,   invert = FALSE,   dir_original = NULL,   show_features = FALSE,   interactive = FALSE,   plot = TRUE,   parallel = FALSE,   workers = NULL,   verbose = TRUE,   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease_shp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Measure disease using shapefiles — measure_disease_shp","text":"img image analyzed. Either image class Image character string containing image name. last, image searched root directory. Declare dir_original inform subfolder contains images processed. nrow, ncol number rows columns generate shapefile. Defaults 1. buffer_x, buffer_y Buffering factor width height, respectively, individual shape's side. value 0 0.5 0 means buffering 0.5 means complete buffering (default: 0). value 0.25 buffer shape 25% side. prepare Logical value indicating whether prepare image analysis using image_prepare() function. allows align crop image processing. Defaults FALSE. viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. index_lb index used segment foreground (e.g., leaf) background. declared, entire image area (pixels) considered computation severity. index_dh index used segment diseased healthy tissues img_healthy img_symptoms declared. Defaults \"GLI\". See image_index() details. pattern pattern file name used identify images processed. example, pattern = \"im\" images name matches pattern (e.g., img1.-, image1.-, im2.-) analyzed. Providing number pattern (e.g., pattern = \"1\") select images named 1.-, 2.-, . threshold default (threshold = NULL), threshold value based Otsu's method used reduce grayscale image binary image. numeric value informed, value used threshold. Inform non-numeric value different \"Otsu\" iteratively choose threshold based raster plot showing pixel intensity index. Must vector length 2 indicate threshold index_lb index_dh, respectively. invert Inverts binary image desired. useful process images black background. Defaults FALSE. dir_original directory containing original processed images. Defaults NULL. case, function search image img current working directory. show_features TRUE returnS lesion features number, area, perimeter, radius. Defaults FALSE. interactive FALSE (default) grid created automatically based image dimension number rows/columns. interactive = TRUE, users must draw points diagonal desired bounding box contain grid. plot Show image processing? Defaults TRUE. parallel Processes images asynchronously (parallel) separate R sessions running background machine. may speed processing time, especially pattern used informed. number sections set 30% available cores. workers positive numeric scalar function specifying maximum number parallel processes can active time. verbose TRUE (default) summary shown console. ... Aditional arguments passed measure_disease.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease_shp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Measure disease using shapefiles — measure_disease_shp","text":"object class plm_disease_byl. See details Value section measure_disease().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_disease_shp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Measure disease using shapefiles — measure_disease_shp","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { # severity for the three leaflets (from left to right) img <- image_pliman(\"mult_leaves.jpg\", plot = TRUE) sev <-  measure_disease_shp(img = img,                      nrow = 1,                      ncol = 3,                      index_lb = \"B\",                      index_dh = \"NGRDI\") sev$severity }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_injury.html","id":null,"dir":"Reference","previous_headings":"","what":"Measures Injury in Images — measure_injury","title":"Measures Injury in Images — measure_injury","text":"measures_injury function calculates percentage injury images performing binary segmentation identifying lesions. processes either single image batch images specified pattern directory.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_injury.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Measures Injury in Images — measure_injury","text":"","code":"measure_injury(   img = NULL,   pattern = NULL,   index = \"GRAY\",   threshold = \"Otsu\",   invert = FALSE,   opening = 5,   closing = FALSE,   filter = FALSE,   erode = FALSE,   dilate = FALSE,   plot = TRUE,   dir_original = NULL,   parallel = FALSE,   workers = NULL,   verbose = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_injury.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Measures Injury in Images — measure_injury","text":"img image analyzed. pattern pattern file name used identify images imported. example, pattern = \"im\" images current working directory name matches pattern (e.g., img1.-, image1.-, im2.-) imported list. Providing number pattern (e.g., pattern = \"1\") select images named 1.-, 2.-, . error returned pattern matches file supported (e.g., img1.pdf). index character value specifying target mode conversion binary image foreground background declared. Defaults \"NB\" (normalized blue). See image_index() details. User can also calculate index using bands names, e.g. index = \"R+B/G\" threshold theshold method used. default (threshold = \"Otsu\"), threshold value based Otsu's method used reduce grayscale image binary image. numeric value informed, value used threshold. threshold = \"adaptive\", adaptive thresholding (Shafait et al. 2008) used, depend k windowsize arguments. non-numeric value different \"Otsu\" \"adaptive\" used, iterative section allow choose threshold based raster plot showing pixel intensity index. invert Inverts binary image desired. useful process images black background. Defaults FALSE. reference = TRUE use, invert can declared logical vector length 2 (eg., invert = c(FALSE, TRUE). case, segmentation objects reference foreground using back_fore_index performed using default (inverted), segmentation objects reference performed inverting selection (selecting pixels higher threshold). opening, closing, filter, erode, dilate Morphological operations (brush size) dilate puts mask every background pixel, sets foreground pixels covered mask foreground. erode puts mask every foreground pixel, sets background pixels covered mask background. opening performs erosion followed dilation. helps remove small objects preserving shape size larger objects. closing performs dilatation followed erosion. helps fill small holes preserving shape size larger objects. filter performs median filtering binary image. Provide positive integer > 1 indicate size median filtering. Higher values efficient remove noise background can dramatically impact perimeter objects, mainly irregular perimeters leaves serrated edges. plot Show image processing? dir_original directory containing original processed images. Defaults NULL. case, function search image img current working directory. parallel TRUE processes images asynchronously (parallel) separate R sessions running background machine. may speed processing time, especially pattern used informed. object_index informed, multiple sections used extract RGB values object image. may significantly speed processing time image lots objects (say >1000). workers positive numeric scalar function specifying number parallel processes can active time. default, number sections set 30% available cores. verbose TRUE (default) summary shown console.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_injury.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Measures Injury in Images — measure_injury","text":"numeric value representing injury percentage single image, data frame injury percentages batch processing.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/measure_injury.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Measures Injury in Images — measure_injury","text":"function processes image reading , applying binary segmentation detect lesions, filling segmented areas, calculating injury percentage, optionally saving processed image highlighted lesions. batch mode, uses provided pattern identify images specified directory can utilize parallel processing efficiency.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_aggregate.html","id":null,"dir":"Reference","previous_headings":"","what":"SpatRaster aggregation — mosaic_aggregate","title":"SpatRaster aggregation — mosaic_aggregate","text":"Aggregate SpatRaster create new SpatRaster lower resolution (larger cells), using GDAL's gdal_translate utility https://gdal.org/programs/gdal_translate.html","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_aggregate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SpatRaster aggregation — mosaic_aggregate","text":"","code":"mosaic_aggregate(mosaic, pct = 50, fun = \"nearest\", in_memory = TRUE)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_aggregate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SpatRaster aggregation — mosaic_aggregate","text":"mosaic SpatRaster pct size fraction (percentage) input image size. Either scalar (eg., 50), length-two numeric vector. last, different percentage reduction/expansion can used columns, rows, respectively. fun resampling function. Defaults nearest, applies nearest neighbor (simple sampling) resampler. accepted values : 'average', 'rms', 'bilinear', 'cubic', 'cubicspline', 'lanczos', 'mode'. See Details detailed explanation. in_memory Wheter return '-memory' SpatRaster. FALSE, aggregated raster returned '-disk' object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_aggregate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"SpatRaster aggregation — mosaic_aggregate","text":"SpatRaster","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_aggregate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"SpatRaster aggregation — mosaic_aggregate","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) library(terra) r <- rast() values(r) <- 1:ncell(r) r2 <- mosaic_aggregate(r, pct = 10) opar <- par(no.readonly = TRUE) par(mfrow=c(1,2)) mosaic_plot(r) mosaic_plot(r2) par(opar) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_analyze.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze a mosaic of remote sensing data — mosaic_analyze","title":"Analyze a mosaic of remote sensing data — mosaic_analyze","text":"function analyzes mosaic remote sensing data (UVAs satellite imagery), extracting information specified regions interest (ROIs) defined shapefile interactively drawn mosaic. allows counting measuring individuals (eg., plants), computing canopy coverage, statistical summaries (eg., mean, coefficient variation) vegetation indices (eg, NDVI) block, plot, individual levels even extract raw results pixel level.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_analyze.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze a mosaic of remote sensing data — mosaic_analyze","text":"","code":"mosaic_analyze(   mosaic,   r = 3,   g = 2,   b = 1,   re = NA,   nir = NA,   swir = NA,   tir = NA,   crop_to_shape_ext = TRUE,   grid = TRUE,   nrow = 1,   ncol = 1,   plot_width = NULL,   plot_height = NULL,   layout = \"lrtb\",   indexes = NULL,   shapefile = NULL,   basemap = NULL,   build_shapefile = TRUE,   check_shapefile = TRUE,   buffer_edge = 1,   buffer_col = 0,   buffer_row = 0,   segment_plot = FALSE,   segment_individuals = FALSE,   segment_pick = FALSE,   mask = NULL,   dsm = NULL,   dsm_lower = 0.2,   dsm_upper = NULL,   dsm_window_size = c(5, 5),   simplify = FALSE,   map_individuals = FALSE,   map_direction = c(\"horizontal\", \"vertical\"),   watershed = TRUE,   tolerance = 1,   extension = 1,   include_if = \"centroid\",   plot_index = \"GLI\",   segment_index = NULL,   threshold = \"Otsu\",   opening = FALSE,   closing = FALSE,   filter = FALSE,   erode = FALSE,   dilate = FALSE,   lower_noise = 0.15,   lower_size = NULL,   upper_size = NULL,   topn_lower = NULL,   topn_upper = NULL,   summarize_fun = \"mean\",   summarize_quantiles = NULL,   attribute = NULL,   invert = FALSE,   color_regions = rev(grDevices::terrain.colors(50)),   alpha = 1,   max_pixels = 2e+06,   downsample = NULL,   quantiles = c(0, 1),   plot = TRUE,   verbose = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_analyze.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze a mosaic of remote sensing data — mosaic_analyze","text":"mosaic mosaic class SpatRaster, generally imported mosaic_input(). r, g, b, re, nir, swir, tir red, green, blue, red-edge,  near-infrared, shortwave Infrared, thermal infrared bands image, respectively. default, function assumes BGR input (b = 1, g = 2, r = 3). multispectral image provided seven bands can used compute built-indexes. limitation band numbers index computed using band name. crop_to_shape_ext Crop mosaic extension shapefile? Defaults TRUE. allows faster index computation region built shapefile much smaller entire mosaic extension. grid Logical, indicating whether use grid segmentation (default: TRUE). nrow Number rows grid (default: 1). ncol Number columns grid (default: 1). plot_width, plot_height width height plot shape (mosaic unit). mutually exclusiv buffer_col buffer_row. layout Character: one 'tblr' top/bottom left/right orientation 'tbrl' top/bottom right/left orientation 'btlr' bottom/top left/right orientation 'btrl' bottom/top right/left orientation 'lrtb' left/right top/bottom orientation 'lrbt' left/right bottom/top orientation 'rltb' right/left top/bottom orientation 'rlbt' right/left bottom/top orientation indexes optional SpatRaster object image indexes, computed mosaic_index(). shapefile optional shapefile containing regions interest (ROIs) analysis. basemap optional basemap generated mosaic_view(). build_shapefile Logical, indicating whether interactively draw ROIs shapefile NULL (default: TRUE). check_shapefile Logical, indicating whether validate shapefile interactive map view (default: TRUE). enables live editing drawn shapefile deleting changing drawn grids. buffer_edge Width buffer around shapefile (default: 5). buffer_col, buffer_row Buffering factor columns rows, respectively, individual plot's side. value 0 0.5 0 means buffering 0.5 means complete buffering (default: 0). value 0.25 buffer plot 25% side. segment_plot Logical, indicating whether segment plots (default: FALSE). TRUE, segment_index computed, pixels values threshold selected. segment_individuals Logical, indicating whether segment individuals within plots (default: FALSE). TRUE, segment_index computed, pixels values threshold selected, watershed-based segmentation performed. segment_pick segment_plot segment_individuals TRUE, segment_pick allows segmenting background (eg., soil) foreground (eg., plants) interactively picking samples background foreground using mosaic_segment_pick() mask optional mask (SpatRaster) mask mosaic. dsm SpatRaster object representing digital surface model. Must single-layer raster. DSM informed, mask derived using mosaic_chm_mask(). dsm_lower numeric value specifying lower height threshold. heights greater value retained. dsm_upper optional numeric value specifying upper height threshold. provided, heights lower upper retained. dsm_window_size integer (meters) specifying window size (rows columns, respectively) creating DTM using moving window. Default c(5, 5). simplify Removes vertices polygons form simpler shapes. function implementation uses Douglas-Peucker algorithm using sf::st_simplify() simplification. map_individuals TRUE, distance objects within plots computed. distance can mapped either horizontal vertical direction. distances, coefficient variation (CV), mean distances returned. map_direction direction mapping individuals within plots. one \"horizontal\" \"vertical\" (default). watershed TRUE (default), performs watershed-based object detection. detect objects even touching one another. FALSE, pixels connected set foreground pixels set unique object. faster able segment touching objects. tolerance minimum height object units image intensity highest point (seed) point contacts another object (checked every contact pixel). height smaller tolerance, object combined one neighbors, highest. extension Radius neighborhood pixels detection neighboring objects. higher value smooths small objects. include_if Character vector specifying type intersection. Defaults \"centroid\" (individuals centroid included within drawn plot included plot). possible values include \"covered\", \"overlap\", \"intersect\". See Details detailed explanation intersecting controls. plot_index index(es) computed drawn plots. Either single vegetation index (e.g., \"GLAI\"), vector indexes (e.g., c(\"GLAI\", \"NGRDI\", \"HUE\")), custom index based available bands (e.g., \"(R-B)/(R+B)\"). See pliman_indexes() image_index() details. segment_index index used segmentation. rule plot_index. Defaults NULL threshold default (threshold = \"Otsu\"), threshold value based Otsu's method used reduce grayscale image binary image. numeric value provided, value used threshold. opening, closing, filter, erode, dilate Morphological operations (brush size) dilate puts mask every background pixel, sets foreground pixels covered mask foreground. erode puts mask every foreground pixel, sets background pixels covered mask background. opening performs erosion followed dilation. helps remove small objects preserving shape size larger objects. closing performs dilatation followed erosion. helps fill small holes preserving shape size larger objects. filter performs median filtering binary image. Provide positive integer > 1 indicate size median filtering. Higher values efficient remove noise background can dramatically impact perimeter objects, mainly irregular perimeters leaves serrated edges. lower_noise prevent noise affecting image analysis, objects lesser 10% mean area objects removed (lower_noise = 0.1). Increasing value remove larger noises (dust points), can remove desired objects . define explicit lower upper size, use lower_size upper_size arguments. lower_size, upper_size Lower upper limits size image analysis. Plant images often contain dirt dust.  Upper limit set NULL, .e., upper limit used. One can set known area use lower_size = 0 select objects (advised). Objects matches size given range sizes can selected setting two arguments. example, lower_size = 120 upper_size = 140, objects size greater equal 120 less equal 140 considered. topn_lower, topn_upper Select top n objects based area. topn_lower selects n elements smallest area whereas topn_upper selects n objects largest area. summarize_fun function compute summaries pixel values. Defaults \"mean,\" .e., mean value pixels (either plot- individual-level) returned. summarize_quantiles quantiles computed 'quantile' summarize_fun. attribute attribute shown plot plot TRUE. Defaults first summary_fun first segment_index. invert Logical, indicating whether invert mask. Defaults FALSE, .e., pixels intensity greater threshold values selected. color_regions color palette regions (default: rev(grDevices::terrain.colors(50))). alpha opacity fill color raster layer(s). max_pixels Maximum number pixels render map plot (default: 500000). downsample Downsampling factor reduce number pixels (default: NULL). case, number pixels image (width x height) greater max_pixels downsampling factor automatically chosen number plotted pixels approximates max_pixels. quantiles upper lower quantiles used color stretching. plot Logical, indicating whether generate plots (default: TRUE). verbose Logical, indicating whether display verbose output (default: TRUE).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_analyze.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze a mosaic of remote sensing data — mosaic_analyze","text":"list containing following objects: result_plot: results plot level. result_plot_summ: summary results plot level. segment_individuals = TRUE, number individuals, canopy coverage, mean values shape statistics perimeter, length, width, diameter computed. result_individ: results individual level. map_plot: object class mapview showing plot-level results. map_individual: object class mapview showing individual-level results. shapefile: generated shapefile, drawn grids/blocks.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_analyze.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Analyze a mosaic of remote sensing data — mosaic_analyze","text":"Since multiple blocks can analyzed, length arguments grid, nrow, ncol, buffer_edge, , buffer_col, buffer_row, segment_plot, segment_i, ndividuals, includ_if, threshold, segment_index, invert, filter, threshold, lower_size, upper_size, watershed, lower_noise, can either scalar (argument applied drawn blocks), vector length number drawn. last, block can analyzed different arguments. segment_individuals = TRUE enabled, individuals included within plot based include_if argument. default value ('centroid') includes object given plot centroid object within plot. makes inclusion mutually exclusive (.e., individual included one plot). 'covered' selected, objects included entire area covered plot. hand, selecting overlap complement covered; words, objects overlap plot boundary included. Finally, intersect chosen, objects intersect plot boundary included. makes inclusion ambiguous (.e., object can included one plot).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_analyze.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyze a mosaic of remote sensing data — mosaic_analyze","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) url <- \"https://github.com/TiagoOlivoto/images/raw/master/pliman/rice_field/rice_ex.tif\" mosaic <- mosaic_input(url) # Draw a polygon (top left, top right, bottom right, bottom left, top left) # include 8 rice lines and one column res <-  mosaic_analyze(mosaic,                 r = 1, g = 2, b = 3,                 segment_individuals = TRUE,     # segment the individuals                 segment_index = \"(G-B)/(G+B-R)\",# index for segmentation                 filter = 4,                 nrow = 8,                 map_individuals = TRUE) # map with individual results res$map_indiv }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_analyze_iter.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze mosaics iteratively — mosaic_analyze_iter","title":"Analyze mosaics iteratively — mosaic_analyze_iter","text":"High-resolution mosaics can take significant amount time analyze, especially segment_individuals = TRUE used mosaic_analyze(). function needs create -memory arrays segment individual using watershed algorithm. process utilizes -loop approach, iteratively analyzing shape within mosaic one time. speed processing, function crops original mosaic extent current shape analyzing . reduces resolution specific analysis, sacrificing detail faster processing.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_analyze_iter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze mosaics iteratively — mosaic_analyze_iter","text":"","code":"mosaic_analyze_iter(   mosaic,   shapefile,   basemap = NULL,   r = 3,   g = 2,   b = 1,   re = NA,   nir = NA,   swir = NA,   tir = NA,   plot = TRUE,   verbose = TRUE,   max_pixels = 3e+06,   attribute = NULL,   summarize_fun = \"mean\",   segment_plot = FALSE,   segment_individuals = FALSE,   segment_index = \"VARI\",   plot_index = \"VARI\",   color_regions = rev(grDevices::terrain.colors(50)),   alpha = 0.75,   quantiles = c(0, 1),   parallel = FALSE,   workers = NULL,   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_analyze_iter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze mosaics iteratively — mosaic_analyze_iter","text":"mosaic mosaic class SpatRaster, generally imported mosaic_input(). shapefile optional shapefile containing regions interest (ROIs) analysis. basemap optional basemap generated mosaic_view(). r, g, b, re, nir, swir, tir red, green, blue, red-edge,  near-infrared, shortwave Infrared, thermal infrared bands image, respectively. default, function assumes BGR input (b = 1, g = 2, r = 3). multispectral image provided seven bands can used compute built-indexes. limitation band numbers index computed using band name. plot Logical, indicating whether generate plots (default: TRUE). verbose Logical, indicating whether display verbose output (default: TRUE). max_pixels Maximum number pixels render map plot (default: 500000). attribute attribute shown plot plot TRUE. Defaults first summary_fun first segment_index. summarize_fun function compute summaries pixel values. Defaults \"mean,\" .e., mean value pixels (either plot- individual-level) returned. segment_plot Logical, indicating whether segment plots (default: FALSE). TRUE, segment_index computed, pixels values threshold selected. segment_individuals Logical, indicating whether segment individuals within plots (default: FALSE). TRUE, segment_index computed, pixels values threshold selected, watershed-based segmentation performed. segment_index index used segmentation. rule plot_index. Defaults NULL plot_index index(es) computed drawn plots. Either single vegetation index (e.g., \"GLAI\"), vector indexes (e.g., c(\"GLAI\", \"NGRDI\", \"HUE\")), custom index based available bands (e.g., \"(R-B)/(R+B)\"). See pliman_indexes() image_index() details. color_regions color palette regions (default: rev(grDevices::terrain.colors(50))). alpha opacity fill color raster layer(s). quantiles upper lower quantiles used color stretching. parallel TRUE processes images asynchronously (parallel) separate R sessions running background machine. may speed processing time, especially pattern used informed. object_index informed, multiple sections used extract RGB values object image. may significantly speed processing time image lots objects (say >1000). workers positive numeric scalar function specifying number parallel processes can active time. default, number sections set 30% available cores. ... arguments passed mosaic_analyze()","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_analyze_iter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze mosaics iteratively — mosaic_analyze_iter","text":"list containing following objects: result_plot: results plot level. result_plot_summ: summary results plot level. segment_individuals = TRUE, number individuals, canopy coverage, mean values shape statistics perimeter, length, width, diameter computed. result_individ: results individual level. map_plot: object class mapview showing plot-level results. map_individual: object class mapview showing individual-level results.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_chm.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Canopy Height Model and Volume — mosaic_chm","title":"Calculate Canopy Height Model and Volume — mosaic_chm","text":"function calculates canopy height model (CHM) volume given digital surface model (DSM) raster layer. Optionally, digital terrain model (DTM) can provided interpolated using set points moving window.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_chm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Canopy Height Model and Volume — mosaic_chm","text":"","code":"mosaic_chm(   dsm,   dtm = NULL,   points = NULL,   interpolation = c(\"Tps\", \"Kriging\"),   window_size = c(5, 5),   ground_quantile = 0,   mask = NULL,   mask_soil = TRUE,   verbose = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_chm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Canopy Height Model and Volume — mosaic_chm","text":"dsm SpatRaster object representing digital surface model. Must single-layer raster. dtm (optional) SpatRaster object representing digital terrain model. Must single-layer raster. provided, can interpolated points created using moving window. points (optional) sf object representing sample points DTM interpolation. provided, dtm interpolated using points. interpolation (optional) character string specifying interpolation method use points provided. Options \"Kriging\" (default) \"Tps\" (Thin Plate Spline). window_size integer  (meters) specifying window size (rows columns, respectively) creating DTM using moving window. Default c(10, 10). ground_quantile Numeric value 0 1 indicating quantile threshold ground point selection CHM computation. Lower values (e.g., 0) retain lowest ground points, higher values (e.g., 1) consider higher ground elevations. Default 0, uses lowest points within window. mask (optional) SpatRaster object used mask CHM volume results. Default NULL. mask_soil mask representing soil mask (eg., removing plants)? Default TRUE. verbose Return progress messages. Default TRUE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_chm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Canopy Height Model and Volume — mosaic_chm","text":"SpatRaster object three layers: dtm (digital terrain model), height (canopy height model), volume.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_chm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Canopy Height Model and Volume — mosaic_chm","text":"function first checks input dsm valid single-layer SpatRaster object. dtm provided, function generates Digital Terrain Model (DTM) Digital Surface Model (DSM) downsampling smoothing input raster data. iterates DSM matrix windows specified size, finds minimum value within window, assigns values downsampled matrix. downsampling, function applies mean filter smooth matrix, enhancing visual analytical quality DTM. Afterwards, DTM resampled original DSM. dsm dtm provided, function ensures extent number cells, resampling dtm necessary. CHM calculated difference dsm dtm, volume calculated multiplying CHM pixel size. results optionally masked using provided mask.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_chm_extract.html","id":null,"dir":"Reference","previous_headings":"","what":"Extracts height metrics and plot quality from a Canopy Height Model (CHM) — mosaic_chm_extract","title":"Extracts height metrics and plot quality from a Canopy Height Model (CHM) — mosaic_chm_extract","text":"function extracts height-related summary statistics CHM using given shapefile.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_chm_extract.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extracts height metrics and plot quality from a Canopy Height Model (CHM) — mosaic_chm_extract","text":"","code":"mosaic_chm_extract(chm, shapefile, chm_threshold = NULL)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_chm_extract.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extracts height metrics and plot quality from a Canopy Height Model (CHM) — mosaic_chm_extract","text":"chm object computed mosaic_chm(). shapefile sf object containing polygons height metrics extracted. chm_threshold numeric value representing height threshold calculating coverage. NULL, coverage computed.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_chm_extract.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extracts height metrics and plot quality from a Canopy Height Model (CHM) — mosaic_chm_extract","text":"sf object containing height summary statistics plot, including: min: Minimum height value. q05: 5th percentile height value. q50: Median height value. q95: 95th percentile height value. max: Maximum height value. mean: Mean height value. volume: Total sum heights multiplied CHM resolution. coverage: mask used mosaic_chm() chm_threshold informed, returns proportion pixels covered within plot. Otherwise, returns 1.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_chm_mask.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply a height mask to CHM data — mosaic_chm_mask","title":"Apply a height mask to CHM data — mosaic_chm_mask","text":"function applies height-based mask Canopy Height Model (CHM), focusing areas heights specified lower threshold , optionally, upper threshold.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_chm_mask.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply a height mask to CHM data — mosaic_chm_mask","text":"","code":"mosaic_chm_mask(   dsm,   lower,   upper = NULL,   window_size = c(5, 5),   interpolation = \"Tps\" )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_chm_mask.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply a height mask to CHM data — mosaic_chm_mask","text":"dsm SpatRaster object representing digital surface model. Must single-layer raster. lower numeric value specifying lower height threshold. heights greater value retained. upper optional numeric value specifying upper height threshold. provided, heights lower upper retained. window_size integer  (meters) specifying window size (rows columns, respectively) creating DTM using moving window. Default c(10, 10). interpolation (optional) character string specifying interpolation method use points provided. Options \"Kriging\" (default) \"Tps\" (Thin Plate Spline).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_chm_mask.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply a height mask to CHM data — mosaic_chm_mask","text":"SpatRaster object representing masked CHM.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_chm_mask.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply a height mask to CHM data — mosaic_chm_mask","text":"mosaic_chm function, used internally, generates DTM DSM downsampling smoothing raster data, applying moving window extract minimum values interpolating results. CHM computed height difference DSM DTM. function calculates applies mask based height thresholds.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_classify.html","id":null,"dir":"Reference","previous_headings":"","what":"Classify a Mosaic Based on Index Breaks — mosaic_classify","title":"Classify a Mosaic Based on Index Breaks — mosaic_classify","text":"function classifies given raster mosaic based user-defined breaks. provides option calculate frequency area class, well plot classified mosaic.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_classify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classify a Mosaic Based on Index Breaks — mosaic_classify","text":"","code":"mosaic_classify(mosaic, breaks, frequency = TRUE, plot = TRUE)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_classify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classify a Mosaic Based on Index Breaks — mosaic_classify","text":"mosaic SpatRaster object representing mosaic classified. breaks numeric vector specifying breakpoints classification. frequency Logical. TRUE, computes class frequency area (hectares). plot Logical. TRUE, plots classified mosaic.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_classify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classify a Mosaic Based on Index Breaks — mosaic_classify","text":"list two elements: classified: SpatRaster object containing classified mosaic. class_freq: data frame containing class frequencies, areas (ha), percentages (frequency = TRUE).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_classify.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Classify a Mosaic Based on Index Breaks — mosaic_classify","text":"","code":"if(interactive()){ library(pliman) library(terra)  # Create an example raster r <- terra::rast(matrix(runif(100, min = 0, max = 1), nrow=10, ncol=10))  # Classify the raster result <- mosaic_classify(r, breaks = c(0.3, 0.6))  # View results result$classified result$class_freq }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_clip.html","id":null,"dir":"Reference","previous_headings":"","what":"Clip Raster Mosaic by Polygons — mosaic_clip","title":"Clip Raster Mosaic by Polygons — mosaic_clip","text":"Quickly partition large raster mosaic individual tiles using polygon layer.  tile clipped either polygon's bounding box (optionally) exact feature geometry, written disk separate GeoTIFF named feature's unique_id.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_clip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clip Raster Mosaic by Polygons — mosaic_clip","text":"","code":"mosaic_clip(   mosaic,   shapefile,   unique_id = \"unique_id\",   out_dir = NULL,   overwrite = TRUE,   verbose = TRUE,   exact = FALSE,   parallel = FALSE,   workers = NULL )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_clip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clip Raster Mosaic by Polygons — mosaic_clip","text":"mosaic terra::SpatRaster object file path pointing raster. -memory rasters first written temporary GeoTIFF. shapefile sf::sf, terra::SpatVector, path vector file.  Must contain column named unique_id naming output tile. unique_id column present shapefile uniquely identifies plots clipped. out_dir Directory clipped rasters saved.  Defaults current working directory.  Created recursively exist. overwrite Logical; TRUE (default), existing files out_dir name overwritten. verbose Logical; TRUE (default), progress bars status messages shown. exact Logical; FALSE (default), tiles cropped feature's bounding box.  TRUE, function extracts polygon cutline exact crop (slower, shape-accurate). parallel Logical; TRUE (default), processing parallelized using mirai. Set FALSE purely sequential execution. workers Integer; number parallel daemons launch parallel = TRUE. Defaults 70% available cores.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_clip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clip Raster Mosaic by Polygons — mosaic_clip","text":"Invisibly returns character vector file paths clipped GeoTIFFs.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_clip.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Clip Raster Mosaic by Polygons — mosaic_clip","text":"Clip Raster Mosaic Polygons function wraps GDAL's warp utility efficient raster clipping. parallel = TRUE, spawn multiple workers via mirai process tiles batches.  Use exact = TRUE clip true polygon shape (extra cost), leave exact = FALSE faster bounding-box crop.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_crop.html","id":null,"dir":"Reference","previous_headings":"","what":"Crop or Mask a Mosaic Raster — mosaic_crop","title":"Crop or Mask a Mosaic Raster — mosaic_crop","text":"function allows cropping raster mosaic interactively programmatically: Interactive Mode: neither shapefile mosaic2 provided, interactive map shown via mosaic_view(), allowing users draw rectangle define cropping area. Shapefile Mode: SpatVector provided shapefile, cropping masking performed based extent exact shape, optionally buffer. Raster Mode: mosaic2 provided, mosaic cropped match extent mosaic2. disk-based mosaics, cropping shapefiles uses GDAL (sf::gdal_utils()) improve efficiency.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_crop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Crop or Mask a Mosaic Raster — mosaic_crop","text":"","code":"mosaic_crop(   mosaic,   r = 3,   g = 2,   b = 1,   re = 4,   nir = 5,   shapefile = NULL,   in_memory = FALSE,   mosaic2 = NULL,   buffer = 0,   show = c(\"rgb\", \"index\"),   index = \"R\",   max_pixels = 5e+05,   downsample = NULL,   type = c(\"crop\", \"mask\"),   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_crop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Crop or Mask a Mosaic Raster — mosaic_crop","text":"mosaic SpatRaster object cropped. r, g, b, re, nir Integer indices representing red, green, blue, red-edge, near-infrared bands input mosaic. Default assumes BGR format (b = 1, g = 2, r = 3). shapefile optional SpatVector (sf object) use cropping/masking geometry. Can created interactively shapefile_input(). in_memory Logical. TRUE, raster processing occur entirely memory using terra. FALSE (default), disk-based processing GDAL used appropriate. mosaic2 second SpatRaster whose extent used crop mosaic. buffer numeric value indicating buffer (CRS units) apply around shapefile geometry. show character value indicating display interactive viewer. Either \"rgb\" \"index\". index index show show = \"index\". Default \"R\". max_pixels Maximum number pixels render interactive viewer. downsample Optional downsampling factor display purposes. type Either \"crop\" (default) \"mask\": \"crop\" crops mosaic bounding box shapefile. \"mask\" sets pixels outside shapefile geometry NA (recommended using exact shapes). ... Additional arguments passed mosaic_view().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_crop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Crop or Mask a Mosaic Raster — mosaic_crop","text":"cropped masked SpatRaster object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_crop.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Crop or Mask a Mosaic Raster — mosaic_crop","text":"Crop mask SpatRaster object (mosaic) based user input interactive map using provided shapefile another raster.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_crop.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Crop or Mask a Mosaic Raster — mosaic_crop","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) {   library(pliman)   # Load a sample raster   mosaic <- mosaic_input(system.file(\"ex/elev.tif\", package = \"terra\"))    # Interactive cropping with drawn rectangle   cropped <- mosaic_crop(mosaic)    # View result   mosaic_view(cropped) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_draw.html","id":null,"dir":"Reference","previous_headings":"","what":"Drawing Lines or Polygons with Raster Information — mosaic_draw","title":"Drawing Lines or Polygons with Raster Information — mosaic_draw","text":"Drawing Lines Polygons Raster Information","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_draw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drawing Lines or Polygons with Raster Information — mosaic_draw","text":"","code":"mosaic_draw(   mosaic,   r = 3,   g = 2,   b = 1,   re = 4,   nir = 5,   index = \"NGRDI\",   show = \"rgb\",   segment = FALSE,   viewer = c(\"mapview\", \"base\"),   threshold = \"Otsu\",   invert = FALSE,   summarize_fun = NULL,   buffer = 2,   color_regions = rev(grDevices::terrain.colors(50)),   alpha = 1,   max_pixels = 1e+06,   downsample = NULL,   quantiles = c(0, 1),   plot = TRUE,   plot_layout = c(1, 2, 3, 3) )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_draw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drawing Lines or Polygons with Raster Information — mosaic_draw","text":"mosaic mosaic class SpatRaster, generally imported mosaic_input(). r, g, b, re, nir red, green, blue, red-edge,  near-infrared bands image, respectively. default, function assumes BGR input (b = 1, g = 2, r = 3). multispectral image provided seven bands can used compute built-indexes. limitation band numbers index computed using band name. index index use index view. Defaults \"B\". show display option map view. Options \"rgb\" RGB view \"index\" index view. segment raster object segmented? set TRUE, pixels within polygon/rectangle segmented based threshold argument. viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. threshold default (threshold = \"Otsu\"), threshold value based Otsu's method used reduce grayscale image binary image. numeric value informed, value used threshold. invert Inverts mask desired. Defaults FALSE. summarize_fun optional function character vector. summarize_fun = \"mean\", mean values index calculated within object. details available functions, refer exactextractr::exact_extract(). buffer Adds buffer around geometries SpatVector created. Note distance unit buffer vary according CRS mosaic. color_regions color palette displaying index values. Defaults rev(grDevices::terrain.colors(50)). alpha opacity fill color raster layer(s). max_pixels Maximum number pixels render map plot (default: 500000). downsample Downsampling factor reduce number pixels (default: NULL). case, number pixels image (width x height) greater max_pixels downsampling factor automatically chosen number plotted pixels approximates max_pixels. quantiles upper lower quantiles used color stretching. plot Plots draw line/rectangle? Defaults TRUE. plot_layout de plot layout. Defaults plot_layout = c(1, 2, 3, 3). Ie., first row two plots, second row one plot.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_draw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Drawing Lines or Polygons with Raster Information — mosaic_draw","text":"invisible list containing mosaic, draw_data, distance, distance_profile, geometry, map.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_draw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Drawing Lines or Polygons with Raster Information — mosaic_draw","text":"mosaic_draw function enables create mosaic drawings remote sensing data compute vegetation indices. line drawn using \"Draw Polyline\" tool, profile index displayed y-axis along line's distance, represented meter units. important ensure Coordinate Reference System (CRS) mosaic latitude/longitude units accurate distance representation. rectangle polygon drawn using \"Draw Rectangle\" \"Draw Polygon\" tools, index values calculated object. default, raw data returned. can set summarize_fun compute summary statistic object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_draw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Drawing Lines or Polygons with Raster Information — mosaic_draw","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) # Load a raster showing the elevation of Luxembourg mosaic <- mosaic_input(system.file(\"ex/elev.tif\", package=\"terra\"))  # draw a polyline to see the elevation profile along the line mosaic_draw(mosaic, buffer = 1500) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_epsg.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine EPSG Code for a Mosaic — mosaic_epsg","title":"Determine EPSG Code for a Mosaic — mosaic_epsg","text":"function calculates EPSG code given mosaic based geographic extent.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_epsg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determine EPSG Code for a Mosaic — mosaic_epsg","text":"","code":"mosaic_epsg(mosaic)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_epsg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine EPSG Code for a Mosaic — mosaic_epsg","text":"mosaic raster object representing mosaic EPSG code determined.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_epsg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine EPSG Code for a Mosaic — mosaic_epsg","text":"character string representing EPSG code corresponding UTM zone hemisphere mosaic's centroid. mosaic lon/lat coordinate system, warning issued.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_epsg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Determine EPSG Code for a Mosaic — mosaic_epsg","text":"function calculates centroid mosaic's extent, determines UTM zone based centroid's longitude, identifies hemisphere based centroid's latitude. EPSG code constructed accordingly.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_epsg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Determine EPSG Code for a Mosaic — mosaic_epsg","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) library(terra)  # Create a sample mosaic mosaic <- rast(nrow=10, ncol=10, xmin=-120, xmax=-60, ymin=30, ymax=60)  # Get the EPSG code for the mosaic mosaic_epsg(mosaic) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_extract.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Values from a Raster Mosaic Using a Shapefile — mosaic_extract","title":"Extract Values from a Raster Mosaic Using a Shapefile — mosaic_extract","text":"function extracts values raster mosaic based regions defined shapefile using exactextractr::exact_extract().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_extract.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Values from a Raster Mosaic Using a Shapefile — mosaic_extract","text":"","code":"mosaic_extract(mosaic, shapefile, fun = \"median\", ...)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_extract.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Values from a Raster Mosaic Using a Shapefile — mosaic_extract","text":"mosaic SpatRaster object representing raster mosaic values extracted. shapefile shapefile, can SpatVector sf object, defining regions interest extraction. fun character string specifying summary function used extraction. Default \"median\". ... Additional arguments passed exactextractr::exact_extract().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_extract.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Values from a Raster Mosaic Using a Shapefile — mosaic_extract","text":"data frame containing extracted values region defined shapefile.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_hist.html","id":null,"dir":"Reference","previous_headings":"","what":"A wrapper around terra::hist() — mosaic_hist","title":"A wrapper around terra::hist() — mosaic_hist","text":"Create histogram values SpatRaster.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_hist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A wrapper around terra::hist() — mosaic_hist","text":"","code":"mosaic_hist(mosaic, layer, ...)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_hist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A wrapper around terra::hist() — mosaic_hist","text":"mosaic SpatRaster layer positive integer character indicate layer numbers (names). missing, layers used ... arguments passed terra::hist().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_hist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A wrapper around terra::hist() — mosaic_hist","text":"NULL object","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_hist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A wrapper around terra::hist() — mosaic_hist","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) r <- mosaic_input(system.file(\"ex/elev.tif\", package=\"terra\")) mosaic_hist(r) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Mosaic Index — mosaic_index","title":"Mosaic Index — mosaic_index","text":"Compute extract index layer multi-band mosaic raster.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mosaic Index — mosaic_index","text":"","code":"mosaic_index(   mosaic,   index = \"NGRDI\",   r = 3,   g = 2,   b = 1,   re = NA,   nir = NA,   swir = NA,   tir = NA,   plot = TRUE,   in_memory = TRUE,   output = c(\"memory\", \"disk\"),   workers = 1,   verbose = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mosaic Index — mosaic_index","text":"mosaic mosaic class SpatRaster, generally imported mosaic_input(). index character value (vector characters) specifying target mode conversion binary image. Use pliman_indexes_rgb() pliman_indexes_me() see available RGB multispectral indexes, respectively. Users can also calculate index using  R, G, B, RE, NIR, SWIR, TIR bands (eg., index = \"R+B/G\") using names mosaic's layers (ex., \"(band_1 + band_2) / 2\"). r, g, b, re, nir, swir, tir red, green, blue, red-edge,  near-infrared, shortwave Infrared, thermal infrared bands image, respectively. default, function assumes BGR input (b = 1, g = 2, r = 3). multispectral image provided seven bands can used compute built-indexes. limitation band numbers index computed using band name. plot Plot computed index? Defaults TRUE. in_memory Logical, indicating whether indexes computed memory. Defaults TRUE. cases, 2-3 times faster, errors can occur mosaic large SpatRaster. FALSE, raster algebra operations performed temporary files. output Character(1), either \"memory\" \"disk\". \"memory\", function returns terra::SpatRaster object assembled memory. \"disk\", index layer written temporary GeoTIFF function returns terra::SpatRaster object points rasters. Default \"memory\". workers numeric. number workers want use parallel processing computing multiple indexes. verbose Whether display progress messages.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mosaic Index — mosaic_index","text":"index layer extracted/computed mosaic raster.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_index.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mosaic Index — mosaic_index","text":"function computes extracts index layer input mosaic raster based specified index name. index found package's predefined index list (see image_index() details), attempts compute index using specified band indices. resulting index layer returned SpatRaster object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mosaic Index — mosaic_index","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) mosaic <- mosaic_input(system.file(\"ex/elev.tif\", package=\"terra\")) names(mosaic) elev2 <- mosaic_index(mosaic, \"elevation * 5\", plot = FALSE) oldpar <- par(no.readonly=TRUE) par(mfrow=c(1,2))  mosaic_plot(mosaic) mosaic_plot(elev2)  # return the original parameters par(oldpar) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_index2.html","id":null,"dir":"Reference","previous_headings":"","what":"Mosaic Index with GDAL — mosaic_index2","title":"Mosaic Index with GDAL — mosaic_index2","text":"Compute extract index layer multi-band mosaic raster using gdal_calc.py (https://gdal.org/programs/gdal_calc.html). requires Python GDAL installation.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_index2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mosaic Index with GDAL — mosaic_index2","text":"","code":"mosaic_index2(   mosaic,   index = \"B\",   r = 3,   g = 2,   b = 1,   re = 4,   nir = 5,   plot = TRUE,   python = Sys.which(\"python.exe\"),   gdal = Sys.which(\"gdal_calc.py\") )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_index2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mosaic Index with GDAL — mosaic_index2","text":"mosaic mosaic class SpatRaster, generally imported mosaic_input(). index character value (vector characters) specifying target mode conversion binary image. Use pliman_indexes_rgb() pliman_indexes_me() see available RGB multispectral indexes, respectively. Users can also calculate index using  R, G, B, RE, NIR, SWIR, TIR bands (eg., index = \"R+B/G\") using names mosaic's layers (ex., \"(band_1 + band_2) / 2\"). r, g, b, re, nir red, green, blue, red-edge,  near-infrared bands image, respectively. default, function assumes BGR input (b = 1, g = 2, r = 3). multispectral image provided seven bands can used compute built-indexes. limitation band numbers index computed using band name. plot Plot computed index? Defaults TRUE. python PATH python.exe gdal PATH gdal_calc.py","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_index2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mosaic Index with GDAL — mosaic_index2","text":"index layer extracted/computed mosaic raster.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_index2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mosaic Index with GDAL — mosaic_index2","text":"","code":"if(interactive() & (Sys.which('python.exe') != '' ) & (Sys.which('gdal_calc.py') != '' )){ library(pliman) mosaic <- mosaic_input(system.file(\"ex/elev.tif\", package=\"terra\")) names(mosaic) <- \"R\" elev2 <- mosaic_index2(mosaic, \"R * 5\", plot = FALSE) oldpar <- par(no.readonly=TRUE) mosaic_plot(mosaic) mosaic_plot(elev2) par(mfrow=c(1,2)) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_input.html","id":null,"dir":"Reference","previous_headings":"","what":"Create and Export mosaics — mosaic_input","title":"Create and Export mosaics — mosaic_input","text":"Create Export mosaics","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_input.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create and Export mosaics — mosaic_input","text":"","code":"mosaic_input(   mosaic,   mosaic_pattern = NULL,   info = TRUE,   check_16bits = FALSE,   check_datatype = FALSE,   ... )  mosaic_export(mosaic, filename, datatype = NULL, overwrite = FALSE, ...)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_input.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create and Export mosaics — mosaic_input","text":"mosaic mosaic_input(), file path raster imported, matrix, array list SpatRaster objects. mosaic_export(), SpatRaster object. mosaic_pattern pattern name import multiple mosaics list. info Print mosaic informations (eg., CRS, extent). Defaults TRUE check_16bits Checks mosaic maximum value 16-bits format (65535), replaces NA. Defaults FALSE. check_datatype Logical. TRUE, checks suggests appropriate data type based raster values. ... Additional arguments passed terra::rast() (mosaic_input())  terra::writeRaster() (mosaic_output()) filename character. Output filename. datatype datatype. default, function try guess data type saves memory usage file size. See terra::writeRaster() terra::datatype() details. overwrite logical. TRUE, filename overwritten.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_input.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create and Export mosaics — mosaic_input","text":"mosaic_input() returns SpatRaster object. mosaic_export() return object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_input.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create and Export mosaics — mosaic_input","text":"mosaic_input() simply wrapper around terra::rast(). creates SpatRaster object scratch, filename, another object. mosaic_export() simply wrapper around terra::writeRaster(). write SpatRaster object file.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_input.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create and Export mosaics — mosaic_input","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman)  # create an SpatRaster object based on a matrix x <- system.file(\"ex/logo.tif\", package=\"terra\") rast <- mosaic_input(x) mosaic_plot(rast)  # create a temporary filename for the example f <- file.path(tempdir(), \"test.tif\") mosaic_export(rast, f, overwrite=TRUE) list.files(tempdir()) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_interpolate.html","id":null,"dir":"Reference","previous_headings":"","what":"Mosaic interpolation — mosaic_interpolate","title":"Mosaic interpolation — mosaic_interpolate","text":"Performs interpolation points raster object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_interpolate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mosaic interpolation — mosaic_interpolate","text":"","code":"mosaic_interpolate(mosaic, points, method = c(\"bilinear\", \"loess\", \"idw\"))"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_interpolate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mosaic interpolation — mosaic_interpolate","text":"mosaic SpatRaster object points sf object points x y coordinates, usually obtained shapefile_build(). Alternatively, external shapefile imported shapefile_input() containing x y coordinates can used. function handle used shapefile formats (eg., .shp, .rds) convert imported shapefile sf object. method One \"bilinear\" (default), \"loess\" (local regression) \"idw\" (Inverse Distance Weighting).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_interpolate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mosaic interpolation — mosaic_interpolate","text":"SpatRaster object extent crs mosaic","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_lonlat2epsg.html","id":null,"dir":"Reference","previous_headings":"","what":"Project a Mosaic from Lon/Lat to EPSG-based CRS — mosaic_lonlat2epsg","title":"Project a Mosaic from Lon/Lat to EPSG-based CRS — mosaic_lonlat2epsg","text":"function projects given mosaic lon/lat coordinate system EPSG-based CRS determined mosaic's extent.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_lonlat2epsg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project a Mosaic from Lon/Lat to EPSG-based CRS — mosaic_lonlat2epsg","text":"","code":"mosaic_lonlat2epsg(mosaic)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_lonlat2epsg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project a Mosaic from Lon/Lat to EPSG-based CRS — mosaic_lonlat2epsg","text":"mosaic raster object representing mosaic projected. mosaic must lon/lat coordinate system.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_lonlat2epsg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project a Mosaic from Lon/Lat to EPSG-based CRS — mosaic_lonlat2epsg","text":"raster object representing projected mosaic. mosaic lon/lat coordinate system, warning issued.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_lonlat2epsg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project a Mosaic from Lon/Lat to EPSG-based CRS — mosaic_lonlat2epsg","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(terra) library(pliman)  # Create a sample mosaic mosaic <- rast(nrow=10, ncol=10, xmin=-120, xmax=-60, ymin=30, ymax=60)  # Project the mosaic to the appropriate UTM zone mosaic_lonlat2epsg(mosaic) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"A wrapper around terra::plot() — mosaic_plot","title":"A wrapper around terra::plot() — mosaic_plot","text":"Plot values SpatRaster","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A wrapper around terra::plot() — mosaic_plot","text":"","code":"mosaic_plot(   mosaic,   col = custom_palette(c(\"red\", \"yellow\", \"forestgreen\"), n = 200),   smooth = TRUE,   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A wrapper around terra::plot() — mosaic_plot","text":"mosaic SpatRaster col character vector specify colors use. Defaults custom_palette(c(\"red\", \"yellow\", \"forestgreen\")). smooth logical. TRUE (default) cell values smoothed (continuous legend used). ... arguments passed terra::plot().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A wrapper around terra::plot() — mosaic_plot","text":"NULL object","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A wrapper around terra::plot() — mosaic_plot","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) r <- mosaic_input(system.file(\"ex/elev.tif\", package=\"terra\")) mosaic_plot(r) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_plot_rgb.html","id":null,"dir":"Reference","previous_headings":"","what":"A wrapper around terra::plotRGB() — mosaic_plot_rgb","title":"A wrapper around terra::plotRGB() — mosaic_plot_rgb","text":"Plot RGB SpatRaster","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_plot_rgb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A wrapper around terra::plotRGB() — mosaic_plot_rgb","text":"","code":"mosaic_plot_rgb(mosaic, ...)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_plot_rgb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A wrapper around terra::plotRGB() — mosaic_plot_rgb","text":"mosaic SpatRaster ... arguments passed terra::plotRGB().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_plot_rgb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A wrapper around terra::plotRGB() — mosaic_plot_rgb","text":"NULL object","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_prepare.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a mosaic — mosaic_prepare","title":"Prepare a mosaic — mosaic_prepare","text":"Prepare SpatRaster object analyzed pliman. includes cropping original mosaic, aligning , cropping aligned object. resulting object object class Image can analyzed.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_prepare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a mosaic — mosaic_prepare","text":"","code":"mosaic_prepare(   mosaic,   r = 3,   g = 2,   b = 1,   re = 4,   nir = 5,   crop_mosaic = TRUE,   align = TRUE,   crop_aligned = TRUE,   rescale = TRUE,   coef = 0,   viewer = \"mapview\",   max_pixels = 5e+05,   show = \"rgb\",   index = \"R\" )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_prepare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a mosaic — mosaic_prepare","text":"mosaic mosaic class SpatRaster, generally imported mosaic_input(). r, g, b, re, nir red, green, blue, red-edge,  near-infrared bands image, respectively. default, function assumes BGR input (b = 1, g = 2, r = 3). multispectral image provided seven bands can used compute built-indexes. limitation band numbers index computed using band name. crop_mosaic Logical, whether crop mosaic interactively aligning (default: FALSE). align Logical, whether align mosaic interactively (default: TRUE). crop_aligned Logical, whether crop aligned mosaic interactively (default: TRUE). rescale Rescale final values? TRUE final values rescaled maximum value 1. coef addition coefficient applied resulting object. useful adjust brightness final image. Defaults 0. viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. max_pixels Maximum number pixels render map plot (default: 500000). show display option map view. Options \"rgb\" RGB view \"index\" index view. index index use index view. Defaults \"B\".","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_prepare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare a mosaic — mosaic_prepare","text":"prepared object class Image.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_prepare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare a mosaic — mosaic_prepare","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) mosaic <- mosaic_input(system.file(\"ex/elev.tif\", package=\"terra\")) mosaic_prepare(mosaic) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_project.html","id":null,"dir":"Reference","previous_headings":"","what":"Project a Mosaic to a New Coordinate Reference System (CRS) — mosaic_project","title":"Project a Mosaic to a New Coordinate Reference System (CRS) — mosaic_project","text":"function projects given mosaic specified CRS.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_project.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project a Mosaic to a New Coordinate Reference System (CRS) — mosaic_project","text":"","code":"mosaic_project(mosaic, y, ...)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_project.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project a Mosaic to a New Coordinate Reference System (CRS) — mosaic_project","text":"mosaic raster object representing mosaic projected. y target CRS mosaic projected. can specified various formats accepted terra::project() function. ... Additional arguments passed terra::project() function.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_project.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project a Mosaic to a New Coordinate Reference System (CRS) — mosaic_project","text":"raster object representing projected mosaic.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_project.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project a Mosaic to a New Coordinate Reference System (CRS) — mosaic_project","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(terra) library(pliman)  # Create a sample mosaic mosaic <- rast(nrow=10, ncol=10, xmin=-120, xmax=-60, ymin=30, ymax=60) mosaic # Define target CRS (EPSG code for WGS 84 / UTM zone 33N) target_crs <- \"EPSG:32633\"  # Project the mosaic projected_mosaic <- mosaic_project(mosaic, \"EPSG:32633\") projected_mosaic }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_resample.html","id":null,"dir":"Reference","previous_headings":"","what":"A wrapper around terra::resample() — mosaic_resample","title":"A wrapper around terra::resample() — mosaic_resample","text":"Transfers values SpatRaster objects align (different origin /resolution). See terra::resample() details","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_resample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A wrapper around terra::resample() — mosaic_resample","text":"","code":"mosaic_resample(mosaic, y, ...)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_resample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A wrapper around terra::resample() — mosaic_resample","text":"mosaic SpatRaster resampled y SpatRaster geometry x resampled ... arguments passed terra::resample().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_resample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A wrapper around terra::resample() — mosaic_resample","text":"SpatRaster","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_resample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A wrapper around terra::resample() — mosaic_resample","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) library(terra) r <- rast(nrows=3, ncols=3, xmin=0, xmax=10, ymin=0, ymax=10) values(r) <- 1:ncell(r) s <- rast(nrows=25, ncols=30, xmin=1, xmax=11, ymin=-1, ymax=11) x <- mosaic_resample(r, s, method=\"bilinear\") opar <- par(no.readonly =TRUE) par(mfrow=c(1,2)) plot(r) plot(x) par(opar) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_rotate.html","id":null,"dir":"Reference","previous_headings":"","what":"Rotate a mosaic image by specified angles — mosaic_rotate","title":"Rotate a mosaic image by specified angles — mosaic_rotate","text":"function rotates mosaic image 90, 180, 270 degrees.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_rotate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rotate a mosaic image by specified angles — mosaic_rotate","text":"","code":"mosaic_rotate(mosaic, angle, direction = \"clockwise\")"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_rotate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rotate a mosaic image by specified angles — mosaic_rotate","text":"mosaic SpatRaster object representing mosaic image. angle integer specifying rotation angle. Must one 90, 180, 270. direction string specifying rotation direction. Must either \"clockwise\" \"anticlockwise\".","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_rotate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rotate a mosaic image by specified angles — mosaic_rotate","text":"SpatRaster object rotated mosaic image.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_rotate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rotate a mosaic image by specified angles — mosaic_rotate","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) # Convert a mosaic raster to an Image object mosaic <- mosaic_input(system.file(\"ex/elev.tif\", package=\"terra\")) r90 <- mosaic_rotate(mosaic, 90) r180 <- mosaic_rotate(mosaic, 180) r270 <- mosaic_rotate(mosaic, 270) # Plot all rotations side by side par(mfrow = c(2, 2)) mosaic_plot(mosaic, main = \"Original\") mosaic_plot(r90, main = \"90 Degrees\") mosaic_plot(r180, main = \"180 Degrees\") mosaic_plot(r270, main = \"270 Degrees\") par(mfrow = c(1, 1))  }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_segment.html","id":null,"dir":"Reference","previous_headings":"","what":"Segment a mosaic — mosaic_segment","title":"Segment a mosaic — mosaic_segment","text":"Segment SpatRaster using computed image index. default, values greater threshold kept mask.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_segment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Segment a mosaic — mosaic_segment","text":"","code":"mosaic_segment(   mosaic,   index = \"R\",   r = 3,   g = 2,   b = 1,   re = NA,   nir = NA,   swir = NA,   tir = NA,   threshold = \"Otsu\",   invert = FALSE,   return = c(\"mosaic\", \"mask\") )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_segment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Segment a mosaic — mosaic_segment","text":"mosaic mosaic class SpatRaster, generally imported mosaic_input(). index character value (vector characters) specifying target mode conversion binary image. Use pliman_indexes_rgb() pliman_indexes_me() see available RGB multispectral indexes, respectively. Users can also calculate index using  R, G, B, RE, NIR, SWIR, TIR bands (eg., index = \"R+B/G\") using names mosaic's layers (ex., \"(band_1 + band_2) / 2\"). r, g, b, re, nir, swir, tir red, green, blue, red-edge,  near-infrared, shortwave Infrared, thermal infrared bands image, respectively. default, function assumes BGR input (b = 1, g = 2, r = 3). multispectral image provided seven bands can used compute built-indexes. limitation band numbers index computed using band name. threshold default (threshold = \"Otsu\"), threshold value based Otsu's method used reduce grayscale image binary image. numeric value provided, value used threshold. invert Logical, indicating whether invert mask. Defaults FALSE, .e., pixels intensity greater threshold values selected. return output function. Either 'mosaic' (segmented mosaic), 'mask' (binary mask).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_segment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Segment a mosaic — mosaic_segment","text":"segmented mosaic (SpatRaster object)","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_segment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Segment a mosaic — mosaic_segment","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) mosaic <- mosaic_input(system.file(\"ex/elev.tif\", package=\"terra\")) seg <- mosaic_segment(mosaic,                index = \"elevation\",                threshold = 350) mosaic_plot(seg) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_segment_pick.html","id":null,"dir":"Reference","previous_headings":"","what":"Segments a mosaic interactively — mosaic_segment_pick","title":"Segments a mosaic interactively — mosaic_segment_pick","text":"function segments mosaic using interative process user picks samples background (eg., soil) foreground (eg., plants).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_segment_pick.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Segments a mosaic interactively — mosaic_segment_pick","text":"","code":"mosaic_segment_pick(   mosaic,   basemap = NULL,   g = 2,   r = 3,   b = 1,   max_pixels = 2e+06,   downsample = NULL,   quantiles = c(0, 1),   return = c(\"mosaic\", \"mask\") )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_segment_pick.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Segments a mosaic interactively — mosaic_segment_pick","text":"mosaic mosaic class SpatRaster, generally imported mosaic_input(). basemap optional mapview object. r, g, b layer Red, Green Blue band, respectively. Defaults 1, 2, 3. max_pixels Maximum number pixels render map plot (default: 500000). downsample Downsampling factor reduce number pixels (default: NULL). case, number pixels image (width x height) greater max_pixels downsampling factor automatically chosen number plotted pixels approximates max_pixels. quantiles upper lower quantiles used color stretching. return output function. Either 'mosaic' (segmented mosaic), 'mask' (binary mask).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_segment_pick.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Segments a mosaic interactively — mosaic_segment_pick","text":"SpatRaster object segmented mosaic (return = 'mosaic') mask (return = 'mask').","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_segment_pick.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Segments a mosaic interactively — mosaic_segment_pick","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) {  mosaic <- mosaic_input(system.file(\"ex/elev.tif\", package=\"terra\"))  seg <- mosaic_segment_pick(mosaic)  mosaic_plot(seg) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_to_pliman.html","id":null,"dir":"Reference","previous_headings":"","what":"Mosaic to pliman — mosaic_to_pliman","title":"Mosaic to pliman — mosaic_to_pliman","text":"Convert SpatRaster object Image object optional scaling.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_to_pliman.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mosaic to pliman — mosaic_to_pliman","text":"","code":"mosaic_to_pliman(   mosaic,   r = 3,   g = 2,   b = 1,   re = 4,   nir = 5,   rescale = TRUE,   coef = 0 )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_to_pliman.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mosaic to pliman — mosaic_to_pliman","text":"mosaic mosaic class SpatRaster, generally imported mosaic_input(). r, g, b, re, nir red, green, blue, red-edge,  near-infrared bands image, respectively. default, function assumes BGR input (b = 1, g = 2, r = 3). multispectral image provided seven bands can used compute built-indexes. limitation band numbers index computed using band name. rescale Rescale final values? TRUE final values rescaled maximum value 1. coef addition coefficient applied resulting object. useful adjust brightness final image. Defaults 0.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_to_pliman.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mosaic to pliman — mosaic_to_pliman","text":"Image object number layers mosaic.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_to_pliman.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mosaic to pliman — mosaic_to_pliman","text":"function converts SpatRaster Image object, can used image analysis pliman. Note large SpatRaster loaded, resulting object may increase considerably memory usage.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_to_pliman.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mosaic to pliman — mosaic_to_pliman","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) # Convert a mosaic raster to an Image object mosaic <- mosaic_input(system.file(\"ex/elev.tif\", package=\"terra\")) pliman_image <- mosaic_to_pliman(mosaic) plot(pliman_image) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_to_rgb.html","id":null,"dir":"Reference","previous_headings":"","what":"Mosaic to RGB — mosaic_to_rgb","title":"Mosaic to RGB — mosaic_to_rgb","text":"Convert SpatRaster three-band RGB image class Image.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_to_rgb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mosaic to RGB — mosaic_to_rgb","text":"","code":"mosaic_to_rgb(mosaic, r = 3, g = 2, b = 1, coef = 0, plot = TRUE)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_to_rgb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mosaic to RGB — mosaic_to_rgb","text":"mosaic mosaic class SpatRaster, generally imported mosaic_input(). r, g, b red, green, blue bands. coef addition coefficient applied resulting object. useful adjust brightness final image. Defaults 0. plot Logical, whether display resulting RGB image (default: TRUE).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_to_rgb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mosaic to RGB — mosaic_to_rgb","text":"three-band RGB image represented pliman (EBImage) object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_to_rgb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mosaic to RGB — mosaic_to_rgb","text":"function converts SpatRaster contains RGB bands three-band RGB image using pliman (EBImage). allows specify band indices red, green, blue channels, well apply scaling coefficient final image. default, resulting RGB image displayed, behavior can controlled using plot parameter.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_to_rgb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mosaic to RGB — mosaic_to_rgb","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) {  library(pliman) # Convert a mosaic raster to an RGB image and display it mosaic <- mosaic_input(system.file(\"ex/elev.tif\", package=\"terra\"))  # Convert a mosaic raster to an RGB image without displaying it rgb_image <- mosaic_to_rgb(c(mosaic * 2, mosaic - 0.3, mosaic * 0.8)) plot(rgb_image) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_vectorize.html","id":null,"dir":"Reference","previous_headings":"","what":"Vectorize a SpatRaster mask to an sf object — mosaic_vectorize","title":"Vectorize a SpatRaster mask to an sf object — mosaic_vectorize","text":"Converts raster mask vectorized sf object, various options morphological operations filtering.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_vectorize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vectorize a SpatRaster mask to an sf object — mosaic_vectorize","text":"","code":"mosaic_vectorize(   mask,   aggregate = NULL,   watershed = TRUE,   tolerance = 1,   extension = 1,   opening = FALSE,   closing = FALSE,   filter = FALSE,   erode = FALSE,   dilate = FALSE,   fill_hull = FALSE,   lower_size = NULL,   upper_size = NULL,   topn_lower = NULL,   topn_upper = NULL,   smooth = FALSE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_vectorize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Vectorize a SpatRaster mask to an sf object — mosaic_vectorize","text":"mask optional mask (SpatRaster) mask mosaic. aggregate size fraction (percentage) input image size. Either scalar (eg., 50), length-two numeric vector. last, different percentage reduction/expansion can used columns, rows, respectively. watershed TRUE (default), performs watershed-based object detection. detect objects even touching one another. FALSE, pixels connected set foreground pixels set unique object. faster able segment touching objects. tolerance minimum height object units image intensity highest point (seed) point contacts another object (checked every contact pixel). height smaller tolerance, object combined one neighbors, highest. extension Radius neighborhood pixels detection neighboring objects. higher value smooths small objects. opening, closing, filter, erode, dilate Morphological operations (brush size) dilate puts mask every background pixel, sets foreground pixels covered mask foreground. erode puts mask every foreground pixel, sets background pixels covered mask background. opening performs erosion followed dilation. helps remove small objects preserving shape size larger objects. closing performs dilatation followed erosion. helps fill small holes preserving shape size larger objects. filter performs median filtering binary image. Provide positive integer > 1 indicate size median filtering. Higher values efficient remove noise background can dramatically impact perimeter objects, mainly irregular perimeters leaves serrated edges. fill_hull Fill holes binary image? Defaults FALSE. lower_size, upper_size Lower upper limits size image analysis. Plant images often contain dirt dust.  Upper limit set NULL, .e., upper limit used. One can set known area use lower_size = 0 select objects (advised). Objects matches size given range sizes can selected setting two arguments. example, lower_size = 120 upper_size = 140, objects size greater equal 120 less equal 140 considered. topn_lower, topn_upper Select top n objects based area. topn_lower selects n elements smallest area whereas topn_upper selects n objects largest area. smooth Smoothes contours using moving average filter. Default FALSE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_vectorize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Vectorize a SpatRaster mask to an sf object — mosaic_vectorize","text":"sf object containing vectorized features raster mask, added area measurements.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_vectorize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vectorize a SpatRaster mask to an sf object — mosaic_vectorize","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) mask <- image_pliman(\"mask.tif\") shp <- mosaic_vectorize(mask, watershed = FALSE) mosaic_plot(mask) shapefile_plot(shp, add = TRUE, lwd = 3) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_view.html","id":null,"dir":"Reference","previous_headings":"","what":"Mosaic View — mosaic_view","title":"Mosaic View — mosaic_view","text":"Mosaic View","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_view.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mosaic View — mosaic_view","text":"","code":"mosaic_view(   mosaic,   r = 3,   g = 2,   b = 1,   edit = FALSE,   title = \"\",   shapefile = NULL,   attribute = NULL,   viewer = c(\"mapview\", \"base\"),   show = c(\"rgb\", \"index\"),   index = \"B\",   max_pixels = 1e+06,   downsample = NULL,   downsample_fun = \"nearest\",   alpha = 1,   quantiles = c(0, 1),   color_regions = custom_palette(c(\"red\", \"yellow\", \"forestgreen\")),   axes = FALSE,   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_view.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mosaic View — mosaic_view","text":"mosaic mosaic class SpatRaster, generally imported mosaic_input(). r, g, b layer Red, Green Blue band, respectively. Defaults 1, 2, 3. edit TRUE enable editing options using mapedit::editMap(). title title generated map plot (default: \"\"). shapefile optional shapefile class sf plotted mosaic. can , example, plot-level result returned mosaic_analyze(). attribute attribute name(s) column number(s) shapefile table column(s) rendered. viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. show display option map view. Options \"rgb\" RGB view \"index\" index view. index index use index view. Defaults \"B\". max_pixels Maximum number pixels render map plot (default: 500000). downsample Downsampling factor reduce number pixels (default: NULL). case, number pixels image (width x height) greater max_pixels downsampling factor automatically chosen number plotted pixels approximates max_pixels. downsample_fun resampling function. Defaults nearest. See details mosaic_aggregate(). alpha opacity fill color raster layer(s). quantiles upper lower quantiles used color stretching. color_regions color palette displaying index values. Default custom_palette(). axes logical. Draw axes? Defaults FALSE. ... Additional arguments passed terra::plot() viewer = \"base\".","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_view.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mosaic View — mosaic_view","text":"sf object, object returned mapedit::editMap().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_view.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mosaic View — mosaic_view","text":"function can generate either interactive map using 'mapview' package static plot using 'base' package, depending viewer show parameters. show = \"index\" used, function first computes image index can either RGB-based index multispectral index, multispectral mosaic provided.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/mosaic_view.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mosaic View — mosaic_view","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) # Load a raster showing the elevation of Luxembourg mosaic <- mosaic_input(system.file(\"ex/elev.tif\", package=\"terra\"))  # Generate an interactive map using 'mapview' mosaic_view(mosaic)  # Generate a static plot using 'base' mosaic_view(mosaic, viewer = \"base\") }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_bbox.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Bounding Boxes from Contours — object_bbox","title":"Compute Bounding Boxes from Contours — object_bbox","text":"function calculates bounding boxes given list contours.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_bbox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Bounding Boxes from Contours — object_bbox","text":"","code":"object_bbox(contours)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_bbox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Bounding Boxes from Contours — object_bbox","text":"contours list matrices, matrix contains two columns representing (x, y) coordinates contour.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_bbox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Bounding Boxes from Contours — object_bbox","text":"list bounding boxes, bounding box represented list x_min, y_min, x_max, y_max values.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_bbox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Bounding Boxes from Contours — object_bbox","text":"","code":"if(interactive()){ contours <- list(   matrix(c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100,            110, 120, 130, 140, 150, 160, 170, 180, 190, 200),          ncol = 2, byrow = FALSE) ) bbox_list <- object_bbox(contours) print(bbox_list) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_edge.html","id":null,"dir":"Reference","previous_headings":"","what":"Object edges — object_edge","title":"Object edges — object_edge","text":"Applies Sobel-Feldman Operator detect edges. operator based convolving image small, separable, integer-valued filter horizontal vertical directions.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_edge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Object edges — object_edge","text":"","code":"object_edge(img, sigma = 1, threshold = \"Otsu\", thinning = FALSE, plot = TRUE)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_edge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Object edges — object_edge","text":"img image list images class Image. sigma Gaussian kernel standard deviation used gaussian blur. threshold theshold method used.  threshold = \"Otsu\" (default), threshold value based Otsu's method used reduce grayscale image binary image. non-numeric value different \"Otsu\" used, iterative section allow choose threshold based raster plot showing pixel intensity index. Alternatively, provide numeric value used threshold value. thinning Logical value indicating whether thinning procedure applied detected edges. See image_skeleton() plot Logical value indicating whether plot created","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_edge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Object edges — object_edge","text":"binary version image.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_edge.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Object edges — object_edge","text":"Sobel, ., G. Feldman. 1973. 3×3 isotropic gradient operator image processing. Pattern Classification Scene Analysis: 271–272.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_edge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Object edges — object_edge","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"sev_leaf_nb.jpg\", plot = TRUE) object_edge(img) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_export.html","id":null,"dir":"Reference","previous_headings":"","what":"Export multiple objects from an image to multiple images — object_export","title":"Export multiple objects from an image to multiple images — object_export","text":"Givin image multiple objects, object_export() split objects list objects using object_split() export multiple images current working directory (subfolder). Batch processing performed declaring file name pattern matches images within working directory.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_export.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export multiple objects from an image to multiple images — object_export","text":"","code":"object_export(   img,   pattern = NULL,   dir_original = NULL,   dir_processed = NULL,   format = \".jpg\",   squarize = FALSE,   augment = FALSE,   times = 12,   index = \"NB\",   lower_size = NULL,   watershed = FALSE,   invert = FALSE,   fill_hull = FALSE,   opening = 3,   closing = FALSE,   filter = FALSE,   erode = FALSE,   dilate = FALSE,   threshold = \"Otsu\",   extension = NULL,   tolerance = NULL,   object_size = \"medium\",   edge = 20,   remove_bg = FALSE,   parallel = FALSE,   workers = NULL,   verbose = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_export.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export multiple objects from an image to multiple images — object_export","text":"img image analyzed. pattern pattern file name used identify images processed. example, pattern = \"im\" images current working directory name matches pattern (e.g., img1.-, image1.-, im2.-) imported processed. Providing number pattern (e.g., pattern = \"1\") select images named 1.-, 2.-, . error returned pattern matches file supported (e.g., img1.pdf). dir_original directory containing original images. Defaults NULL. can either full path, e.g., \"C:/Desktop/imgs\", subfolder within current working directory, e.g., \"/imgs\". dir_processed Optional character string indicating subfolder within current working directory save image(s). folder exist, created. format format image exported. squarize Squarizes image exportation? TRUE, image_square() called internally. augment logical indicating exported objects augmented using image_augment(). Defaults FALSE. times number times rotate image. index character value specifying target mode conversion binary image foreground background declared. Defaults \"NB\" (normalized blue). See image_index() details. User can also calculate index using bands names, e.g. index = \"R+B/G\" lower_size Plant images often contain dirt dust. prevent dust affecting image analysis, objects lesser 10% mean objects removed. Set lower_limit = 0 keep objects. watershed TRUE (default) performs watershed-based object detection. detect objects even touching one . FALSE, pixels connected set foreground pixels set unique object. faster able segment touching objects. invert Inverts binary image desired. useful process images black background. Defaults FALSE. reference = TRUE use, invert can declared logical vector length 2 (eg., invert = c(FALSE, TRUE). case, segmentation objects reference foreground using back_fore_index performed using default (inverted), segmentation objects reference performed inverting selection (selecting pixels higher threshold). fill_hull Fill holes binary image? Defaults FALSE. useful fill holes objects portions color similar background. IMPORTANT: Objects touching can combined one single object, may underestimate number objects image. opening, closing, filter, erode, dilate Morphological operations (brush size) dilate puts mask every background pixel, sets foreground pixels covered mask foreground. erode puts mask every foreground pixel, sets background pixels covered mask background. opening performs erosion followed dilation. helps remove small objects preserving shape size larger objects. closing performs dilatation followed erosion. helps fill small holes preserving shape size larger objects. filter performs median filtering binary image. Provide positive integer > 1 indicate size median filtering. Higher values efficient remove noise background can dramatically impact perimeter objects, mainly irregular perimeters leaves serrated edges. threshold theshold method used. default (threshold = \"Otsu\"), threshold value based Otsu's method used reduce grayscale image binary image. numeric value informed, value used threshold. threshold = \"adaptive\", adaptive thresholding (Shafait et al. 2008) used, depend k windowsize arguments. non-numeric value different \"Otsu\" \"adaptive\" used, iterative section allow choose threshold based raster plot showing pixel intensity index. extension Radius neighborhood pixels detection neighboring objects. Higher value smooths small objects. tolerance minimum height object units image intensity highest point (seed) point contacts another object (checked every contact pixel). height smaller tolerance, object combined one neighbors, highest. object_size size object. Used automatically set tolerance extension parameters. One following. \"small\" (e.g, wheat grains), \"medium\" (e.g, soybean grains), \"large\"(e.g, peanut grains), \"elarge\" (e.g, soybean pods)`. edge number pixels added edge segmented object. Defaults 5. remove_bg TRUE, pixels part objects converted white. parallel TRUE processes images asynchronously (parallel) separate R sessions running background machine. may speed processing time, especially pattern used informed. object_index informed, multiple sections used extract RGB values object image. may significantly speed processing time image lots objects (say >1000). workers positive numeric scalar function specifying number parallel processes can active time. default, number sections set 30% available cores. verbose TRUE (default) summary shown console.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_export.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export multiple objects from an image to multiple images — object_export","text":"NULL object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_export.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export multiple objects from an image to multiple images — object_export","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"potato_leaves.jpg\") object_export(img,               remove_bg = TRUE) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_export_shp.html","id":null,"dir":"Reference","previous_headings":"","what":"Export multiple objects from an image to multiple images — object_export_shp","title":"Export multiple objects from an image to multiple images — object_export_shp","text":"Givin image multiple objects, object_export_shp() split objects list objects using object_split_shp() export multiple images current working directory (subfolder). Batch processing performed declaring file name pattern matches images within working directory.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_export_shp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export multiple objects from an image to multiple images — object_export_shp","text":"","code":"object_export_shp(   img,   pattern = NULL,   dir_original = NULL,   dir_processed = NULL,   format = \".jpg\",   subfolder = NULL,   squarize = FALSE,   nrow = 1,   ncol = 1,   buffer_x = 0,   buffer_y = 0,   interactive = FALSE,   parallel = FALSE,   workers = NULL,   verbose = TRUE,   viewer = pliman::get_pliman_viewer() )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_export_shp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export multiple objects from an image to multiple images — object_export_shp","text":"img object class Image pattern pattern file name used identify images processed. example, pattern = \"im\" images current working directory name matches pattern (e.g., img1.-, image1.-, im2.-) imported processed. Providing number pattern (e.g., pattern = \"1\") select images named 1.-, 2.-, . error returned pattern matches file supported (e.g., img1.pdf). dir_original directory containing original images. Defaults NULL. can either full path, e.g., \"C:/Desktop/imgs\", subfolder within current working directory, e.g., \"/imgs\". dir_processed Optional character string indicating subfolder within current working directory save image(s). folder exist, created. format format image exported. subfolder Optional character string indicating subfolder within current working directory save image(s). folder exist, created. squarize Squarizes image exportation? TRUE, image_square() called internally. nrow number desired rows grid. Defaults 1. ncol number desired columns grid. Defaults 1. buffer_x, buffer_y Buffering factor width height, respectively, individual shape's side. value 0 0.5 0 means buffering 0.5 means complete buffering (default: 0). value 0.25 buffer shape 25% side. interactive FALSE (default) grid created automatically based image dimension number rows/columns. interactive = TRUE, users must draw points diagonal desired bounding box contain grid. parallel TRUE processes images asynchronously (parallel) separate R sessions running background machine. may speed processing time, especially pattern used informed. object_index informed, multiple sections used extract RGB values object image. may significantly speed processing time image lots objects (say >1000). workers positive numeric scalar function specifying number parallel processes can active time. default, number sections set 30% available cores. verbose TRUE (default) summary shown console. viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_export_shp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export multiple objects from an image to multiple images — object_export_shp","text":"NULL object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_export_shp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export multiple objects from an image to multiple images — object_export_shp","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) flax <- image_pliman(\"flax_leaves.jpg\", plot = TRUE) object_export_shp(flax)  }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_label.html","id":null,"dir":"Reference","previous_headings":"","what":"Labels objects — object_label","title":"Labels objects — object_label","text":"pixels connected set foreground (non-zero) pixels x set unique increasing integer, starting 1. Hence, max(x) gives number connected objects x. wrapper EBImage::bwlabel EBImage::watershed (watershed = TRUE).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_label.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Labels objects — object_label","text":"","code":"object_label(   img,   index = \"B\",   invert = FALSE,   fill_hull = FALSE,   threshold = \"Otsu\",   k = 0.1,   windowsize = NULL,   opening = FALSE,   closing = FALSE,   filter = FALSE,   erode = FALSE,   dilate = FALSE,   watershed = FALSE,   tolerance = NULL,   extension = NULL,   object_size = \"medium\",   plot = TRUE,   ncol = NULL,   nrow = NULL,   verbose = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_label.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Labels objects — object_label","text":"img image object. index character value (vector characters) specifying target mode conversion binary image. See available indexes pliman_indexes() image_index() details. invert Inverts binary image, desired. fill_hull Fill holes objects? Defaults FALSE. threshold theshold method used. default (threshold = \"Otsu\"), threshold value based Otsu's method used reduce grayscale image binary image. numeric value informed, value used threshold. threshold = \"adaptive\", adaptive thresholding (Shafait et al. 2008) used, depend k windowsize arguments. non-numeric value different \"Otsu\" \"adaptive\" used, iterative section allow choose threshold based raster plot showing pixel intensity index. k numeric range 0-1. k high, local threshold values tend lower. k low, local threshold value tend higher. windowsize windowsize controls number local neighborhood adaptive thresholding. default set 1/3 * minxy, minxy minimum dimension image (pixels). erode, dilate, opening, closing, filter Morphological operations (brush size) dilate puts mask every background pixel, sets foreground pixels covered mask foreground. erode puts mask every foreground pixel, sets background pixels covered mask background. opening performs erosion followed dilation. helps remove small objects preserving shape size larger objects. closing performs dilatation followed erosion. helps fill small holes preserving shape size larger objects. filter performs median filtering binary image. Provide positive integer > 1 indicate size median filtering. Higher values efficient remove noise background can dramatically impact perimeter objects, mainly irregular perimeters leaves serrated edges. Hierarchically, operations performed opening > closing > filter. value declared argument define brush size. watershed TRUE (default) performs watershed-based object detection. detect objects even touching one . FALSE, pixels connected set foreground pixels set unique object. faster able segment touching objects. tolerance minimum height object units image intensity highest point (seed) point contacts another object (checked every contact pixel). height smaller tolerance, object combined one neighbors, highest. extension Radius neighborhood pixels detection neighboring objects. Higher value smooths small objects. object_size size object. Used automatically set tolerance extension parameters. One following. \"small\" (e.g, wheat grains), \"medium\" (e.g, soybean grains), \"large\"(e.g, peanut grains), \"elarge\" (e.g, soybean pods)`. plot Show image processing? nrow, ncol number rows columns plot grid. Defaults NULL, .e., square grid produced. verbose TRUE (default) summary shown console.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_label.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Labels objects — object_label","text":"list length img containing labeled objects.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_label.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Labels objects — object_label","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { img <- image_pliman(\"soybean_touch.jpg\") # segment the objects using the \"B\" (blue) band. object_label(img, index = \"B\") object_label(img, index = \"B\", watershed = TRUE) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Map Object Distances — object_map","title":"Map Object Distances — object_map","text":"Computes distances objects anal_obj object returns list distances, coefficient variation (CV), means.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map Object Distances — object_map","text":"","code":"object_map(object, by_column = \"img\", direction = c(\"horizontal\", \"vertical\"))"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map Object Distances — object_map","text":"object anal_obj object computed analyze_objects_shp(). by_column column name object's results data frame group objects . Default \"img\". direction direction mapping. one \"horizontal\" \"vertical\". Default \"horizontal\".","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map Object Distances — object_map","text":"list following components: distances list distances objects grouped unique values specified column/row. cvs vector coefficient variation (CV) values column/row. means vector mean distances column/row.","code":""},{"path":[]},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Map Object Distances — object_map","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) flax <- image_pliman(\"flax_leaves.jpg\", plot =TRUE) res <-    analyze_objects_shp(flax,                        nrow = 3,                        ncol = 1,                        watershed = FALSE,                        index = \"R/(G/B)\",                        plot = FALSE) plot(res$final_image_mask) plot(res$shapefiles)  # distance from each leave within each row result <- object_map(res) result$distances result$cvs result$means }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_mark.html","id":null,"dir":"Reference","previous_headings":"","what":"Mark Object Points — object_mark","title":"Mark Object Points — object_mark","text":"Marks coordinates objects anal_obj object plot.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_mark.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mark Object Points — object_mark","text":"","code":"object_mark(object, col = \"white\")"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_mark.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mark Object Points — object_mark","text":"object anal_obj object computed analyze_objects_shp() analyze_objects_shp(). col color marked points. Default \"white\".","code":""},{"path":[]},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_mark.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mark Object Points — object_mark","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) flax <- image_pliman(\"flax_leaves.jpg\", plot =TRUE) res <-    analyze_objects(flax,                        watershed = FALSE,                        index = \"R/(G/B)\",                        plot = FALSE) object_mark(res) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_rgb.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract red, green and blue values from objects — object_rgb","title":"Extract red, green and blue values from objects — object_rgb","text":"Given image matrix labels identify object, function extracts red, green, blue values object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_rgb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract red, green and blue values from objects — object_rgb","text":"","code":"object_rgb(img, labels)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_rgb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract red, green and blue values from objects — object_rgb","text":"img Image object labels mask containing labels object. can obtained EBImage::bwlabel() EBImage::watershed()","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_rgb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract red, green and blue values from objects — object_rgb","text":"data.frame n rows (number pixels objects) following columns: id: object id; R: value red band; G: value blue band; B: value green band;","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_rgb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract red, green and blue values from objects — object_rgb","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"soybean_touch.jpg\") # segment the objects using the \"B\" (blue) band (default)  labs <- object_label(img, watershed = TRUE) rgb <- object_rgb(img, labs[[1]]) head(rgb) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_scatter.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot object thumbnails at (x, y) coordinates derived from image features — object_scatter","title":"Plot object thumbnails at (x, y) coordinates derived from image features — object_scatter","text":"Extracts connected objects image, computes features, crops object, converts crop raster alpha, draws thumbnail centered corresponding (x, y) feature location ggplot. Optionally overlays object IDs. Caching can used avoid recomputing object features repeated calls.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_scatter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot object thumbnails at (x, y) coordinates derived from image features — object_scatter","text":"","code":"object_scatter(   img,   x,   y,   scale = 0.1,   xy_ratio = 1,   xlab = x,   ylab = y,   erosion = 2,   dilatation = FALSE,   show_id = FALSE,   color_id = \"black\",   size_id = 3,   cache = TRUE,   verbose = TRUE,   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_scatter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot object thumbnails at (x, y) coordinates derived from image features — object_scatter","text":"img image class EBImage::Image (compatible) objects segmented measured. x Character scalar. Name feature column (returned get_measures(res)) use x-axis. y Character scalar. Name feature column use y-axis. scale Numeric (0, 1]. Relative thumbnail size fraction data range along axis (larger values draw larger thumbnails). xy_ratio Numeric scalar. Factor applied vertical scaling (y-axis) thumbnails. Use values 1 stretch compress thumbnails vertically. xlab, ylab Character scalars used x- y-axis labels. Defaults x y, respectively. erosion, dilatation Integer (non-negative). Size structuring element morphological erosion/dilatation segmented objects. show_id Logical. TRUE, overlays object IDs x, y locations. color_id Character. Color used ID labels show_id = TRUE. size_id Numeric. Text size ID labels show_id = TRUE. cache Logical. TRUE (default), caches results object extraction using simple key based image dimensions parameters. verbose TRUE (default), shows progress analysis. ... Additional arguments forwarded analyze_objects().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_scatter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot object thumbnails at (x, y) coordinates derived from image features — object_scatter","text":"list two elements: features — data frame (tibble) object-level features returned get_measures(res). Must contain columns named x y. plot — ggplot object. thumbnail scatter plot.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_scatter.html","id":"scaling-behavior","dir":"Reference","previous_headings":"","what":"Scaling behavior","title":"Plot object thumbnails at (x, y) coordinates derived from image features — object_scatter","text":"Thumbnails sized relative observed ranges x y. two axes differ substantially range, perceived thumbnail aspect plotting device may vary. Use xy_ratio adjust vertical scaling.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_scatter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot object thumbnails at (x, y) coordinates derived from image features — object_scatter","text":"","code":"if(interactive()){ img <- image_pliman(\"potato_leaves.jpg\") plot(img) res <- object_scatter(  img = img,  index = \"B\",  x = \"area\",  y = \"solidity\",  watershed = FALSE,  scale = 0.5 ) res$plot  # remove cached data clear_pliman_cache() }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_split.html","id":null,"dir":"Reference","previous_headings":"","what":"Splits objects from an image into multiple images — object_split","title":"Splits objects from an image into multiple images — object_split","text":"Using threshold-based segmentation, objects first isolated background. , new image created single object. list images returned.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Splits objects from an image into multiple images — object_split","text":"","code":"object_split(   img,   index = \"NB\",   lower_size = NULL,   watershed = TRUE,   invert = FALSE,   fill_hull = FALSE,   opening = 3,   closing = FALSE,   filter = FALSE,   erode = FALSE,   dilate = FALSE,   threshold = \"Otsu\",   extension = NULL,   tolerance = NULL,   object_size = \"medium\",   edge = 3,   remove_bg = FALSE,   plot = TRUE,   verbose = TRUE,   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Splits objects from an image into multiple images — object_split","text":"img image analyzed. index character value specifying target mode conversion binary image foreground background declared. Defaults \"NB\" (normalized blue). See image_index() details. User can also calculate index using bands names, e.g. index = \"R+B/G\" lower_size Plant images often contain dirt dust. prevent dust affecting image analysis, objects lesser 10% mean objects removed. Set lower_limit = 0 keep objects. watershed TRUE (default) performs watershed-based object detection. detect objects even touching one . FALSE, pixels connected set foreground pixels set unique object. faster able segment touching objects. invert Inverts binary image desired. useful process images black background. Defaults FALSE. reference = TRUE use, invert can declared logical vector length 2 (eg., invert = c(FALSE, TRUE). case, segmentation objects reference foreground using back_fore_index performed using default (inverted), segmentation objects reference performed inverting selection (selecting pixels higher threshold). fill_hull Fill holes binary image? Defaults FALSE. useful fill holes objects portions color similar background. IMPORTANT: Objects touching can combined one single object, may underestimate number objects image. opening, closing, filter, erode, dilate Morphological operations (brush size) dilate puts mask every background pixel, sets foreground pixels covered mask foreground. erode puts mask every foreground pixel, sets background pixels covered mask background. opening performs erosion followed dilation. helps remove small objects preserving shape size larger objects. closing performs dilatation followed erosion. helps fill small holes preserving shape size larger objects. filter performs median filtering binary image. Provide positive integer > 1 indicate size median filtering. Higher values efficient remove noise background can dramatically impact perimeter objects, mainly irregular perimeters leaves serrated edges. threshold theshold method used. default (threshold = \"Otsu\"), threshold value based Otsu's method used reduce grayscale image binary image. numeric value informed, value used threshold. threshold = \"adaptive\", adaptive thresholding (Shafait et al. 2008) used, depend k windowsize arguments. non-numeric value different \"Otsu\" \"adaptive\" used, iterative section allow choose threshold based raster plot showing pixel intensity index. extension Radius neighborhood pixels detection neighboring objects. Higher value smooths small objects. tolerance minimum height object units image intensity highest point (seed) point contacts another object (checked every contact pixel). height smaller tolerance, object combined one neighbors, highest. object_size size object. Used automatically set tolerance extension parameters. One following. \"small\" (e.g, wheat grains), \"medium\" (e.g, soybean grains), \"large\"(e.g, peanut grains), \"elarge\" (e.g, soybean pods)`. edge number pixels added edge segmented object. Defaults 5. remove_bg TRUE, pixels part objects converted white. plot Show image processing? verbose TRUE (default) summary shown console. ... Additional arguments passed image_combine()","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Splits objects from an image into multiple images — object_split","text":"list objects class Image.","code":""},{"path":[]},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_split.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Splits objects from an image into multiple images — object_split","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"la_leaves.jpg\", plot = TRUE) imgs <- object_split(img) # set to NULL to use 50% of the cores }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_split_shp.html","id":null,"dir":"Reference","previous_headings":"","what":"Splits image objects based on a shape file — object_split_shp","title":"Splits image objects based on a shape file — object_split_shp","text":", image_shp() used create shape file based desired number rows columns. , using object coordinates, list Image objects created.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_split_shp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Splits image objects based on a shape file — object_split_shp","text":"","code":"object_split_shp(   img,   nrow = 1,   ncol = 1,   buffer_x = 0,   buffer_y = 0,   interactive = FALSE,   viewer = get_pliman_viewer(),   only_shp = FALSE,   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_split_shp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Splits image objects based on a shape file — object_split_shp","text":"img object class Image nrow number desired rows grid. Defaults 1. ncol number desired columns grid. Defaults 1. buffer_x, buffer_y Buffering factor width height, respectively, individual shape's side. value 0 0.5 0 means buffering 0.5 means complete buffering (default: 0). value 0.25 buffer shape 25% side. interactive FALSE (default) grid created automatically based image dimension number rows/columns. interactive = TRUE, users must draw points diagonal desired bounding box contain grid. viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. only_shp TRUE returns shapefiles coordinates image. FALSE (default) returns splitted image according nrow ncol arguments. ... arguments passed image_shp()","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_split_shp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Splits image objects based on a shape file — object_split_shp","text":"list Image objects","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_split_shp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Splits image objects based on a shape file — object_split_shp","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) flax <- image_pliman(\"flax_leaves.jpg\", plot = TRUE) objects <- object_split_shp(flax, nrow = 3, ncol = 5) image_combine(objects$imgs) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_to_color.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply color to image objects — object_to_color","title":"Apply color to image objects — object_to_color","text":"function applies color informed argument color segmented objects image. segmentation performed using image indexes. Use image_index() identify better candidate index segment objects.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_to_color.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply color to image objects — object_to_color","text":"","code":"object_to_color(   img,   pick_palettes = FALSE,   background = NULL,   foreground = NULL,   index = \"NB\",   color = \"blue\",   plot = TRUE,   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_to_color.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply color to image objects — object_to_color","text":"img image object. pick_palettes Logical argument indicating wheater user needs pick color palettes foreground background image. TRUE pick_palette() called internally user can sample color points representing foreground background. foreground, background color palette foregrond background, respectively (optional). index character value (vector characters) specifying target mode conversion binary image. See available indexes pliman_indexes() image_index() details. color color apply image objects. Defaults \"blue\". plot Plots modified image? Defaults TRUE. ... Additional arguments passed image_binary().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_to_color.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply color to image objects — object_to_color","text":"object class Image","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/object_to_color.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply color to image objects — object_to_color","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"la_leaves.jpg\") img2 <- object_to_color(img, index = \"G-R\") image_combine(img, img2) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/otsu.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Otsu's threshold — otsu","title":"Calculate Otsu's threshold — otsu","text":"Given numeric vector pixel's intensities, returns threshold value based Otsu's method, minimizes combined intra-class variance","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/otsu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Otsu's threshold — otsu","text":"","code":"otsu(values)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/otsu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Otsu's threshold — otsu","text":"values numeric vector pixel values.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/otsu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Otsu's threshold — otsu","text":"double (threshold value).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/otsu.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate Otsu's threshold — otsu","text":"Otsu, N. 1979. Threshold selection method gray-level histograms. IEEE Trans Syst Man Cybern SMC-9(1): 62–66. doi: doi:10.1109/tsmc.1979.4310076","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/otsu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Otsu's threshold — otsu","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { img <- image_pliman(\"soybean_touch.jpg\") thresh <- otsu(img@.Data[,,3]) plot(img[,,3] < thresh) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/palettes.html","id":null,"dir":"Reference","previous_headings":"","what":"Create image palettes — palettes","title":"Create image palettes — palettes","text":"image_palette()  creates image palettes applying k-means algorithm RGB values.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/palettes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create image palettes — palettes","text":"","code":"image_palette(   img,   pattern = NULL,   npal = 5,   proportional = TRUE,   colorspace = c(\"rgb\", \"hsb\"),   remove_bg = FALSE,   index = \"B\",   plot = TRUE,   save_image = FALSE,   prefix = \"proc_\",   dir_original = NULL,   dir_processed = NULL,   return_pal = FALSE,   parallel = FALSE,   workers = NULL,   verbose = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/palettes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create image palettes — palettes","text":"img image object. pattern pattern file name used identify images imported. example, pattern = \"im\" images current working directory name matches pattern (e.g., img1.-, image1.-, im2.-) imported list. Providing number pattern (e.g., pattern = \"1\") select images named 1.-, 2.-, . error returned pattern matches file supported (e.g., img1.pdf). npal number color palettes. proportional Creates joint palette proportional size equal number pixels image? Defaults TRUE. colorspace color space produce clusters. Defaults rgb. hsb, color space first converted RGB > HSB k-means algorithm applied. remove_bg Remove background color palette? Defaults FALSE. index image index used remove background, passed image_binary(). plot Plot generated palette? Defaults TRUE. save_image Save image processing? image saved current working directory named proc_* * image name given img. prefix prefix included processed images. Defaults \"proc_\". dir_original, dir_processed directory containing original processed images. Defaults NULL. case, function search image img current working directory. processing, save_image = TRUE, processed image also saved directory. can either full path, e.g., \"C:/Desktop/imgs\", subfolder within current working directory, e.g., \"/imgs\". return_pal Return color palette image? Defaults FALSE. parallel TRUE processes images asynchronously (parallel) separate R sessions running background machine. workers positive numeric scalar function specifying number parallel processes can active time. default, number sections set 30% available cores. verbose TRUE (default) summary shown console.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/palettes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create image palettes — palettes","text":"image_palette() returns list two elements: palette_list list npal color palettes class Image. joint object class Image color palettes proportions proportion entire image corresponding color palette rgbs average RGB value palette","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/palettes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create image palettes — palettes","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"sev_leaf.jpg\") pal <- image_palette(img, npal = 5) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward-pipe operator — pipe","title":"Forward-pipe operator — pipe","text":"Pipe object forward function call expression.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward-pipe operator — pipe","text":"","code":"lhs %>% rhs"},{"path":"https://nepem-ufsc.github.io/pliman/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward-pipe operator — pipe","text":"lhs result piping. rhs piping result .","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/pipe.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Forward-pipe operator — pipe","text":"Nathan Eastwood nathan.eastwood@icloud.com Antoine Fabri antoine.fabri@gmail.com. code obtained poorman package https://github.com/nathaneastwood/poorman/blob/master/R/pipe.R","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/pipe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward-pipe operator — pipe","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman)  # Basic use:  iris %>% head()  # use to apply several functions to an image img <- image_pliman(\"la_leaves.jpg\")  img %>%  image_resize(50) %>%        # resize to 50% of the original size  object_isolate(id = 1) %>%  # isolate object 1  image_filter() %>%          # apply a median filter  plot()                      # plot }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/pixel_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the pixel indices for a given row of a binary image — pixel_index","title":"Get the pixel indices for a given row of a binary image — pixel_index","text":"function finds first row bin matrix value greater 0 (TRUE). calculates minimum, median, maximum values pixels row creates array containing row index, minimum pixel index, median pixel index, maximum pixel index.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/pixel_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the pixel indices for a given row of a binary image — pixel_index","text":"","code":"pixel_index(bin, row = NULL, direction = \"updown\")"},{"path":"https://nepem-ufsc.github.io/pliman/reference/pixel_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the pixel indices for a given row of a binary image — pixel_index","text":"bin logical matrix representing binary image row optional row index. provided, function selects first non-zero row. direction direction row selection row provided. set \"updown\", function starts scanning top image towards bottom. set \"downup\", function starts scanning bottom towards top.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/pixel_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the pixel indices for a given row of a binary image — pixel_index","text":"numeric vector containing row index, minimum pixel index, median pixel index, maximum pixel index.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/pixel_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the pixel indices for a given row of a binary image — pixel_index","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) leaf <- image_pliman(\"sev_leaf.jpg\") bin <- image_binary(leaf, \"NB\")[[1]]  # first row with leaf (17) pixel_index(bin)  # index at the row 100 pixel_index(bin, row = 100)  plot(leaf) points(x = 248, y = 17, pch = 16, col = \"red\", cex = 2) points(x = 163, y = 100, pch = 16, col = \"red\", cex = 2) points(x = 333, y = 100, pch = 16, col = \"red\", cex = 2) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/pliman_images.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample images — pliman_images","title":"Sample images — pliman_images","text":"Sample images installed pliman package","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/pliman_images.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample images — pliman_images","text":"*.jpg format flax_leaves.jpg Flax leaves white background flax_grains.jpg Flax grains background light. la_back.jpg cyan palette representing background images la_pattern, la_leaves, soybean_touch. la_leaf.jpg sample leaves la_leaves la_leaves.jpg Tree leaves sample known area. mult_leaves.jpg Three soybean leaflets soybean rust symptoms. objects_300dpi.jpg image 300 dpi resolution. potato_leaves.jpg Three potato leaves, gathered Gupta et al. (2020). sev_leaf.jpg soybean leaf blue background. sev_leaf_nb.jpg soybean leaf without background. sev_back.jpg blue palette representing background sev_leaf. sev_healthy.jpg Healthy area sev_leaf. sev_sympt.jpg symptomatic area sev_leaf. shadow.jpg shaded leaf, useful test adaptive thresholding soy_green.jpg Soybean grains white background. soybean_grain.jpg sample palette grains soy_green. soybean_touch.jpg Soybean grains cyan background touching one . field_mosaic.jpg UVA image soybean field. *.tif format following .tif files provided sample data, representing slice large orthomosaic soybean plots vegetative stage. files kindly provided Arthur Bernardeli. ortho.tif: orthomosaic soybean plots (5 rows 3 columns). dsm.tif: digital surface model (DSM) soybean plots. dtm.tif: digital terrain model (DTM) area. mask.tif: mask represents soybean plants.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/pliman_images.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Sample images — pliman_images","text":"Personal data, Gupta et al. (2020).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/pliman_images.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample images — pliman_images","text":"Gupta, S., Rosenthal, D. M., Stinchcombe, J. R., & Baucom, R. S. (2020). remarkable morphological diversity leaf shape sweet potato (Ipomoea batatas): influence genetics, environment, G×E. New Phytologist, 225(5), 2183–2195. doi:10.1111/NPH.16286","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/pliman_images.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sample images — pliman_images","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/pliman_indexes_ican_compute.html","id":null,"dir":"Reference","previous_headings":"","what":"List Computable Indexes Based on Available Bands — pliman_indexes_ican_compute","title":"List Computable Indexes Based on Available Bands — pliman_indexes_ican_compute","text":"function reads index equations CSV file included pliman package, determines bands used index equation, checks indexes can computed based provided available bands.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/pliman_indexes_ican_compute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List Computable Indexes Based on Available Bands — pliman_indexes_ican_compute","text":"","code":"pliman_indexes_ican_compute(available)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/pliman_indexes_ican_compute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List Computable Indexes Based on Available Bands — pliman_indexes_ican_compute","text":"available character vector available bands (e.g., c(\"R\", \"G\")).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/pliman_indexes_ican_compute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List Computable Indexes Based on Available Bands — pliman_indexes_ican_compute","text":"data frame indexes can computed available bands.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/pliman_indexes_ican_compute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List Computable Indexes Based on Available Bands — pliman_indexes_ican_compute","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) available_bands <- c(\"R\", \"G\") computable_indexes <- pliman_indexes_ican_compute(available_bands) print(computable_indexes) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/pliman_viewer.html","id":null,"dir":"Reference","previous_headings":"","what":"Global option for controlling the viewer in pliman package — pliman_viewer","title":"Global option for controlling the viewer in pliman package — pliman_viewer","text":"Users can set value option using options(\"pliman_viewer\", value). default value \"base\". Use \"mapview\" allow image plotted/edited using R packages mapview mapedit","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot.image_shp.html","id":null,"dir":"Reference","previous_headings":"","what":"S3 method plot for image_shp objects — plot.image_shp","title":"S3 method plot for image_shp objects — plot.image_shp","text":"Draws bounding boxes object computed image_shp().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot.image_shp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"S3 method plot for image_shp objects — plot.image_shp","text":"","code":"# S3 method for class 'image_shp' plot(   x,   img = NULL,   col_line = \"black\",   size_line = 2,   col_text = \"black\",   size_text = 0.75,   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot.image_shp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"S3 method plot for image_shp objects — plot.image_shp","text":"x object computed image_shp(). img image used compute shapefile (optional) col_line, col_text color line/text grid. Defaults \"red\". size_line, size_text size line/text grid. Defaults 2.5. ... Currently used.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot.image_shp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"S3 method plot for image_shp objects — plot.image_shp","text":"NULL object","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot.image_shp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"S3 method plot for image_shp objects — plot.image_shp","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) flax <- image_pliman(\"flax_leaves.jpg\") shape <- image_shp(flax, nrow = 3, ncol = 5)  # grid on the existing image plot(flax) plot(shape) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_bbox.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Bounding Boxes to an Existing Plot — plot_bbox","title":"Add Bounding Boxes to an Existing Plot — plot_bbox","text":"function overlays bounding boxes onto existing plot.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_bbox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Bounding Boxes to an Existing Plot — plot_bbox","text":"","code":"plot_bbox(bbox_list, col = \"red\")"},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_bbox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Bounding Boxes to an Existing Plot — plot_bbox","text":"bbox_list list bounding boxes, returned object_bbox(). col color bounding boxes. Defaults \"red\".","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_bbox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Bounding Boxes to an Existing Plot — plot_bbox","text":"None (adds bounding boxes existing plot).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_bbox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Bounding Boxes to an Existing Plot — plot_bbox","text":"","code":"if(interactive()){ plot(NA,     xlim = c(0, 200),     ylim = c(0, 200),     asp = 1) contours <- list(   matrix(c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100,            110, 120, 130, 140, 150, 160, 170, 180, 190, 200),          ncol = 2, byrow = FALSE) ) bbox_list <- object_bbox(contours) plot_bbox(bbox_list) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_id.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate plot IDs with different layouts — plot_id","title":"Generate plot IDs with different layouts — plot_id","text":"Based shapefile, number columns rows, generate plot IDs different layouts.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_id.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate plot IDs with different layouts — plot_id","text":"","code":"plot_id(   shapefile,   nrow,   ncol,   layout = c(\"tblr\", \"tbrl\", \"btlr\", \"btrl\", \"lrtb\", \"lrbt\", \"rltb\", \"rlbt\"),   plot_prefix = \"P\",   serpentine = FALSE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_id.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate plot IDs with different layouts — plot_id","text":"shapefile object computed shapefile_build() nrow number columns ncol number rows layout Character: one 'tblr' top/bottom left/right orientation 'tbrl' top/bottom right/left orientation 'btlr' bottom/top left/right orientation 'btrl' bottom/top right/left orientation 'lrtb' left/right top/bottom orientation 'lrbt' left/right bottom/top orientation 'rltb' right/left top/bottom orientation 'rlbt' right/left bottom/top orientation plot_prefix plot_id prefix. Defaults 'P'. serpentine Create serpentine-based layout? Defaults FALSE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_id.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate plot IDs with different layouts — plot_id","text":"vector plot IDs specified layout","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot an image index — plot_index","title":"Plot an image index — plot_index","text":"Plot image index","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot an image index — plot_index","text":"","code":"plot_index(   img = NULL,   object = NULL,   index = NULL,   remove_bg = TRUE,   viewer = get_pliman_viewer(),   all_layers = TRUE,   layer = 1,   max_pixels = 1e+06,   downsample = NULL,   downsample_fun = NULL,   color_regions = custom_palette(n = 100),   ncol = NULL,   nrow = NULL,   aspect_ratio = NA )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot an image index — plot_index","text":"img optional Image object object computed image_index(). object provided, input image obtained internally. object object computed analyze_objects() using argument return_mask = TRUE. index index plot. Defaults index computed object provided. Otherwise, B index computed. See image_index() details. remove_bg Logical value indicating whether remove background object provided. Defaults TRUE. viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. all_layers Render layers img object computed image_index() viewer = \"mapview\"?. layer layer plot img object computed image_index() viewer = \"mapview\". Defaults first layer (first index computed). max_pixels integer > 0. Maximum number cells plot index. max_pixels < npixels(img), downsampling performed plotting index. Using large number pixels may slow plotting time. downsample integer; dimension number pixels/lines/bands etc skipped; Defaults NULL, find best downsampling factor approximate max_pixels value. downsample_fun function; given, downsampling apply downsample_fun``  subtiles. color_regions color palette displaying index values. Default custom_palette(). nrow, ncol number rows columns plot grid. Defaults NULL, .e., square grid produced. aspect_ratio Numeric, giving aspect ratio y/x. Defaults NA. See graphics::plot.window() details.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot an image index — plot_index","text":"None","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot an image index — plot_index","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { # Example usage: library(pliman) img <- image_pliman(\"sev_leaf.jpg\") plot_index(img, index = c(\"R\", \"G\")) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_index_shp.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot rectangles colored by a quantitative attribute and overlay on an RGB image — plot_index_shp","title":"Plot rectangles colored by a quantitative attribute and overlay on an RGB image — plot_index_shp","text":"function plots rectangles top RGB image, rectangle colored based quantitative variable. quantitative variable specified attribute argument present object_index object computed using analyze_objects_shp(). rectangles colored using color scale.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_index_shp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot rectangles colored by a quantitative attribute and overlay on an RGB image — plot_index_shp","text":"","code":"plot_index_shp(   object,   attribute = \"coverage\",   r = 1,   g = 2,   b = 3,   color = c(\"red\", \"yellow\", \"darkgreen\"),   viewer = c(\"mapview\", \"base\"),   max_pixels = 5e+05,   downsample = NULL,   downsample_fun = NULL,   alpha = 0.7,   legend.position = \"bottom\",   na.color = \"gray\",   classes = 6,   round = 3,   horiz = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_index_shp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot rectangles colored by a quantitative attribute and overlay on an RGB image — plot_index_shp","text":"object object computed analyze_objects_shp(). attribute name quantitative variable object_index used coloring rectangles. r, g, b layer Red, Green Blue band, respectively. Defaults 1, 2, 3. color vector two colors used color scale. viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. max_pixels integer > 0. Maximum number cells plot index. max_pixels < npixels(img), downsampling performed plotting index. Using large number pixels may slow plotting time. downsample integer; dimension number pixels/lines/bands etc skipped; Defaults NULL, find best downsampling factor approximate max_pixels value. downsample_fun function; given, downsampling apply downsample_fun``  subtiles. alpha transparency level rectangles' color (0 1). legend.position position color legend, either \"bottom\" \"right\". na.color color used rectangles missing values quantitative variable. classes number classes color scale. round number decimal places round legend values. horiz Logical, whether legend horizontal (TRUE) vertical (FALSE).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_index_shp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot rectangles colored by a quantitative attribute and overlay on an RGB image — plot_index_shp","text":"function plots rectangles colored specified quantitative variable top RGB image shows continuous color legend outside plot.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_index_shp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot rectangles colored by a quantitative attribute and overlay on an RGB image — plot_index_shp","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman)  # Computes the DGCI index for each flax leaf flax <- image_pliman(\"flax_leaves.jpg\", plot =TRUE) res <-    analyze_objects_shp(flax,                        buffer_x = 0.1,                        buffer_y = 0.02,                        nrow = 3,                        ncol = 5,                        plot = FALSE,                        object_index = \"DGCI\") plot_index_shp(res, attribute = \"DGCI\") }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_line_segment.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Detected Line Segments — plot_line_segment","title":"Plot Detected Line Segments — plot_line_segment","text":"Plots detected line segments output image_line_segment(). segment drawn red line existing plot.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_line_segment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Detected Line Segments — plot_line_segment","text":"","code":"plot_line_segment(x, col = \"red\", lwd = 1)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_line_segment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Detected Line Segments — plot_line_segment","text":"x list returned image_line_segment(), containing detected line segments. col color lines lwd width lines. Defaults 1","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_line_segment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Detected Line Segments — plot_line_segment","text":"return value. function adds line segments existing plot.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_line_segment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Detected Line Segments — plot_line_segment","text":"","code":"library(pliman)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_lw.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot length and width lines on objects — plot_lw","title":"Plot length and width lines on objects — plot_lw","text":"function plots length width lines given object computed analyze_objects(). function call plot.new, must called image plotted. can done either using, e.g., plot(img), analyze_objects(..., plot = TRUE).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_lw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot length and width lines on objects — plot_lw","text":"","code":"plot_lw(   object,   col_length = \"red\",   col_width = \"green\",   lwd_length = 2,   lwd_width = 2 )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_lw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot length and width lines on objects — plot_lw","text":"object object computed analyze_objects(). col_length color length line. Default \"red\". col_width color width line. Default \"green\". lwd_length line width length line. Default 2. lwd_width line width width line. Default 2.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_lw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot length and width lines on objects — plot_lw","text":"function takes object computed analyze_objects() plots length width lines object onto image. length width lines calculated based position orientation object, plotted using specified colors line widths.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/plot_lw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot length and width lines on objects — plot_lw","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { img <- image_pliman(\"flax_leaves.jpg\") res <- analyze_objects(img, watershed = FALSE, show_contour = FALSE) plot_lw(res) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_apex_base_angle.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the apex and base angles of an object — poly_apex_base_angle","title":"Calculate the apex and base angles of an object — poly_apex_base_angle","text":"function calculates apex base angles object. takes input matrix coordinates returns apex angle, base angle, coordinates apex base list. angles computed object aligned vertical axis poly_align().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_apex_base_angle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the apex and base angles of an object — poly_apex_base_angle","text":"","code":"poly_apex_base_angle(   x,   percentiles = c(0.25, 0.75),   invert = FALSE,   plot = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_apex_base_angle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the apex and base angles of an object — poly_apex_base_angle","text":"x matrix coordinates representing contour object, often obtained object_contour(). percentiles numeric vector two percentiles 0 1 indicating height points top bottom. function calculates apex angle two percentiles base angle lowest point highest point. invert TRUE, aligns object along horizontal axis. plot Plots polygon points? Defaults TRUE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_apex_base_angle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the apex and base angles of an object — poly_apex_base_angle","text":"list containing apex angle, base angle, apex coordinates, base coordinates.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_apex_base_angle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the apex and base angles of an object — poly_apex_base_angle","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) # a matrix of coordinates angls <- poly_apex_base_angle(contours[[2]]) angls  # or a list of coordinates poly_apex_base_angle(contours) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_pcv.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Perimeter Complexity Value (PCV) — poly_pcv","title":"Compute Perimeter Complexity Value (PCV) — poly_pcv","text":"function calculates Perimeter Complexity Value (PCV) given set coordinates representing contour. PCV measures variation distances original coordinates smoothed coordinates relative perimeter length original contour. See details section.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_pcv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Perimeter Complexity Value (PCV) — poly_pcv","text":"","code":"poly_pcv(x, niter = 100)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_pcv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Perimeter Complexity Value (PCV) — poly_pcv","text":"x matrix list matrices representing coordinates polygon(s). niter integer specifying number smoothing iterations. See poly_smooth() details.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_pcv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Perimeter Complexity Value (PCV) — poly_pcv","text":"PCV value(s) computed contour(s). x matrix, returns complexity value polygon's perimeter. x list matrices, returns numeric vector complexity values polygon.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_pcv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Perimeter Complexity Value (PCV) — poly_pcv","text":"PCV computed using following formula: $$PCV = \\frac{sum(dists) \\times sd(dists)}{perim}$$ \\(dists\\) represents distances corresponding points original smoothed coordinates, \\(perim\\) perimeter length smoothed contour. PCV computed first smoothing input contour using specified number iterations. smoothed contour used compute distances corresponding points original smoothed coordinates. distances reflect variations contour shape smoothing. sum distances represents overall magnitude variations. Next, sum distances multiplied standard deviation distances capture dispersion spread variations. Finally, value divided perimeter length original contour provide relative measure complexity. Therefore, PCV provides relative measure complexity considering magnitude spread variations contour shape smoothing.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_pcv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Perimeter Complexity Value (PCV) — poly_pcv","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) set.seed(20) shp <- efourier_shape(npoints = 1000) poly_pcv(shp)  # increase the complexity of the outline shp2 <- poly_jitter(shp, noise_x = 20, noise_y = 250, plot = TRUE)  smo <- poly_smooth(shp2, niter = 100, plot = FALSE) plot_contour(smo, col = \"red\") poly_pcv(shp2) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_width_at.html","id":null,"dir":"Reference","previous_headings":"","what":"Width at a given height — poly_width_at","title":"Width at a given height — poly_width_at","text":"function computes polygonal convex hull points x returns number points lie specified set heights along vertical axis convex hull.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_width_at.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Width at a given height — poly_width_at","text":"","code":"poly_width_at(   x,   at = c(0.05, 0.25, 0.5, 0.75, 0.95),   unify = FALSE,   plot = FALSE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_width_at.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Width at a given height — poly_width_at","text":"x vector containing two-dimensional data points (often produced object_contour). vector heights along vertical axis convex hull count number points . default value c(0.05, 0.25, 0.5, 0.75, 0.95), means function return number points 5th, 25th, 50th, 75th, 95th percentiles convex hull. = \"heights\" used, function returns width point object length. unify logical value indicating whether use unified convex hull calculation method. unify = TRUE, coordinates x first bound computing convex hull. plot logical value specifies whether widths plotted.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_width_at.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Width at a given height — poly_width_at","text":"vector widths convex hull specified heights list vectors widths component.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_width_at.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Width at a given height — poly_width_at","text":"convex hull computed x aligned along major axis converted binary image. height vector, function computes corresponding row number binary image (.e., row number corresponds specified height along vertical axis convex hull) sums values row obtain number points lie specified height. convex hull contains multiple polygons unify = FALSE, function loops polygon returns list number points specified heights polygon. convex hull contains one polygon multiple polygons unify = TRUE, function returns vector number points specified heights single polygon.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/poly_width_at.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Width at a given height — poly_width_at","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { cont <- contours[[2]] plot_polygon(cont |> conv_hull() |> poly_align()) #  width below 5th, 25th, 50th, 75th, and 95th percentiles of the length wd <- poly_width_at(cont) wd  # width along the height poly_width_at(cont, at = \"height\", plot = TRUE)  }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/prepare_to_shp.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare images to analyze_objects_shp() — prepare_to_shp","title":"Prepare images to analyze_objects_shp() — prepare_to_shp","text":"simple wrapper around image_align() image_crop(). case, option viewer = \"base\" used. use viewer = \"mapview\", please, use functions separately.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/prepare_to_shp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare images to analyze_objects_shp() — prepare_to_shp","text":"","code":"prepare_to_shp(img, align = \"vertical\")"},{"path":"https://nepem-ufsc.github.io/pliman/reference/prepare_to_shp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare images to analyze_objects_shp() — prepare_to_shp","text":"img Image object align desired alignment. Either \"vertical\" (default) \"horizontal\".","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/prepare_to_shp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare images to analyze_objects_shp() — prepare_to_shp","text":"aligned cropped Image object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/prepare_to_shp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare images to analyze_objects_shp() — prepare_to_shp","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { img <- image_pliman(\"flax_leaves.jpg\") prepare_to_shp(img) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/random_color.html","id":null,"dir":"Reference","previous_headings":"","what":"Random built-in color names — random_color","title":"Random built-in color names — random_color","text":"Randomly chooses single multiple built-color names R knows . See grDevices::colors()","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/random_color.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random built-in color names — random_color","text":"","code":"random_color(n = 1, distinct = FALSE)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/random_color.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random built-in color names — random_color","text":"n number color names. Defaults 1. distinct Logical indicating colors returned distinct. Defaults FALSE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/random_color.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random built-in color names — random_color","text":"character vector color names","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/random_color.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random built-in color names — random_color","text":"","code":"library(pliman) random_color(n = 3)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/sad.html","id":null,"dir":"Reference","previous_headings":"","what":"Produces Santandard Area Diagrams — sad","title":"Produces Santandard Area Diagrams — sad","text":"Given object computed measure_disease() measure_disease_byl() Standard Area Diagram (SAD) n images returned respective severity values.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/sad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produces Santandard Area Diagrams — sad","text":"","code":"sad(   object,   n,   show_original = FALSE,   show_contour = FALSE,   nrow = NULL,   ncol = NULL,   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/sad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produces Santandard Area Diagrams — sad","text":"object object computed measure_disease() measure_disease_byl(). n number leaves Standard Area Diagram. show_original Show original images? Defaults FALSE, .e., mask returned. show_contour Show original images? Defaults FALSE, .e., mask returned. nrow, ncol number rows columns plot. See [image_combine())] [image_combine())]: R:image_combine()) ... arguments passed measure_disease().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/sad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produces Santandard Area Diagrams — sad","text":"data frame severity values n sampled leaves. plot standard area diagram can saved wrapping sad() png().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/sad.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Produces Santandard Area Diagrams — sad","text":"leaves smallest highest severity always SAD. n = 1, leaf smallest severity returned. others sampled sequentially achieve n images severity ordered ascending order. example, 30 leaves n set 3, leaves sampled 1st, 15th, 30th smallest severity values. SAD can computed image pattern name used argument pattern measure_disease(). images saved, n images retrevied dir_processed directory. Otherwise, severity computed generate images.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/sad.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Produces Santandard Area Diagrams — sad","text":"Del Ponte EM, Pethybridge SJ, Bock CH, et al (2017) Standard area diagrams aiding severity estimation: Scientometrics, pathosystems, methodological trends last 25 years. Phytopathology 107:1161–1174. doi:10.1094/PHYTO-02-17-0069-FI","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/sad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produces Santandard Area Diagrams — sad","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) sev <- measure_disease(pattern = \"sev_leaf\",                 img_healthy = \"sev_healthy\",                 img_symptoms = \"sev_sympt\",                 img_background  = \"sev_back\",                 plot = FALSE,                 save_image = TRUE,                 show_original = FALSE,                 dir_original = image_pliman(),                 dir_processed = tempdir()) sad(sev, n = 2) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/sentinel_to_tif.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Sentinel data to GeoTIFF format — sentinel_to_tif","title":"Convert Sentinel data to GeoTIFF format — sentinel_to_tif","text":"function converts Sentinel satellite data files GeoTIFF format.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/sentinel_to_tif.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Sentinel data to GeoTIFF format — sentinel_to_tif","text":"","code":"sentinel_to_tif(layers = NULL, path = \".\", destination, spat_res = 10)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/sentinel_to_tif.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Sentinel data to GeoTIFF format — sentinel_to_tif","text":"layers (character) Vector file paths Sentinel data files. NULL, function searches files specified path names containing \"B\". path (character) Directory path Sentinel data files located. Default current directory. destination (character) File path output GeoTIFF file. spat_res (numeric) Spatial resolution output GeoTIFF file. Default 10 meters.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/sentinel_to_tif.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert Sentinel data to GeoTIFF format — sentinel_to_tif","text":"function converts Sentinel satellite data files GeoTIFF format using GDAL utilities. builds virtual raster file (VRT) input files translates GeoTIFF format. Compression applied output GeoTIFF file using DEFLATE method.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/separate_col.html","id":null,"dir":"Reference","previous_headings":"","what":"Turns a single character column into multiple columns. — separate_col","title":"Turns a single character column into multiple columns. — separate_col","text":"Given either regular expression vector character positions, separate_col() turns single character column multiple columns.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/separate_col.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turns a single character column into multiple columns. — separate_col","text":"","code":"separate_col(.data, col, into, sep = \"[^[:alnum:]]+\")"},{"path":"https://nepem-ufsc.github.io/pliman/reference/separate_col.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turns a single character column into multiple columns. — separate_col","text":".data data frame col Column name Names new variables create character vector sep separator columns. default, regular expression matches sequence non-alphanumeric values.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/separate_col.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Turns a single character column into multiple columns. — separate_col","text":"mutated .data","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/separate_col.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Turns a single character column into multiple columns. — separate_col","text":"","code":"library(pliman) df <- data.frame(x = paste0(\"TRAT_\", 1:5),                  y = 1:5) df #>        x y #> 1 TRAT_1 1 #> 2 TRAT_2 2 #> 3 TRAT_3 3 #> 4 TRAT_4 4 #> 5 TRAT_5 5 separate_col(df, x, into = c(\"TRAT\", \"REP\"))"},{"path":"https://nepem-ufsc.github.io/pliman/reference/set_pliman_viewer.html","id":null,"dir":"Reference","previous_headings":"","what":"Set the value of the pliman_viewer option — set_pliman_viewer","title":"Set the value of the pliman_viewer option — set_pliman_viewer","text":"Sets value pliman_viewer option used package.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/set_pliman_viewer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set the value of the pliman_viewer option — set_pliman_viewer","text":"","code":"set_pliman_viewer(value)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/set_pliman_viewer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set the value of the pliman_viewer option — set_pliman_viewer","text":"value value set pliman_viewer option.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_build.html","id":null,"dir":"Reference","previous_headings":"","what":"Build a shapefile from a mosaic raster — shapefile_build","title":"Build a shapefile from a mosaic raster — shapefile_build","text":"function takes mosaic raster create shapefile containing polygons specified regions. Users can drawn Areas Interest (AOIs) can either polygon n sides, grid, defined nrow, ncol arguments.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_build.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build a shapefile from a mosaic raster — shapefile_build","text":"","code":"shapefile_build(   mosaic,   basemap = NULL,   controlpoints = NULL,   r = 3,   g = 2,   b = 1,   crop_to_shape_ext = TRUE,   grid = TRUE,   nrow = 1,   ncol = 1,   nsides = 200,   plot_width = NULL,   plot_height = NULL,   layout = \"lrtb\",   serpentine = TRUE,   build_shapefile = TRUE,   check_shapefile = FALSE,   sf_to_polygon = FALSE,   buffer_edge = 1,   buffer_col = 0,   buffer_row = 0,   as_sf = TRUE,   verbose = TRUE,   max_pixels = 1e+06,   downsample = NULL,   quantiles = c(0, 1) )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_build.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build a shapefile from a mosaic raster — shapefile_build","text":"mosaic SpatRaster object, typically imported using mosaic_input().  provided, latitude/longitude basemap generated \"EPSG:4326\" coordinate reference system. basemap optional mapview object. controlpoints sf object created mapedit::editMap(), containing polygon defines region interest analyzed. r, g, b layer Red, Green Blue band, respectively. Defaults 1, 2, 3. crop_to_shape_ext Crop mosaic extension shapefile? Defaults TRUE. allows faster index computation region built shapefile much smaller entire mosaic extension. grid Logical, indicating whether use grid segmentation (default: TRUE). nrow Number rows grid (default: 1). ncol Number columns grid (default: 1). nsides number sides geometry generated Draw Circle tool. plot_width, plot_height width height plot shape (mosaic unit). mutually exclusiv buffer_col buffer_row. layout Character: one 'tblr' top/bottom left/right orientation 'tbrl' top/bottom right/left orientation 'btlr' bottom/top left/right orientation 'btrl' bottom/top right/left orientation 'lrtb' left/right top/bottom orientation 'lrbt' left/right bottom/top orientation 'rltb' right/left top/bottom orientation 'rlbt' right/left bottom/top orientation serpentine Create serpentine-based layout? Defaults FALSE. build_shapefile Logical, indicating whether interactively draw ROIs shapefile NULL (default: TRUE). check_shapefile Logical, indicating whether validate shapefile interactive map view (default: TRUE). enables live editing drawn shapefile deleting changing drawn grids. sf_to_polygon Convert sf geometry like POINTS LINES POLYGONS? Defaults FALSE. Using TRUE allows using POINTS extract values raster using exactextractr::exact_extract(). buffer_edge Width buffer around shapefile (default: 5). buffer_col, buffer_row Buffering factor columns rows, respectively, individual plot's side. value 0 0.5 0 means buffering 0.5 means complete buffering (default: 0). value 0.25 buffer plot 25% side. as_sf Logical value indicating whether convert imported shapefile sf object (default TRUE). verbose Logical, indicating whether display verbose output (default: TRUE). max_pixels Maximum number pixels render map plot (default: 500000). downsample Downsampling factor reduce number pixels (default: NULL). case, number pixels image (width x height) greater max_pixels downsampling factor automatically chosen number plotted pixels approximates max_pixels. quantiles upper lower quantiles used color stretching.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_build.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build a shapefile from a mosaic raster — shapefile_build","text":"list built shapefile. element sf object coordinates drawn polygons.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_build.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build a shapefile from a mosaic raster — shapefile_build","text":"Since multiple blocks can created, length arguments grid, nrow, ncol, buffer_edge, buffer_col, buffer_row can either scalar (argument applied drawn blocks), vector length number drawn blocks. last, shapefiles block can created different dimensions.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_build.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build a shapefile from a mosaic raster — shapefile_build","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) mosaic <- mosaic_input(system.file(\"ex/elev.tif\", package=\"terra\")) shps <-       shapefile_build(mosaic,                       nrow = 6,                       ncol = 3,                       buffer_row = -0.05,                       buffer_col = -0.25,                       check_shapefile = FALSE,                       build_shapefile = FALSE) ## Use TRUE to interactively build the plots mosaic_plot(mosaic) shapefile_plot(shps[[1]], add = TRUE) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_edit.html","id":null,"dir":"Reference","previous_headings":"","what":"Edit Features in a Shapefile — shapefile_edit","title":"Edit Features in a Shapefile — shapefile_edit","text":"function allows interactively edit features shapefile using mapedit package.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_edit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Edit Features in a Shapefile — shapefile_edit","text":"","code":"shapefile_edit(   shapefile,   mosaic = NULL,   basemap = NULL,   r = 3,   g = 2,   b = 1,   max_pixels = 3e+06 )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_edit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Edit Features in a Shapefile — shapefile_edit","text":"shapefile shapefile (sf object) can created shapefile_input(). mosaic Optionally, mosaic (SpatRaster) displayed background. basemap optional mapview object. r Red band index RGB display (default 3). g Green band index RGB display (default 2). b Blue band index RGB display (default 1). max_pixels Maximum number pixels -sampling mosaic (default 3e6).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_edit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Edit Features in a Shapefile — shapefile_edit","text":"modified shapefile user-edited features.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_edit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Edit Features in a Shapefile — shapefile_edit","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) shp <- shapefile_input(system.file(\"ex/lux.shp\", package=\"terra\")) edited <- shapefile_edit(shp) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_interpolate.html","id":null,"dir":"Reference","previous_headings":"","what":"Interpolate values at specific points based on coordinates and a target variable — shapefile_interpolate","title":"Interpolate values at specific points based on coordinates and a target variable — shapefile_interpolate","text":"function interpolates values specified points using x, y coordinates target variable shapefile. supports \"Kriging\" \"Tps\" interpolation methods.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_interpolate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interpolate values at specific points based on coordinates and a target variable — shapefile_interpolate","text":"","code":"shapefile_interpolate(   shapefile,   z,   x = \"x\",   y = \"y\",   interpolation = c(\"Kriging\", \"Tps\"),   verbose = FALSE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_interpolate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interpolate values at specific points based on coordinates and a target variable — shapefile_interpolate","text":"shapefile sf object containing x, y, target variable (z) columns. highly recommended use shapefile_measures() obtain data. z string specifying name column shapefile contains target variable interpolated. x string specifying name column containing x-coordinates. Default 'x'. y string specifying name column containing y-coordinates. Default 'y'. interpolation character vector specifying interpolation method. Options \"Kriging\" \"Tps\". verbose Logical; TRUE, progress messages displayed.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_interpolate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interpolate values at specific points based on coordinates and a target variable — shapefile_interpolate","text":"vector interpolated values specified points.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_measures.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract geometric measures from a shapefile object — shapefile_measures","title":"Extract geometric measures from a shapefile object — shapefile_measures","text":"shapefile_measures() calculates key geometric measures number points, area, perimeter, width, height, centroid coordinates given shapefile (polygon) object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_measures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract geometric measures from a shapefile object — shapefile_measures","text":"","code":"shapefile_measures(shapefile, n = NULL)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_measures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract geometric measures from a shapefile object — shapefile_measures","text":"shapefile sf object representing shapefile. contain polygonal geometries measures calculated. n integer specifying number polygons process. NULL, polygons considered.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_measures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract geometric measures from a shapefile object — shapefile_measures","text":"modified sf object added columns : xcoord: x-coordinate centroid. ycoord: y-coordinate centroid. area: area polygon (square units). perimeter: perimeter polygon (linear units). width: calculated width based sequential distances points. result accurate polygon rectangular. height: calculated height based sequential distances points. result accurate polygon rectangular.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_measures.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract geometric measures from a shapefile object — shapefile_measures","text":"function processes single multi-polygon sf object computes geometric properties. calculates distances points, extracts centroid coordinates, computes area perimeter polygons. width height derived sequential distances points.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_measures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract geometric measures from a shapefile object — shapefile_measures","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman)  path_shp <- paste0(image_pliman(), \"/soy_shape.rds\") shp <- shapefile_input(path_shp) shapefile_measures(shp) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_operations.html","id":null,"dir":"Reference","previous_headings":"","what":"Spatial Operations on Shapefiles — shapefile_operations","title":"Spatial Operations on Shapefiles — shapefile_operations","text":"functions perform various spatial operations two shapefiles, including determining geometries fall within, outside, touch, cross, overlap, intersect another geometry. also include functions geometric operations intersection, difference, union.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_operations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spatial Operations on Shapefiles — shapefile_operations","text":"","code":"shapefile_within(shp1, shp2)  shapefile_outside(shp1, shp2)  shapefile_overlaps(shp1, shp2)  shapefile_touches(shp1, shp2)  shapefile_crosses(shp1, shp2)  shapefile_intersection(shp1, shp2)  shapefile_difference(shp1, shp2)  shapefile_union(shp1, shp2)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_operations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spatial Operations on Shapefiles — shapefile_operations","text":"shp1 sf object representing first shapefile. shp2 sf object representing second shapefile.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_operations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spatial Operations on Shapefiles — shapefile_operations","text":"filtered sf object result geometric operation.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_operations.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Spatial Operations on Shapefiles — shapefile_operations","text":"functions ensure coordinate reference systems (CRS) shapefiles performing operations. CRSs different, shp2 transformed match CRS shp1. shapefile_within(): Filters features shp1 fully within shp2. shapefile_outside(): Filters features shp1 outside overlap shp2. shapefile_overlaps(): Filters features shp1 overlap shp2. shapefile_touches(): Filters features shp1 touch boundary shp2. shapefile_crosses(): Filters features shp1 cross shp2. shapefile_intersection(): Computes geometric intersection shp1 shp2. shapefile_difference(): Computes geometric difference shp1 minus shp2. shapefile_union(): Computes geometric union shp1 shp2.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_operations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spatial Operations on Shapefiles — shapefile_operations","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman)  shp1 <- shapefile_input(paste0(image_pliman(), \"/shp1.rds\")) shp2 <- shapefile_input(paste0(image_pliman(), \"/shp2.rds\")) shapefile_view(shp1) + shapefile_view(shp1)  # Apply operations shapefile_within(shp1, shp2) shapefile_outside(shp1, shp2) shapefile_overlaps(shp1, shp2) shapefile_touches(shp1, shp2) shapefile_crosses(shp1, shp2) shapefile_intersection(shp1, shp2) shapefile_difference(shp1, shp2) shapefile_union(shp1, shp2) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"A wrapper around terra::plot() — shapefile_plot","title":"A wrapper around terra::plot() — shapefile_plot","text":"Plot values SpatVector","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A wrapper around terra::plot() — shapefile_plot","text":"","code":"shapefile_plot(shapefile, ...)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A wrapper around terra::plot() — shapefile_plot","text":"shapefile SpatVector sf object. ... arguments passed terra::plot().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A wrapper around terra::plot() — shapefile_plot","text":"NULL object","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A wrapper around terra::plot() — shapefile_plot","text":"","code":"if(interactive()){ library(pliman) r <- shapefile_input(system.file(\"ex/lux.shp\", package=\"terra\")) shapefile_plot(r) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_surface.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a spatial surface plot based on interpolated values — shapefile_surface","title":"Generate a spatial surface plot based on interpolated values — shapefile_surface","text":"function creates surface plot interpolated spatial model, options customize plot appearance, grid resolution, color palette.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_surface.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a spatial surface plot based on interpolated values — shapefile_surface","text":"","code":"shapefile_surface(   model,   curve = TRUE,   nx = 300,   ny = 300,   xlab = \"Longitude (UTM)\",   ylab = \"Latitude (UTM)\",   col = custom_palette(c(\"darkred\", \"yellow\", \"forestgreen\"), n = 100),   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_surface.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a spatial surface plot based on interpolated values — shapefile_surface","text":"model interpolated spatial object (e.g., shapefile_interpolate()) containing data plotting. curve Logical; TRUE, contour plot generated (type = \"C\"), otherwise image plot (type = \"\"). Default TRUE. nx Integer; number grid cells x-direction. Default 300. ny Integer; number grid cells y-direction. Default 300. xlab Character; label x-axis. Default \"Longitude (UTM)\". ylab Character; label y-axis. Default \"Latitude (UTM)\". col color palette function surface plot. Default custom palette dark red yellow forest green. ... Additional parameters pass fields::surface.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/shapefile_surface.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a spatial surface plot based on interpolated values — shapefile_surface","text":"surface plot showing spatially interpolated data.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/summary_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary an object index — summary_index","title":"Summary an object index — summary_index","text":"one index available, function performs Principal Component Analysis produces plot showing contribution indexes PC1 (see pca()). index declared index cut point cut_point, number proportion objects mean value index bellow cut_point returned. Additionaly, number proportion pixels bellow cutpoint shown object (id).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/summary_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary an object index — summary_index","text":"","code":"summary_index(   object,   index = NULL,   cut_point = NULL,   select_higher = FALSE,   plot = TRUE,   type = \"var\",   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/summary_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary an object index — summary_index","text":"object object computed analyze_objects(). index index desired, e.g., \"B\". Note value must match index(es) used argument object_index analyze_objects(). cut_point cut point. select_higher FALSE (default) selects objects index smaller cut_point. Use select_higher = TRUE select objects index higher cut_point. plot Shows contribution plot one index available? Defaults TRUE. type type plot produce. Defaults \"var\". See get_biplot(). ... arguments passed get_biplot().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/summary_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary an object index — summary_index","text":"list following elements: ids identification selected objects. between_id data frame following columns n number objects. nsel number selected objects. prop proportion objects selected. mean_index_sel, mean_index_nsel mean value index selected non-selected objects, respectively. within_id data frame following columns id object identification n_less number pixels values lesser equal cut_point. n_greater number pixels values greater cut_point. less_ratio proportion pixels values lesser equal cut_point. greater_ratio proportion pixels values greater cut_point. pca_res object computed pca()","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/summary_index.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary an object index — summary_index","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/summary_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary an object index — summary_index","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) soy <- image_pliman(\"soy_green.jpg\") anal <- analyze_objects(soy, object_index = \"G\", pixel_level_index = TRUE) plot_measures(anal, measure = \"G\")  summary_index(anal, index = \"G\", cut_point = 0.5) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_colorspace.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert between colour spaces — utils_colorspace","title":"Convert between colour spaces — utils_colorspace","text":"rgb_to_srgb() Transforms colors RGB space (red/green/blue) Standard Red Green Blue (sRGB), using gamma correction 2.2. function performs conversion applying gamma correction input RGB values (raising power 2.2) transforming using specific transformation matrix. result clamped range 0-1 ensure valid sRGB values. rgb_to_hsb() Transforms colors RGB space (red/green/blue) HSB space (hue/saturation/brightness). HSB values calculated follows (see https://www.rapidtables.com/convert/color/rgb--hsv.html details). Hue: hue determined based maximum value among R, G, B, ranges 0 360 degrees. Saturation: Saturation calculated difference maximum minimum channel values, expressed percentage. Brightness: Brightness equal maximum channel value, expressed percentage. rgb_to_lab() Transforms colors RGB space (red/green/blue) CIE-LAB space, using sRGB values. See grDevices::convertColor() details.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_colorspace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert between colour spaces — utils_colorspace","text":"","code":"rgb_to_hsb(object)  rgb_to_srgb(object)  rgb_to_lab(object)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_colorspace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert between colour spaces — utils_colorspace","text":"object Image object, object computed analyze_objects() valid object_index argument, data.frame/matrix. last, three-column data (R, G, B, respectively) required.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_colorspace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert between colour spaces — utils_colorspace","text":"data frame columns converted color space","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_colorspace.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Convert between colour spaces — utils_colorspace","text":"See detailed formulas ","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_colorspace.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert between colour spaces — utils_colorspace","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_colorspace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert between colour spaces — utils_colorspace","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"sev_leaf.jpg\") rgb_to_lab(img)  # analyze the object and convert the pixels anal <- analyze_objects(img, object_index = \"B\", pixel_level_index = TRUE) rgb_to_lab(anal) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_dpi.html","id":null,"dir":"Reference","previous_headings":"","what":"Utilities for image resolution — utils_dpi","title":"Utilities for image resolution — utils_dpi","text":"Provides useful conversions size (cm), number pixels (px) dots per inch (dpi). dpi_to_cm() converts known dpi value centimeters. cm_to_dpi() converts known centimeter values dpi. pixels_to_cm() converts number pixels centimeters, given known resolution (dpi). cm_to_pixels() converts distance (cm) number pixels, given known resolution (dpi). distance() Computes distance two points image based Pythagorean theorem. dpi() interactive function compute image resolution given known distance informed user. See information Details section. npixels() returns number pixels image.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_dpi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utilities for image resolution — utils_dpi","text":"","code":"dpi_to_cm(dpi)  cm_to_dpi(cm)  pixels_to_cm(px, dpi)  cm_to_pixels(cm, dpi)  npixels(img)  dpi(img, viewer = get_pliman_viewer(), downsample = NULL, max_pixels = 1e+06)  distance(   img,   viewer = get_pliman_viewer(),   downsample = NULL,   max_pixels = 1e+06 )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_dpi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utilities for image resolution — utils_dpi","text":"dpi image resolution dots per inch. cm size centimeters. px number pixels. img image object. viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. downsample integer; dimension number pixels/lines/bands etc skipped; Defaults NULL, find best downsampling factor approximate max_pixels value. max_pixels integer > 0. Maximum number cells use plot. max_pixels < npixels(img), regular sampling used plotting.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_dpi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utilities for image resolution — utils_dpi","text":"dpi_to_cm(), cm_to_dpi(), pixels_to_cm(), cm_to_pixels() return numeric value vector numeric values input data vector. dpi() returns computed dpi (dots per inch) given known distance informed plot.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_dpi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Utilities for image resolution — utils_dpi","text":"dpi() run interactive section. compute image resolution (dpi) user must use left button mouse create line known distance. can done, example, using template known distance image (e.g., la_leaves.jpg).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_dpi.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Utilities for image resolution — utils_dpi","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_dpi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utilities for image resolution — utils_dpi","text":"","code":"library(pliman) # Convert  dots per inch to centimeter dpi_to_cm(c(1, 2, 3)) #> [1] 2.5400000 1.2700000 0.8466667  # Convert centimeters to dots per inch cm_to_dpi(c(1, 2, 3)) #> [1] 0.3937008 0.7874016 1.1811024  # Convert centimeters to number of pixels with resolution of 96 dpi. cm_to_pixels(c(1, 2, 3), 96) #> [1]  37.79528  75.59055 113.38583  # Convert number of pixels to cm with resolution of 96 dpi. pixels_to_cm(c(1, 2, 3), 96) #> [1] 0.02645833 0.05291667 0.07937500  if(isTRUE(interactive())){ #### compute the dpi (dots per inch) resolution #### # only works in an interactive section # objects_300dpi.jpg has a known resolution of 300 dpi img <- image_pliman(\"objects_300dpi.jpg\") # Higher square: 10 x 10 cm # 1) Run the function dpi() # 2) Use the left mouse button to create a line in the higher square # 3) Declare a known distance (10 cm) # 4) See the computed dpi dpi(img)   img2 <- image_pliman(\"la_leaves.jpg\") # square leaf sample (2 x 2 cm) dpi(img2) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Utilities for file manipulation — utils_file","title":"Utilities for file manipulation — utils_file","text":"file_extension() Get extension file. file_name() Get name file. file_dir() Get directory file manipulate_files() Manipulate files directory options rename (insert prefix suffix) save new files provided directory. pliman_indexes() Get indexes available pliman. pliman_indexes_eq() Get equation indexes available pliman.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utilities for file manipulation — utils_file","text":"","code":"file_extension(file)  file_name(file)  file_dir(file)  manipulate_files(   pattern,   dir = NULL,   prefix = NULL,   name = NULL,   suffix = NULL,   extension = NULL,   sep = \"\",   save_to = NULL,   overwrite = FALSE,   remove_original = FALSE,   verbose = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utilities for file manipulation — utils_file","text":"file file name. pattern file name pattern. dir working directory containing files manipulated. Defaults current working directory. prefix, suffix prefix suffix added new file names. Defaults NULL (prefix suffix). name name new files. Defaults NULL (original names). name can either single value character vector length number files manipulated. one value informed, sequential vector names created \"name_1\", \"name_2\", . extension new extension file. declared (default), original extensions used. sep optional separator. Defaults \"\". save_to directory save new files. Defaults current working directory. file name file changed, nothing occur. save_to refers subfolder current working directory, files saved given folder. case folder exist, created. default, files overwritten. Set overwrite = TRUE overwrite files. overwrite Overwrite files? Defaults FALSE. remove_original Remove original files manipulation? defaults FALSE. TRUE files pattern removed. verbose FALSE, code run silently.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utilities for file manipulation — utils_file","text":"file_extension(),  file_name(), file_dir() return character string. manipulate_files() return value. verbose == TRUE, message printed indicating operation succeeded () files attempted.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_file.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utilities for file manipulation — utils_file","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) # get file name, directory and extension file <- \"E:/my_folder/my_subfolder/image1.png\" file_dir(file) file_name(file) file_extension(file)  # manipulate files dir <- tempdir() list.files(dir) file.create(paste0(dir, \"/test.txt\")) list.files(dir) manipulate_files(\"test\",                  dir = paste0(dir, \"\\\\\"),                 prefix = \"chang_\",                 save_to = paste0(dir, \"\\\\\"),                 overwrite = TRUE) list.files(dir) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_image.html","id":null,"dir":"Reference","previous_headings":"","what":"Import and export images — utils_image","title":"Import and export images — utils_image","text":"Import images files URLs write images files, possibly batch processing.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_image.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import and export images — utils_image","text":"","code":"image_import(   img,   ...,   which = 1,   pattern = NULL,   path = NULL,   resize = FALSE,   plot = FALSE,   nrow = NULL,   ncol = NULL )  image_export(img, name, prefix = \"\", extension = NULL, subfolder = NULL, ...)  image_input(img, ...)  image_pliman(img, plot = FALSE)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_image.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import and export images — utils_image","text":"img image_import(), character vector file names URLs. image_input(), character vector file names URLs array containing pixel intensities image. image_export(), Image object, array list images. image_pliman(), charactere value specifying image example. See ?pliman_images details. ... image_import() alternative arguments passed corresponding functions jpeg, png, tiff packages. image_input() arguments passed EBImage::Image(). logical scalar integer vector indicate image imported TIFF files informed. Defaults 1 (first image returned). pattern pattern file name used identify images imported. example, pattern = \"im\" images current working directory name matches pattern (e.g., img1.-, image1.-, im2.-) imported list. Providing number pattern (e.g., pattern = \"1\") select images named 1.-, 2.-, . error returned pattern matches file supported (e.g., img1.pdf). path character vector full path names; default corresponds working directory, getwd(). overwrite (given) path informed image argument. resize Resize image importation? Defaults FALSE. Use numeric value range 0-100 (proportion size original image). plot Plots image importing? Defaults FALSE. nrow, ncol Passed image_combine(). number rows columns use composite image plot = TRUE. name string specifying name image. can either character image name (e.g., \"img1\") name extension (e.g., \"img1.jpg\"). none file extension provided, image saved *.jpg file. prefix prefix include image name exporting list images. Defaults \"\", .e., prefix. extension image list, extension can used define extension exported files. overwrite file extensions given image. subfolder Optional character string indicating subfolder within current working directory save image(s). folder exist, created.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_image.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import and export images — utils_image","text":"image_import() returns new Image object. image_export() returns invisible vector file names. image_pliman() returns new Image object example image required. empty call used, path tmp_images directory installed package returned.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_image.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Import and export images — utils_image","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_image.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import and export images — utils_image","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) folder <- image_pliman() full_path <- paste0(folder, \"/sev_leaf.jpg\") (path <- file_dir(full_path)) (file <- basename(full_path)) image_import(img = full_path) image_import(img = file, path = path) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_indexes.html","id":null,"dir":"Reference","previous_headings":"","what":"Utilities for image indexes — utils_indexes","title":"Utilities for image indexes — utils_indexes","text":"pliman_indexes(): Get available indexes pliman. pliman_indexes_rgb(): Get RGB-based available indexes pliman. pliman_indexes_me(): Get multispectral available indexes pliman. pliman_indexes_hs(): Get hyperspectral available indexes pliman. pliman_indexes_eq(): Get equations available indexes.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_indexes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utilities for image indexes — utils_indexes","text":"","code":"pliman_indexes()  pliman_indexes_eq()  pliman_indexes_rgb()  pliman_indexes_me()  pliman_indexes_hs()"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_measures.html","id":null,"dir":"Reference","previous_headings":"","what":"Utilities for object measures — utils_measures","title":"Utilities for object measures — utils_measures","text":"get_measures() computes object measures (area, perimeter, radius) using either known resolution (dpi) object known measurements. plot_measures() draws object measures given object current plot. object identification (\"id\") drawn default.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_measures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utilities for object measures — utils_measures","text":"","code":"get_measures(   object,   measure = NULL,   id = NULL,   dpi = NULL,   sep = \"\\\\_|-\",   verbose = TRUE,   digits = 5 )  plot_measures(   object,   measure = \"id\",   id = NULL,   hjust = NULL,   vjust = NULL,   digits = 2,   size = 0.9,   col = \"white\",   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_measures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utilities for object measures — utils_measures","text":"object object computed analyze_objects(). measure plot_measures(), character string; get_measures(), two-sided formula, e.g., measure = area ~ 100 indicating known value object id. right-hand side known value left-hand side can one following. area known area object. perimeter known perimeter object. radius_mean known radius object. radius_min known minimum radius object. object square, radius_min object L/2 L length square side. radius_max known maximum radius object. object square, radius_max object according Pythagorean theorem L x sqrt(2) / 2 L length square side. id object image indicate known value. dpi known resolution image DPI (dots per inch). sep Regular expression manage file names. function combines merge object object measures (sum area mean measures) images share filename prefix, defined part filename preceding first hyphen (-) underscore (_) (hyphen underscore required). example, measures images named L1-1.jpeg, L1-2.jpeg, L1-3.jpeg combined single image information (L1). feature allows user treat multiple images belonging single sample, desired. Defaults sep = \"\\\\_|-\". verbose FALSE, runs code silently. digits number significant figures. Defaults 2. hjust, vjust numeric value adjust labels horizontally vertically. Positive values move labels right (hjust) top (vjust). Negative values move labels left bottom, respectively. size size text. Defaults 0.9. col color text. Defaults \"white\". ... arguments passed graphics::text().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_measures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utilities for object measures — utils_measures","text":"get_measures(), measure informed, pixel values corrected value known object, given unit right-hand side meae. dpi informed, measures adjusted knosurwn dpi. applied object class anal_obj, returns data frame object id (corrected) measures. applied object class anal_obj_ls, returns list class measures_ls, two objects: () results, data frame containing identification image (img) object within image (id); (ii) summary data frame containing values image. one object detected given image, number objects (n), total area (area_sum), mean area (area_mean) standard deviation area (area_sd) computed. measures (perimeter radius), mean values presented. plot_measures() returns NULL object, drawing text according x y coordinates objects object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_measures.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Utilities for object measures — utils_measures","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_measures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utilities for object measures — utils_measures","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"objects_300dpi.jpg\") plot(img) # Image with four objects with a known resolution of 300 dpi # Higher square: 10 x 10 cm # Lower square: 5 x 5 cm # Rectangle: 4 x 2 cm # Circle: 3 cm in diameter  # Count the objects using the blue band to segment the image results <-    analyze_objects(img,                  index = \"B\",                  lower_noise = 0.1) plot_measures(results, measure = \"id\")  # Get object measures by declaring the known resolution in dots per inch (measures <- get_measures(results, dpi = 300))  # Calculated diagonal of the object 1 # 10 * sqrt(2) = 14.14  # Observed diagonal of the object 1 measures[1, \"radius_max\"] * 2   # Get object measures by declaring the known area of object 1 get_measures(results,              id = 1,              area ~ 100) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_objects.html","id":null,"dir":"Reference","previous_headings":"","what":"Utilities for working with image objects — utils_objects","title":"Utilities for working with image objects — utils_objects","text":"object_id() get object identification image. object_coord() get object coordinates (optionally) draw bounding rectangle around multiple objects image. object_contour() returns coordinates (x y) contours object image. object_isolate() isolates object image.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_objects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utilities for working with image objects — utils_objects","text":"","code":"object_coord(   img,   id = NULL,   index = \"NB\",   watershed = TRUE,   invert = FALSE,   opening = FALSE,   closing = FALSE,   filter = FALSE,   fill_hull = FALSE,   threshold = \"Otsu\",   edge = 2,   extension = NULL,   tolerance = NULL,   object_size = \"medium\",   parallel = FALSE,   workers = NULL,   plot = TRUE,   verbose = TRUE )  object_contour(   img,   pattern = NULL,   dir_original = NULL,   center = FALSE,   index = \"NB\",   invert = FALSE,   opening = FALSE,   closing = FALSE,   filter = FALSE,   fill_hull = FALSE,   smooth = FALSE,   threshold = \"Otsu\",   watershed = TRUE,   extension = NULL,   tolerance = NULL,   object_size = \"medium\",   parallel = FALSE,   workers = NULL,   plot = TRUE,   verbose = TRUE )  object_isolate(   img,   id = NULL,   parallel = FALSE,   workers = NULL,   verbose = TRUE,   ... )  object_id(img, parallel = FALSE, workers = NULL, verbose = TRUE, ...)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_objects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utilities for working with image objects — utils_objects","text":"img image class Image list Image objects. id object_coord(), vector (scalar) object id compute bounding rectangle. Object ids can obtained object_id(). Set id = \"\" compute coordinates objects image. id = NULL (default) bounding rectangle drawn including objects. object_isolate(), scalar identifies object extracted. index index produce binary image used compute bounding rectangle coordinates. See image_binary() details. watershed TRUE (default) performs watershed-based object detection. detect objects even touching one . FALSE, pixels connected set foreground pixels set unique object. faster able segment touching objects. invert Inverts binary image, desired. Defaults FALSE. opening, closing, filter Morphological operations (brush size) opening performs erosion followed dilation. helps remove small objects preserving shape size larger objects. closing performs dilatation followed erosion. helps fill small holes preserving shape size larger objects. filter performs median filtering binary image. Provide positive integer > 1 indicate size median filtering. Higher values efficient remove noise background can dramatically impact perimeter objects, mainly irregular perimeters leaves serrated edges. Hierarchically, operations performed opening > closing > filter. value declared argument define brush size. fill_hull Fill holes objects? Defaults FALSE. threshold default (threshold = \"Otsu\"), threshold value based Otsu's method used reduce grayscale image binary image. numeric value informed, value used threshold. Inform non-numeric value different \"Otsu\" iteratively chosen threshold based raster plot showing pixel intensity index. edge number pixels edge bounding rectangle. Defaults 2. extension, tolerance, object_size Controls watershed segmentation objects image. See analyze_objects() details. parallel Processes images asynchronously (parallel) separate R sessions running background machine. may speed processing time image list. number sections set 50% available cores. workers positive numeric scalar function specifying maximum number parallel processes can active time. plot Shows image bounding rectangles? Defaults TRUE. verbose TRUE (default) summary shown console. pattern pattern file name used identify images imported. example, pattern = \"im\" images current working directory name matches pattern (e.g., img1.-, image1.-, im2.-) imported list. Providing number pattern (e.g., pattern = \"1\") select images named 1.-, 2.-, . error returned pattern matches file supported (e.g., img1.pdf). dir_original directory containing original images. Defaults NULL, means current working directory considered. center TRUE returns object contours centered origin. smooth whether object contours smoothed poly_smooth(). Defaults FALSE. smooth use numeric value indicating number interactions used smooth contours. ... object_isolate(), arguments passed object_coord(). object_id(), arguments passed analyze_objects().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_objects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utilities for working with image objects — utils_objects","text":"object_id() image class \"Image\" containing object's identification. object_coord() list coordinates bounding rectangles. id = \"\" numeric vector, list vector coordinates returned. object_isolate() image class \"Image\" containing isolated object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_objects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utilities for working with image objects — utils_objects","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"la_leaves.jpg\") # Get the object's (leaves) identification object_id(img)  # Get the coordinates and draw a bounding rectangle around leaves 1 and 3 object_coord(img, id = c(1, 3))  # Isolate leaf 3 isolated <- object_isolate(img, id = 3) plot(isolated)  }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_pca.html","id":null,"dir":"Reference","previous_headings":"","what":"Utilities for Principal Component Axis analysis — utils_pca","title":"Utilities for Principal Component Axis analysis — utils_pca","text":"pca() Computes Principal Component Analysis. wrappers stats::prcomp(), returns results data, scores, contributions quality measurements individuals variables. get_biplot(): Produces biplot object computed pca(). plot.pca(): Produces several types plots, depending type arguments. type = \"var\" Produces barplot contribution (=  \"contrib\"), qualitity adjustment = \"cos2\", scatter plot coordinates (= \"coord\") variables. type = \"ind\" Produces barplot contribution (=  \"contrib\"), qualitity adjustment = \"cos2\", scatter plot coordinates (= \"coord\") individuals. type = \"biplot\" Produces biplot.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_pca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utilities for Principal Component Axis analysis — utils_pca","text":"","code":"pca(x, scale = TRUE)  get_biplot(   x,   axes = c(1, 2),   show = c(\"both\"),   show_ind_id = TRUE,   show_unit_circle = TRUE,   expand = NULL )  # S3 method for class 'pca' plot(x, type = \"var\", which = \"contrib\", axis = 1, ...)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_pca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utilities for Principal Component Axis analysis — utils_pca","text":"x pca(), numeric complex matrix (data frame) provides data principal components analysis. plot.pca() get_biplot(), object computed pca(). scale logical value indicating whether variables scaled unit variance analysis takes place. Defaults TRUE. axes principal component axes plot. Defaults axes = c(1, 2), .e., first second interaction principal component axis. show show biplot. Defaults \"\" (variables individuals). One can also use \"var\", \"ind\". show_ind_id Shows labels individuals? Defaults TRUE. show_unit_circle Shows unit variance circle? Defaults TRUE. expand expansion factor apply plotting second set points relative first. can used tweak scaling two sets physically comparable scale. Setting TRUE automatically compute expansion factor. Alternatively, numeric value can informed. type One \"var\" (plot variables), \"ind\" (plot individuals), \"biplot\" create biplot. measure plot. Either = \"contribution\" (default),  = \"cos2\" (quality representation), = \"coord\" (coordinates) axis axist plot contribution/cos2. Defaults 1. ... arguments passed get_biplot() type = \"biplot\". Otherwise, = \"coord\", arguments passed get_biplot(). = \"contrib\", = \"cos2\" arguments passed graphics::barplot().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_pca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utilities for Principal Component Axis analysis — utils_pca","text":"pca() returns list including: data: raw data used compute PCA. variances: Variances (eigenvalues), proportion explained variance component. center,scale: centering scaling used. ind,var list following objects individuals/variables, respectively. coord: coordinates individuals/variables (loadings * component standard deviations) cos2: cos2 individuals/variables (coord^2) contrib: contribution  (percentage) variable given principal component: (cos2 * 100) / (total cos2 component) plot.pca() returns list coordinates used. get_biplot() returns NULL object","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_pca.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utilities for Principal Component Axis analysis — utils_pca","text":"","code":"library(pliman) pc <- pca(mtcars[1:10 ,1:6]) plot(pc)  plot(pc, type = \"ind\")  plot(pc, type = \"var\", which = \"coord\")   plot(pc, type = \"ind\", which = \"coord\")  plot(pc, type = \"biplot\")"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_pick.html","id":null,"dir":"Reference","previous_headings":"","what":"Utilities for picking up points in an image — utils_pick","title":"Utilities for picking up points in an image — utils_pick","text":"pick_count() opens interactive section user able click image count objects (points) manually. mouse click, point drawn upward counter shown console. n counts user press Esc, interactive process terminated number counts returned. pick_coord() Picks coordinates image pick_palette()  creates image palette picking color point(s) image. pick_rgb() Picks RGB values selected point(s) image.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_pick.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utilities for picking up points in an image — utils_pick","text":"","code":"pick_count(   img,   n = Inf,   col = \"red\",   viewer = get_pliman_viewer(),   external_device = FALSE,   size = 0.8,   plot = TRUE,   verbose = TRUE )  pick_coords(   img,   n = Inf,   col = \"red\",   viewer = get_pliman_viewer(),   external_device = FALSE,   size = 0.8,   verbose = TRUE )  pick_rgb(   img,   n = Inf,   col = \"red\",   viewer = get_pliman_viewer(),   external_device = FALSE,   size = 0.8,   plot = TRUE,   verbose = TRUE )  pick_palette(   img,   n = Inf,   r = 2,   shape = \"box\",   viewer = get_pliman_viewer(),   external_device = FALSE,   show = \"rgb\",   title = \"Pick colors in the image\",   index = \"B\",   random = TRUE,   width = 100,   height = 100,   col = \"red\",   size = 0.8,   plot = TRUE,   palette = TRUE,   verbose = TRUE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_pick.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utilities for picking up points in an image — utils_pick","text":"img Image object. n number points pick_* function. Defaults Inf. means picking run user press Esc. col, size color size marker point. viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. external_device Logical. TRUE (default), opens external graphics window running inside RStudio ensure accurate point selection using locator(). Ignored RStudio using viewer = \"mapview\". plot Call new plot(img) processing? Defaults TRUE. verbose TRUE (default) shows counter console. r radius neighborhood pixels. Defaults 1. shape character vector indicating shape brush around selected pixel.  can \"box\", \"disc\", \"diamond\", \"Gaussian\" \"line\". Defaults \"box\". case, 'r = 1', 8 surrounding pixels sampled. Setting \"disc\" increasing radius (r) select surrounding pixels towards format sphere around selected pixel. show plot mapview viewer, either 'rgb 'index'. title title map view vieweris used. index index use index view. Defaults 'B'. random Randomize selected pixels? Defaults TRUE. width, height width height generated palette. Defaults 100 , .e., square image 100 x 100. palette Plot generated palette? Defaults TRUE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_pick.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utilities for picking up points in an image — utils_pick","text":"pick_count() returns data.frame x y coordinates selected point(x). pick_rgb() returns data.frame R, G, B values selected point(s). pick_palette() returns object class Image.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_pick.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Utilities for picking up points in an image — utils_pick","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_pick.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utilities for picking up points in an image — utils_pick","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"soybean_touch.jpg\")  # start a counting process pick_count(img)  # get rgb from point(s) pick_rgb(img)  # create a palette from point(s) pick_palette(img) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_polygon.html","id":null,"dir":"Reference","previous_headings":"","what":"Utilities for Polygons — utils_polygon","title":"Utilities for Polygons — utils_polygon","text":"Several useful functions analyzing polygons. based set coordinate points describe edge object(s). list polygons provided, loops list computes needed element list. Polygon measures conv_hull() Computes convex hull set points. conv_hull_unified() Computes convex hull set points. Compared conv_hull(), conv_hull_unified() binds (unifies) coordinates x list coordinates. poly_area() Computes area polygon given vertices vectors x y using Shoelace formula, follows (Lee Lim, 2017): $$=\\frac{1}{2}\\left|\\sum_{=1}^{n}\\left(x_{} y_{+1}-x_{+1} y_{}\\right)\\right|$$ x y coordinates form corners polygon, n number coordinates. poly_angles() Calculates internal angles polygon using law cosines. poly_lw() Returns length width polygon based alignment y-axis (poly_align()). length defined range along x-axis, width defined range y-axis. poly_mass() Computes center mass (centroid) polygon given vertices vectors x y using following formulas: $$C_x = \\frac{1}{6A} \\sum_{=1}^{n} (x_i + x_{+1}) (x_i y_{+1} - x_{+1} y_i)$$ $$C_y = \\frac{1}{6A} \\sum_{=1}^{n} (y_i + y_{+1}) (x_i y_{+1} - x_{+1} y_i)$$ C_x C_y coordinates center mass, area polygon computed Shoelace formula, x y coordinates form corners polygon, n number coordinates. poly_solidity() Computes solidity shape ratio shape area convex hull area. Perimeter measures poly_slide() Slides coordinates polygon given vertices vectors x y id-th point becomes first one. poly_distpts() Computes Euclidean distance every point polygon given vertices vectors x y. poly_centdist() Computes Euclidean distance every point perimeter centroid object. poly_centdist_mass() Computes Euclidean distance every point perimeter center mass object. poly_perimeter() Computes perimeter polygon given vertices vectors x y. poly_caliper() Computes caliper (also called Feret's diameter) polygon given vertices vectors x y. Circularity measures (Montero et al. 2009). poly_circularity() computes circularity (C), also called shape compactness roundness measure, object. given C = P^2 / , P perimeter area object. poly_circularity_norm() computes normalized circularity (Cn), unity circle. measure invariant translation, rotation, scaling transformations, dimensionless. given : Cn = P^2 / 4*pi*. poly_circularity_haralick() computes Haralick's circularity (CH). method based computing Euclidean distances object centroid boundary pixel. set distances, mean (m) standard deviation (sd) computed. statistical parameters used calculate circularity, CH, shape CH = m/sd. poly_convexity() computes convexity shape using ratio perimeter convex hull perimeter polygon. poly_eccentricity() computes eccentricity shape using ratio eigenvalues (inertia axes coordinates). poly_elongation() computes elongation shape 1 - width / length. Utilities polygons poly_check() Checks set coordinate points returns matrix x y columns. poly_is_closed() Returns logical value indicating polygon closed. poly_close() poly_unclose() close unclose polygon, respectively. poly_rotate() Rotates polygon coordinates angle (0-360 degrees) counterclockwise direction. poly_flip_x(), poly_flip_y() flip shapes along x-axis y-axis, respectively. poly_align() Aligns coordinates along longer axis using var-cov matrix eigen values. poly_center() Centers coordinates origin. poly_sample() Samples n coordinates existing points. Defaults 50. poly_sample_prop() Samples proportion coordinates existing points. Defaults 0.1. poly_spline() Interpolates polygon contour. poly_smooth() Smooths polygon contour using simple moving average. poly_jitter() Adds small amount noise set point coordinates. See base::jitter() details. poly_measures() wrapper around poly_*() functions.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_polygon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utilities for Polygons — utils_polygon","text":"","code":"poly_check(x)  poly_is_closed(x)  poly_close(x)  poly_unclose(x)  poly_angles(x)  poly_limits(x)  conv_hull(x)  conv_hull_unified(x)  poly_area(x)  poly_slide(x, fp = 1)  poly_distpts(x)  poly_centdist(x)  poly_centdist_mass(x)  poly_perimeter(x)  poly_rotate(x, angle, plot = TRUE)  poly_align(x, plot = TRUE)  poly_center(x, plot = TRUE)  poly_lw(x)  poly_eccentricity(x)  poly_convexity(x)  poly_caliper(x)  poly_elongation(x)  poly_solidity(x)  poly_flip_y(x)  poly_flip_x(x)  poly_sample(x, n = 50)  poly_sample_prop(x, prop = 0.1)  poly_jitter(x, noise_x = 1, noise_y = 1, plot = TRUE)  poly_circularity(x)  poly_circularity_norm(x)  poly_circularity_haralick(x)  poly_mass(x)  poly_spline(x, vertices = 100, k = 2)  poly_smooth(x, niter = 10, n = NULL, prop = NULL, plot = TRUE)  poly_measures(x)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_polygon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utilities for Polygons — utils_polygon","text":"x 2-column matrix x y coordinates. x list vector coordinates, function applied element using base::lapply() base::sapply(). fp ID point become new first point. Defaults 1. angle angle (0-360) rotate object. plot object plotted? Defaults TRUE. n, prop number proportion coordinates sample perimeter coordinates. poly_smooth(), arguments can used sample points object's perimeter smoothing. noise_x, noise_y numeric factor define noise added x y axes, respectively. See base::jitter() details. vertices number spline vertices create. k number points wrap around ends obtain smooth periodic spline. niter integer indicating number smoothing iterations.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_polygon.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utilities for Polygons — utils_polygon","text":"conv_hull() poly_spline() returns matrix x y coordinates convex hull/smooth line clockwise order. x list, list points returned. poly_area() returns double, numeric vector x list vector points. poly_mass() returns data.frame containing coordinates center mass, well maximum minimum distance contour center mass. poly_slides(), poly_distpts(), poly_spline(), poly_close(), poly_unclose(), poly_rotate(), poly_jitter(), poly_sample(), poly_sample_prop(), poly_measures returns data.frame. poly_perimeter(), poly_lw(), poly_eccentricity(), poly_convexity(), poly_caliper(), poly_elongation(), poly_circularity_norm(), poly_circularity_haralick() returns double.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_polygon.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Utilities for Polygons — utils_polygon","text":"Lee, Y., & Lim, W. (2017). Shoelace Formula: Connecting Area Polygon Vector Cross Product. Mathematics Teacher, 110(8), 631–636. doi:10.5951/mathteacher.110.8.0631 Montero, R. S., Bribiesca, E., Santiago, R., & Bribiesca, E. (2009). State Art Compactness Circularity Measures. International Mathematical Forum, 4(27), 1305–1335. Chen, C.H., P.S.P. Wang. 2005. Handbook Pattern Recognition Computer Vision. 3rd ed. World Scientific.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_polygon.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utilities for Polygons — utils_polygon","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) # A 2 x 2 square df <- draw_square(side = 2)  # square area poly_area(df)  # polygon perimeter poly_perimeter(df)  # center of mass of the square cm <- poly_mass(df) plot_mass(cm)  # The convex hull will be the vertices of the square (conv_square <- conv_hull(df) |> poly_close()) plot_contour(conv_square,              col = \"blue\",              lwd = 6) poly_area(conv_square)   ################### Example with a polygon ################## x <- c(0, 1,   2, 3,  5, 2, -1, 0, 0) y <- c(5, 6.5, 7, 3,  1, 1,  0, 2, 5) df_poly <- cbind(x, y)  # area of the polygon plot_polygon(df_poly, fill = \"red\") poly_area(df_poly)  # perimeter of the polygon poly_perimeter(df_poly)  # center of mass of polygon cm <- poly_mass(df_poly) plot_mass(cm,  col = \"blue\")  # vertices of the convex hull (conv_poly <- conv_hull(df_poly))  # area of the convex hull poly_area(conv_poly)  plot_polygon(conv_poly,              fill = \"red\",              alpha = 0.2,              add = TRUE)   ############ example of circularity measures ################ tri <- draw_circle(n = 200, plot = FALSE) plot_polygon(tri, aspect_ratio = 1) poly_circularity_norm(tri)  set.seed(1) tri2 <-   draw_circle(n = 200, plot = FALSE) |>   poly_jitter(noise_x = 100, noise_y = 100, plot = FALSE)  plot_polygon(tri2, aspect_ratio = 1) poly_circularity_norm(tri2) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_polygon_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Utilities for plotting polygons — utils_polygon_plot","title":"Utilities for plotting polygons — utils_polygon_plot","text":"plot_contour() Plot contour lines. plot_polygon() Plots polygon describing objects. plot_mass() Plots center mass along maximum minimum radius. plot_ellipse() Plots ellipse fits major minor axis object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_polygon_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utilities for plotting polygons — utils_polygon_plot","text":"","code":"plot_contour(x, id = NULL, col = \"black\", lwd = 1, ...)  plot_polygon(   x,   fill = \"gray\",   random_fill = TRUE,   points = FALSE,   merge = TRUE,   border = \"black\",   alpha = 1,   add = FALSE,   nrow = NULL,   ncol = NULL,   aspect_ratio = 1,   show_id = TRUE,   xlim = NULL,   ylim = NULL,   ... )  plot_mass(x, id = NULL, col = \"black\", cex = 1, lwd = 1)  plot_ellipse(object, id = NULL, col = \"black\", lwd = 1)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_polygon_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utilities for plotting polygons — utils_polygon_plot","text":"x 2-column matrix x y coordinates. id object identification (numeric) plot contour/ellipse. default (id = NULL), contour plotted objects. col, lwd, cex color, width lines, size point, respectively. ... plot_contour() plot_ellipse() arguments passed graphics::lines(). plot_mass(), arguments passed graphics::points(). plot_polygon(), arguments passed graphics::polygon(). fill, border, alpha color fill polygon, color polygon's border, alpha transparency (1 opaque, 0 transparent). random_fill Fill multiple objects random colors? Defaults TRUE. points Plot points? Defaults FALSE. merge Merge multiple objects single plot? Defaults TRUE. FALSE, single call plot() used objects. Use nrow ncol control number rows columns window. add Add current plot previous one? Defaults FALSE. nrow, ncol number rows columns use composite image. Defaults NULL, .e., square grid produced. aspect_ratio x/y aspect ratio. Defaults 1. set window one data unit y direction equal one data unit x direction. Set aspect_ratio = NULL fit object window size. show_id Shows object id? Defaults TRUE. xlim, ylim numeric vector length 2 (min; max) indicating range x y-axes. object object computed analyze_objects().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_polygon_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utilities for plotting polygons — utils_polygon_plot","text":"NULL object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_polygon_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utilities for plotting polygons — utils_polygon_plot","text":"","code":"plot_polygon(contours) plot_contour(contours[[1]], id = 6, col = \"red\", lwd = 3)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_rows_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Utilities for handling with rows and columns — utils_rows_cols","title":"Utilities for handling with rows and columns — utils_rows_cols","text":"columns_to_rownames(): Move column .data row names. rownames_to_column(): Move row names .data new column. remove_rownames(): Remove row names .data. round_cols() Rounds values numeric variables specified number decimal places (default 2).","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_rows_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utilities for handling with rows and columns — utils_rows_cols","text":"","code":"column_to_rownames(.data, var = \"rowname\")  rownames_to_column(.data, var = \"rowname\")  remove_rownames(.data)  round_cols(.data, digits = 2)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_rows_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utilities for handling with rows and columns — utils_rows_cols","text":".data data frame var Name column use rownames. digits number significant figures. Defaults 2.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_rows_cols.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Utilities for handling with rows and columns — utils_rows_cols","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_rows_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utilities for handling with rows and columns — utils_rows_cols","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) iris2 <- iris |> rownames_to_column() head(iris2) iris2$rowname <- paste0(\"r\", iris2$rowname) iris2 |> column_to_rownames(\"rowname\") |> head() }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_shapefile.html","id":null,"dir":"Reference","previous_headings":"","what":"Import/export shapefiles. — utils_shapefile","title":"Import/export shapefiles. — utils_shapefile","text":"shapefile_input() creates imports shapefile optionally converts sf object. can also cast POLYGON MULTIPOLYGON geometries MULTILINESTRING required. shapefile_export() exports object (sf SpatVector) file. shapefile_view() simple wrapper around mapview() plot shapefile.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_shapefile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import/export shapefiles. — utils_shapefile","text":"","code":"shapefile_input(   shapefile,   info = TRUE,   as_sf = TRUE,   multilinestring = FALSE,   ... )  shapefile_export(shapefile, filename, ...)  shapefile_view(   shapefile,   attribute = NULL,   type = c(\"shape\", \"centroid\"),   color_regions = custom_palette(c(\"red\", \"yellow\", \"forestgreen\")),   ... )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_shapefile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import/export shapefiles. — utils_shapefile","text":"shapefile shapefile_input(), character (filename), object can coerced SpatVector, sf (simple features) object. See terra::vect() details. shapefile_export(), SpatVector sf object exported shapefile. info Logical value indicating whether print information imported shapefile (default TRUE). as_sf Logical value indicating whether convert imported shapefile sf object (default TRUE). multilinestring Logical value indicating whether cast polygon geometries MULTILINESTRING geometries (default FALSE). ... Additional arguments passed terra::vect() (shapefile_input()), terra::writeVector() (shapefile_export()) mapview::mapview() (shapefile_view()). filename path output shapefile. attribute attribute shown color key. must variable present shapefile. type character string specifying whether visualize shapefile \"shape\" \"centroid\". Partial matching allowed. set \"centroid\", function convert shapefile's geometry centroids displaying. Defaults \"shape\". color_regions color palette represent attribute.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_shapefile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import/export shapefiles. — utils_shapefile","text":"shapefile_input() returns object class sf (default) representing imported shapefile. shapefile_export() returns NULL object. shapefile_view() returns object class mapview.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_shapefile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import/export shapefiles. — utils_shapefile","text":"","code":"if(interactive()){ library(pliman) shp <- system.file(\"ex/lux.shp\", package=\"terra\") shp_file <- shapefile_input(shp, as_sf = FALSE) shapefile_view(shp_file) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_shapes.html","id":null,"dir":"Reference","previous_headings":"","what":"Utilities for drawing coordinates of known shapes — utils_shapes","title":"Utilities for drawing coordinates of known shapes — utils_shapes","text":"functions computes coordinates common shapes squares triangles, rectangles circles. draw_circle() Draws perfect circle desired radius. draw_square() Draws square desired side. draw_rectangle() Draws rectangle given two desired sides. draw_trian_equi() Draws equilateral triangle desired side. draw_trian_rect() Draws triangle rectangle given two cathetus. draw_n_tagon() Draws polygons n sides","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_shapes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utilities for drawing coordinates of known shapes — utils_shapes","text":"","code":"draw_circle(radius = 1, n = 1000, plot = TRUE)  draw_square(side = 2, plot = TRUE)  draw_rectangle(side1 = 2, side2 = 3, plot = TRUE)  draw_trian_equi(side = 2, plot = TRUE)  draw_trian_rect(cat1 = 1, cat2 = 2, plot = TRUE)  draw_n_tagon(n, plot = TRUE)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_shapes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utilities for drawing coordinates of known shapes — utils_shapes","text":"radius radius circle. Defaults 1. n number sides n-tagon. plot Plots result? Defaults TRUE. side side square/equilateral triangle. Defaults 2. side1, side2 first second sides rectangle. Defaults 2 3, respectively. cat1, cat2 first second cathetus right triangle. Defaults 1, 2, respectively.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_shapes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utilities for drawing coordinates of known shapes — utils_shapes","text":"data frame x y coordinates","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_shapes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utilities for drawing coordinates of known shapes — utils_shapes","text":"","code":"########## An example of a circle ########## library(pliman) radius <- 3 circ <- draw_circle(radius = radius)   # area pi * radius ^ 2 #> [1] 28.27433 poly_area(circ) #> [1] 28.27415  # perimeter 2 * pi * radius #> [1] 18.84956 poly_perimeter(circ) #> [1] 18.84952  ############ An example of a square ############ side <- 2 (square <- draw_square(side = side))  #>   x y #> 2 0 2 #> 3 2 2 #> 4 2 0 #> 5 0 0  # area side ^ 2 #> [1] 4 poly_area(square) #> [1] 4  # perimeter side * 4 #> [1] 8 poly_perimeter(square) #> [1] 6  ############ An example of a rectangle ############ side1 <- 2 side2 <- 3 (rect <- draw_rectangle())  #>   x y #> 2 0 2 #> 3 3 2 #> 4 3 0 #> 5 0 0  # area poly_area(rect) #> [1] 6  # perimeter poly_perimeter(rect) #> [1] 8 ###########  An example of an equilateral triangle ######### side <- 1 # defaults (trig <- draw_trian_equi(side = side))  #>     x         y #> 2 1.0 0.0000000 #> 3 0.5 0.8660254 #> 4 0.0 0.0000000  ### area (b*h / 2) # height of the triangle (h <- (side * sqrt(3)) / 2) #> [1] 0.8660254 side * h / 2 #> [1] 0.4330127  poly_area(trig) #> [1] 0.4330127  ### perimeter (side * 3) poly_perimeter(trig) #> [1] 2  ########### An example of a rectangle triangle ########## cat1 <- 2 cat2 <- 3 (df <- draw_trian_rect(cat1, cat2))  #>      x y #> [1,] 0 0 #> [2,] 3 0 #> [3,] 0 2 #> [4,] 0 0 # area (cat1 * cat2) / 2 #> [1] 3 poly_area(df) #> [1] 3  # perimeter cat1 + cat2 + sqrt(cat1^2 + cat2^2) #> [1] 8.605551 poly_perimeter(df) #> [1] 8.605551 ############ An creating shapes with n sides ############ side <- 2 (square <- draw_square(side = side))  #>   x y #> 2 0 2 #> 3 2 2 #> 4 2 0 #> 5 0 0  # area side ^ 2 #> [1] 4 poly_area(square) #> [1] 4  # perimeter side * 4 #> [1] 8 poly_perimeter(square) #> [1] 6"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"These functions applies common statistics to a list of objects, returning a numeric vector. — utils_stats","title":"These functions applies common statistics to a list of objects, returning a numeric vector. — utils_stats","text":"functions applies common statistics list objects, returning numeric vector.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"These functions applies common statistics to a list of objects, returning a numeric vector. — utils_stats","text":"","code":"mean_list(x, ...)  sd_list(x, ...)  max_list(x, ...)  min_list(x, ...)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"These functions applies common statistics to a list of objects, returning a numeric vector. — utils_stats","text":"x data.frame matrix numeric values. ... arguments passed R base function (e.g, mean(), sd(), etc.)","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"These functions applies common statistics to a list of objects, returning a numeric vector. — utils_stats","text":"numeric vector.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"These functions applies common statistics to a list of objects, returning a numeric vector. — utils_stats","text":"","code":"mean_list(list(a = 1:10, b = 2:20)) #>    a    b  #>  5.5 11.0"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_transform.html","id":null,"dir":"Reference","previous_headings":"","what":"Spatial transformations — utils_transform","title":"Spatial transformations — utils_transform","text":"Performs image rotation reflection image autocrop() Crops automatically  image area objects. image_crop() Crops image desired area. image_trim() Remove pixels edges image (20 default). image_dimension() Gives dimension (width height) image. image_rotate() Rotates image clockwise given angle. image_horizontal() Converts (needed) image horizontal image. image_vertical() Converts (needed) image vertical image. image_hreflect() Performs horizontal reflection image. image_vreflect() Performs vertical reflection image. image_resize() Resize image. See EBImage::resize(). image_contrast() Improve contrast locally performing adaptive histogram equalization. See EBImage::clahe(). image_dilate() Performs image dilatation. See EBImage::dilate(). image_erode() Performs image erosion. See EBImage::erode(). image_opening() Performs erosion followed dilation. See EBImage::opening(). image_closing() Performs dilation followed erosion. See EBImage::closing(). image_filter() Performs median filtering constant time. See EBImage::medianFilter(). image_blur() Performs blurring filter images. See EBImage::gblur(). image_skeleton() Performs image skeletonization.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_transform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spatial transformations — utils_transform","text":"","code":"image_autocrop(   img,   index = \"NB\",   edge = 5,   opening = 5,   closing = FALSE,   filter = FALSE,   invert = FALSE,   threshold = \"Otsu\",   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE )  image_crop(   img,   width = NULL,   height = NULL,   viewer = get_pliman_viewer(),   downsample = NULL,   max_pixels = 1e+06,   show = \"rgb\",   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE )  image_dimension(img, parallel = FALSE, workers = NULL, verbose = TRUE)  image_rotate(   img,   angle,   bg_col = \"white\",   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = TRUE )  image_horizontal(   img,   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE )  image_vertical(   img,   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE )  image_hreflect(   img,   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE )  image_vreflect(   img,   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE )  image_resize(   img,   rel_size = 100,   width,   height,   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE )  image_trim(   img,   edge = NULL,   top = NULL,   bottom = NULL,   left = NULL,   right = NULL,   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE )  image_dilate(   img,   kern = NULL,   size = NULL,   shape = \"disc\",   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE )  image_erode(   img,   kern = NULL,   size = NULL,   shape = \"disc\",   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE )  image_opening(   img,   kern = NULL,   size = NULL,   shape = \"disc\",   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE )  image_closing(   img,   kern = NULL,   size = NULL,   shape = \"disc\",   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE )  image_skeleton(   img,   kern = NULL,   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE,   ... )  image_thinning(   img,   niter = 3,   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE,   ... )  image_filter(   img,   size = 2,   cache = 512,   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE )  image_blur(   img,   sigma = 3,   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE )  image_contrast(   img,   parallel = FALSE,   workers = NULL,   verbose = TRUE,   plot = FALSE )"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_transform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spatial transformations — utils_transform","text":"img image list images class Image. index index segment image. See image_index() details. Defaults \"NB\" (normalized blue). edge image_autocrop() number pixels edge cropped image. edge = 0 image cropped create bounding rectangle (x y coordinates) around image objects. image_trim(), number pixels removed edges. default, 20 pixels removed edges. opening, closing, filter Morphological operations (brush size) opening performs erosion followed dilation. helps remove small objects preserving shape size larger objects. closing performs dilatation followed erosion. helps fill small holes preserving shape size larger objects. filter performs median filtering binary image. Provide positive integer > 1 indicate size median filtering. Higher values efficient remove noise background can dramatically impact perimeter objects, mainly irregular perimeters leaves serrated edges. Hierarchically, operations performed opening > closing > filter. value declared argument define brush size. invert Inverts binary image desired. useful process images black background. Defaults FALSE. reference = TRUE use, invert can declared logical vector length 2 (eg., invert = c(FALSE, TRUE). case, segmentation objects reference foreground using back_fore_index performed using default (inverted), segmentation objects reference performed inverting selection (selecting pixels higher threshold). threshold theshold method used. default (threshold = \"Otsu\"), threshold value based Otsu's method used reduce grayscale image binary image. numeric value informed, value used threshold. threshold = \"adaptive\", adaptive thresholding (Shafait et al. 2008) used, depend k windowsize arguments. non-numeric value different \"Otsu\" \"adaptive\" used, iterative section allow choose threshold based raster plot showing pixel intensity index. parallel Processes images asynchronously (parallel) separate R sessions running background machine. may speed processing time image list. number sections set 70% available cores. workers positive numeric scalar function specifying maximum number parallel processes can active time. verbose TRUE (default) summary shown console. plot TRUE plots modified image. Defaults FALSE. width, height image_resize() Width height resized image. arguments can missing. case, image resized according relative size informed rel_size. image_crop() numeric vector indicating pixel range (x y, respectively) maintained cropped image, e.g., width = 100:200 viewer viewer option. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options \"base\" \"mapview\". set \"base\", base R graphics system used interactive plotting. set \"mapview\", mapview package used. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option \"mapview\" functions. downsample integer; dimension number pixels/lines/bands etc skipped; Defaults NULL, find best downsampling factor approximate max_pixels value. max_pixels integer > 0. Maximum number cells use plot. max_pixels < npixels(img), regular sampling used plotting. show plot mapview viewer, either \"rgb\" \"index\". angle rotation angle degrees. bg_col Color used fill background pixels, defaults \"white\". rel_size relative size resized image. Defaults 100. example, setting rel_size = 50 image width 1280 x 720, new image size 640 x 360. top, bottom, left, right number pixels removed top, bottom, left, right using image_trim(). kern Image object array, containing structuring element. Defaults brushe generated EBImage::makeBrush(). size image_filter() median filter radius (integer). Defaults 3. image_dilate() image_erode() odd number containing size brush pixels. Even numbers rounded next odd one. default depends image resolution computed image resolution (megapixels) times 20. shape character vector indicating shape brush. Can box, disc, diamond, Gaussian line. Default disc. ... Additional arguments passed image_binary(). niter number iterations perform thinning procedure. Defaults 3. Set NULL iterate binary image longer changing. cache L2 cache size system CPU kB (integer). Defaults 512. sigma numeric denoting standard deviation Gaussian filter used blurring. Defaults 3.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_transform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spatial transformations — utils_transform","text":"image_skeleton() returns binary Image object. functions returns  modified version image depending image_*() function used. image list, list length returned.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_transform.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Spatial transformations — utils_transform","text":"Tiago Olivoto tiagoolivoto@gmail.com","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_transform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spatial transformations — utils_transform","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"sev_leaf.jpg\") plot(img) img <- image_resize(img, 50) img1 <- image_rotate(img, 45) img2 <- image_hreflect(img) img3 <- image_vreflect(img) img4 <- image_vertical(img) image_combine(img1, img2, img3, img4) }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_wd.html","id":null,"dir":"Reference","previous_headings":"","what":"Set and get the Working Directory quicky — utils_wd","title":"Set and get the Working Directory quicky — utils_wd","text":"get_wd_here() gets working directory path current script. set_wd_here() sets working directory path current script. open_wd_here() Open File Explorer directory path current script. open_wd() Open File Explorer current working directory.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_wd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set and get the Working Directory quicky — utils_wd","text":"","code":"set_wd_here(path = NULL)  get_wd_here(path = NULL)  open_wd_here(path = get_wd_here())  open_wd(path = getwd())"},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_wd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set and get the Working Directory quicky — utils_wd","text":"path Path components project root. Defaults NULL. means directory set path file. path exist, user asked wants create folder.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_wd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set and get the Working Directory quicky — utils_wd","text":"get_wd_here() returns full-path directory name. get_wd_here() returns message showing current working directory. open_wd_here() Opens File Explorer path returned get_wd_here().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/utils_wd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set and get the Working Directory quicky — utils_wd","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { get_wd_here() set_wd_here() open_wd_here() }"},{"path":"https://nepem-ufsc.github.io/pliman/reference/uuid.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Version 7 UUIDs or Random UUIDs — uuid","title":"Generate Version 7 UUIDs or Random UUIDs — uuid","text":"function generates one UUIDs (Universally Unique Identifiers). default, generates Version 7 UUIDs, time-ordered suitable use cases requiring efficient indexing sorting creation time. Alternatively, random Version 4 UUIDs can generated setting usetime = FALSE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/uuid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Version 7 UUIDs or Random UUIDs — uuid","text":"","code":"uuid(n = 1, uppercase = FALSE, usetime = FALSE)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/uuid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Version 7 UUIDs or Random UUIDs — uuid","text":"n Integer. Number UUIDs generate. Default 1. uppercase Logical. TRUE, generated UUIDs returned uppercase letters. Default FALSE. usetime Logical. TRUE, generates Version 7 UUIDs using current timestamp. FALSE, generates random Version 4 UUIDs. Default FALSE.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/uuid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Version 7 UUIDs or Random UUIDs — uuid","text":"character vector UUIDs length n.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/uuid.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Version 7 UUIDs or Random UUIDs — uuid","text":"Version 7 UUIDs: time-ordered UUIDs based current timestamp milliseconds since Unix epoch (1970-01-01 00:00:00 UTC). ideal scenarios requiring chronological sorting indexing. Version 4 UUIDs: randomly generated UUIDs depend time, ensuring uniqueness random hexadecimal values.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/uuid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Version 7 UUIDs or Random UUIDs — uuid","text":"","code":"library(pliman) # Generate a single UUID uuid() #> [1] \"af3a0b88-c9ae-435e-b1e9-ed1991423dd1\"  # Generate 5 UUIDs in uppercase uuid(n = 3, uppercase = TRUE) #> [1] \"4452077D-57DF-421E-ABFB-A769479E4F23\" #> [2] \"0C8C16C2-E972-40E0-8F99-A419A7134DBB\" #> [3] \"6C3332DE-454F-42BD-9B38-D45E66954B7A\"  # Generate two random UUIDs uuid(n = 2, usetime = FALSE) #> [1] \"ffa19a71-5504-4e4b-b58c-eb0083f17f6d\" #> [2] \"f6fa9654-985d-4c7d-a2b9-f9ba19663bcb\""},{"path":"https://nepem-ufsc.github.io/pliman/reference/watershed2.html","id":null,"dir":"Reference","previous_headings":"","what":"Alternative watershed algorithm — watershed2","title":"Alternative watershed algorithm — watershed2","text":"basic watershed algorithm can used faster alternative EBImage::watershed(). strongly suggest using round objects, since consider 'extension' 'tolerance' arguments EBImage::watershed().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/watershed2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Alternative watershed algorithm — watershed2","text":"","code":"watershed2(binary, dist_thresh = 0.75, plot = TRUE)"},{"path":"https://nepem-ufsc.github.io/pliman/reference/watershed2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Alternative watershed algorithm — watershed2","text":"binary binary image dist_thresh distance threshold create plot TRUE (default) plots labeled objects","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/watershed2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Alternative watershed algorithm — watershed2","text":"labelled version binary.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/reference/watershed2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Alternative watershed algorithm — watershed2","text":"","code":"if (interactive() && requireNamespace(\"EBImage\")) { library(pliman) img <- image_pliman(\"soybean_touch.jpg\") binary <- image_binary(img, \"B\")[[1]] wts <- watershed2(binary) range(wts) }"},{"path":[]},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"pliman-310","dir":"Changelog","previous_headings":"","what":"pliman 3.1.0","title":"pliman 3.1.0","text":"CRAN release: 2025-08-19","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"new-functions-3-1-0","dir":"Changelog","previous_headings":"","what":"New Functions","title":"pliman 3.1.0","text":"New functions geometric operation shapefiles. New mosaic_classify() function classify orthomosaics based break values defined users. New new image_contour_line() function allows users detect smooth contour lines image. New image_canny_edge() function, implements Canny Edge detection. New image_line_segment() function enables automatic line segment detection using Line Segment Detector (LSD) algorithm.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"minor-improvements-3-1-0","dir":"Changelog","previous_headings":"","what":"Minor Improvements","title":"pliman 3.1.0","text":"Include option draw circles shapefile_build() Remove dependency lwgeom package compute perimeter. mosaic_crop() now type argument, allows returning cropped masked raster. image_autocrop() now threshold invert arguments. Removed dependencies future, foreach doFuture favour new mirai background engine. simplifies installation delivers faster, reliable parallel processing across image-based functions. Added cli-based messages (rules, progress steps alerts) throughout parallel sequential workflows provide clear, informative status updates long-running image processing tasks.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"pliman-300","dir":"Changelog","previous_headings":"","what":"pliman 3.0.0","title":"pliman 3.0.0","text":"CRAN release: 2024-11-06","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"new-functions-3-0-0","dir":"Changelog","previous_headings":"","what":"New Functions","title":"pliman 3.0.0","text":"Added image_label() label binary images options control max_gap, ie., maximum allowable gap (pixels) connected components considered part object. # pliman 3.0.0 Introduced mosaic_*() family functions high-throughput phenotyping, enabling efficient analysis large-scale image data. Added shapefile_*() functions handling manipulating shapefiles, providing streamlined spatial data management.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"minor-improvements-3-0-0","dir":"Changelog","previous_headings":"","what":"Minor Improvements","title":"pliman 3.0.0","text":"Fixed documentation bug related missing references. Additional performance enhancements minor bug fixes.","code":""},{"path":[]},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"new-functions-2-2-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"pliman 2.2.0","text":"mosaic_analyze() analyze orthomosaics.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"minor-improvements-2-2-0","dir":"Changelog","previous_headings":"","what":"Minor improvements","title":"pliman 2.2.0","text":"Imports poorman package data manipulation. # pliman 2.1.0 ## New functions new mosaic_*() family functions handle orthomosaics RGB multispectral images. object_export() object_export_shp() export objects single images multiple images. image_augment() augment image rotating multiple times.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"bug-fixes-2-2-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"pliman 2.2.0","text":"Setting save_image = TRUE measure_disease_byl() now exports processed images local directory, allowing use sad() call created object.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"minor-improvements-2-2-0-1","dir":"Changelog","previous_headings":"","what":"Minor improvements","title":"pliman 2.2.0","text":"Arguments r, g, b, re, nir now included analyze_objects(), analyze_objects_shp(), image_view(), allowing correctly choose image band. image_segment_mask() now col_background argument. Argument width_at included analyze_objects().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"pliman-201","dir":"Changelog","previous_headings":"","what":"pliman 2.0.1","title":"pliman 2.0.1","text":"CRAN release: 2023-09-11","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"new-functions-2-0-1","dir":"Changelog","previous_headings":"","what":"New functions","title":"pliman 2.0.1","text":"object_export_shp() object_export() export objects image multiple images current working directory. plot_index_shp() plot rectangles top RGB image, rectangle colored based quantitative variable.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"bug-fixes-2-0-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"pliman 2.0.1","text":"Fix bug poly_center() calling column position instead column name (X1)","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"pliman-200","dir":"Changelog","previous_headings":"","what":"pliman 2.0.0","title":"pliman 2.0.0","text":"CRAN release: 2023-07-15","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"new-functions-2-0-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"pliman 2.0.0","text":"analyze_objects_iter() execute interactive section analyze_objects(). measure_disease_byl() measure disease severity ‘leaf’ image several leaves. object_split() split multiples objects image list images. pca(), plot.pca(), get_biplot() helper functions perform Principal Component Analysis. rownames_to_column(), column_to_rownames(), separate_col(), round_cols() helper functions manipulate data. set poly_*() function analyze polygons. based set coordinate points describing edge object(s). See ?utils_polygon details. get_wd_here() set_wd_here() deal working directories. apply_fun_to_imgs() apply function (functions) set images stored working directory. make_brush(), make_mask(), image_segment_mask() create masks segment images based mask. image_segment_manual(), image segment kmeans(), image_segment_mask() perform image segmentation different ways. new family efourier_*() functions performs Elliptical Fourier Analysis. efourier(): Elliptical Fourier Analysis efourier_coefs(): Get Fourier coefficients efourier_error(): Erros original reconstructed outline efourier_inv(): Inverse Elliptical Fourier Analysis efourier_norm(): Normalized Fourier coefficients efourier_power(): Power Fourier Analysis efourier_shape(): Draw shapes based Fourier coefficients new family landmarks_*() functions handle landmarks landmarks(): Create image landmarks landmarks_add(): Artificially inflates number landmarks landmarks_angle(): Angles landmarks landmarks_dist(): Distances landmarks landmarks_regradi(): Pseudolandmarks equally spaced angles object_edge() detect edges images using Sobel-Feldman Operator. new family *_shp() functions analyze shape files. image_shp() construct shape file image. object_split_shp() splits image objects based shapefile. analyze_objects_shp() analyze objects using shapefiles. measure_disease_shp() measure disease using shapefiles. New plot_index() function plot image index using raster package, optionaly using mapview package show image index. New image_view() function create interactive map view image. function allows users interactively edit analyze image using mapview mapedit packages. New image_prepare_mv() function prepare image analyzed analyze_objects_shp(). function aligns crops image using either base mapview visualization.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"new-features-2-0-0","dir":"Changelog","previous_headings":"","what":"New features","title":"pliman 2.0.0","text":"New viewer option added. Now, iterative functions pick_palette() measure_disease_iter() argument viewer. provided, value retrieved using get_pliman_viewer(). option controls type viewer use interactive plotting. available options “base” “mapview”. set “base”, base R graphics system used interactive plotting. set “mapview”, mapview package used, allowing users draw shapes like points polygons mapedit package. set argument globally functions package, can use set_pliman_viewer() function. example, can run set_pliman_viewer(\"mapview\") set viewer option “mapview” functions. Haralick’s features quantify pixel texture image objects included. Several measures added analyze_objects(). function now wraps poly_*() functions compute shape measures width, length, elongation, circularity. Haralick’s features now computed default. . improvement cost slight increase computation time. analyze_objects(), measure_disease(), measure_disease_byl() now filter argument applies median filtering binary mask. useful reduce noise segmentation objects. Arguments reference_larger reference_smaller included analyze_objects() indicating larger/smaller object image must used reference object. Arguments efourier nharm included analyze_objects(). efourier = TRUE, Elliptical Fourier analysis computed object depending number harmonics (nharm). Logical arguments reference_larger reference_smaller included analyze_objects(). indicates larger/smaller object image must used reference object. valid reference = TRUE reference_area indicates area reference object. IMPORTANT. reference_smaller used, objects area smaller 1% mean objects ignored. used remove possible noise image dust. , sure reference object area removed cutpoint. Rcpp RcppArmadillo dependencies included, allowing implementation C++ code. dramatically reduce time computing functions/procesures. example, wave. Reduction time processing 5 minutes less 1 second using new object_rgb() function extract RGB values image (1445 x 1084) ~1400 objects. Reduction time processing set *_poly() functions.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"minor-changes-2-0-0","dir":"Changelog","previous_headings":"","what":"Minor changes","title":"pliman 2.0.0","text":"get_measures() now remove known objects results using id argument. right-hand argument measure get_measures() now accepts numeric object stored global environment. analyze_objects() now returns objects object_index object_rgb argument pattern used. Thanks João Paulo Oliveira Ribeiro alerting regarding issue. New argument reference analyze_objects() adjust measures using reference object image. Argument object_index analyze_objects() now recognizes names built-indexes (see ?pliman_indexes()). plot.image_index() limits number pixels reduce plotting time. show_image argument changed plot standardize argument across functions. rgb_to_hsb() optimized using C++. Change rows cols nrow ncol, respectively, functions analyze_objects_shp(), image_shp(), measure_disease_shp(), object_split_shp(), standardize arguments across functions.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"pliman-110","dir":"Changelog","previous_headings":"","what":"pliman 1.1.0","title":"pliman 1.1.0","text":"CRAN release: 2021-12-10","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"new-functions-1-1-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"pliman 1.1.0","text":"measure_disease_iter() measure disease interactive section. pick_count() count objects image manually. pick_palette() create image palette picking color point(s) image pick_rgb() pick RGB values selected point(s) image. summary_index() summary index either within objects. pliman now exports foward-pipe operator %>%. Code poorman package.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"minor-changes-1-1-0","dir":"Changelog","previous_headings":"","what":"Minor changes","title":"pliman 1.1.0","text":"Deprecated functions last version (count_objects(), image_show(), leaf_area(), objects_rgb(), prop_segmented(), symptomatic_area()) removed. Use Bootstrap 5 pkgdown 2.0.0 package site.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"pliman-100","dir":"Changelog","previous_headings":"","what":"pliman 1.0.0","title":"pliman 1.0.0","text":"CRAN release: 2021-11-09","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"new-functions-1-0-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"pliman 1.0.0","text":"analyze_objects() now used main function compute number shape objects. measure_disease() now used main function perform phytopatometry studies. function can compute symptomatic area, well number shape lesions. image_segment_iter() used performs iterative image segmentation. conv_hull(), poly_area(), poly_mass(), poly_spline(), plot_contour(), plot_ellipse() utilities analyzing polygons. dpi() compute resolution (dots per inch) image. tune_tolerance() tunning tolerance parameter.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"deprecated-functions-1-0-0","dir":"Changelog","previous_headings":"","what":"Deprecated functions.","title":"pliman 1.0.0","text":"objects_rgb() depracated future. Now, compute index object use object_index argument analyze_objects(), example, analyze_objects(object_index = \"B\"). leaf_area() depracated future. Now, combine analyze_objects() get_measures() obtain area shape objects (leaves). prop_segmented() now deprecated favour image_segment_iter(). count_lesions() now deprecated. Now, compute number shape lesions, use argument show_features = TRUE measure_disease(). image_show() now deprecated favour plot().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"minor-improvements-1-0-0","dir":"Changelog","previous_headings":"","what":"Minor improvements","title":"pliman 1.0.0","text":"Include fill_hull argument symptomatic_area() count_lesions() Improve image_contrast() function avoid error regarding image resolution. New argument subfolder image_export() export image subfolder. Now EBImage installation checked pliman installed. image_pliman() now returns image object instead path image. , necessarily call within image_import().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"pliman-030","dir":"Changelog","previous_headings":"","what":"pliman 0.3.0","title":"pliman 0.3.0","text":"CRAN release: 2021-06-10","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"new-functions-0-3-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"pliman 0.3.0","text":"image_autocrop() automatic image cropping. image_filter() perform median-based filtering. image_contrast() improve contrast performing adaptive histogram equalization object_coord() get object coordinates (optionally) draw bounding rectangle around multiple objects image. object_id() get object identification image. object_isolate() isolate object image. prop_segmented() perform (iterative) image segmentation pixels proportion.","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"minor-improvements-0-3-0","dir":"Changelog","previous_headings":"","what":"Minor improvements","title":"pliman 0.3.0","text":"New argument filter count_objects() prop_segmented().","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"pliman-020","dir":"Changelog","previous_headings":"","what":"pliman 0.2.0","title":"pliman 0.2.0","text":"CRAN release: 2021-05-15 Includes suggestions given CRAN team first submission","code":""},{"path":"https://nepem-ufsc.github.io/pliman/news/index.html","id":"pliman-010","dir":"Changelog","previous_headings":"","what":"pliman 0.1.0","title":"pliman 0.1.0","text":"first version pliman package submitted CRAN.","code":""}]
